{
  "hash": "82b42f70cd304c1b4a847fd329f71fe8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Analysis Code\"\nformat: html\nexecute:\n  eval: false\n  echo: true  # Ensures code still appears\n  freeze: auto  # Prevents execution unless manually triggered\n\n---\n\n::: {#e9f0ac6e .cell execution_count=1}\n``` {.python .cell-code}\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Wed Feb 26 14:14:04 2025\n\n@author: gianc\n\"\"\"\n\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\nimport natsort\nimport os\nfrom scipy.interpolate import UnivariateSpline\nfrom scipy.optimize import brentq\nimport matplotlib as mpl\nfrom mpl_toolkits.axes_grid1.inset_locator import inset_axes\n\n\n\ndef compute_analysis(input_folder, output_folder, sizes, dim=2):\n    \"\"\"\n    Compute and save analysis for each system size.\n    This function averages observables (energy, magnetisation, Binder cumulant, etc.)\n    over simulation runs at each temperature, storing them in per–spin units.\n\n    The final arrays (e_means, mag_means, sus_vals, s_heat_vals) will be:\n      e_means, mag_means:        E/N^2,  M/N^2\n      sus_vals, s_heat_vals:     per–spin definitions of susceptibility & specific heat\n    \"\"\"\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    for N in sizes:\n        analysis_file = os.path.join(output_folder, f\"Analysis_N{N}.npz\")\n        # Remove or comment out this block if you want to overwrite existing files:\n        if os.path.exists(analysis_file):\n            print(f\"Analysis file for N={N} already exists. Skipping computation.\")\n            continue\n\n        files = natsort.natsorted(glob.glob(f\"{input_folder}/*N{N}*.npz\"))\n        print(f\"Processing system size N={N}\")\n\n        norm_factor = N**dim  \n\n        t_vals = []\n        binder_vals = []\n        binder_errs = []\n        e_means = []\n        e_errs = []\n        mag_means = []\n        mag_errs = []\n        sus_vals = []\n        sus_errs = []\n        s_heat_vals = []\n        s_heat_errs = []\n        corr_list = []\n\n        for f in files:\n            data = np.load(f)\n\n            try:\n                T = float(f.split(\"T\")[1].split(\"N\")[0])\n            except Exception as e:\n                print(f\"Error parsing temperature from {f}: {e}\")\n                continue\n\n            M = np.abs(data[\"magnetisation\"])\n            n_mag = len(M)\n            M_mean = np.mean(M)\n            M_std  = np.std(M, ddof=1)\n            M_err  = M_std / np.sqrt(n_mag)\n\n            M2_mean = np.mean(M**2)\n            M4_mean = np.mean(M**4)\n            M2_std  = np.std(M**2, ddof=1)\n            M4_std  = np.std(M**4, ddof=1)\n            M2_err  = M2_std / np.sqrt(n_mag)\n            M4_err  = M4_std / np.sqrt(n_mag)\n\n            if M2_mean == 0:\n                continue\n            binder = 1 - M4_mean / (3 * M2_mean**2)\n            binder_err = np.sqrt(\n                ((2 * M4_mean / (3 * M2_mean**3)) * M2_err)**2\n                + ((1 / (3 * M2_mean**2)) * M4_err)**2\n            )\n\n            E = data[\"energy\"]\n            n_e = len(E)\n            E_mean = np.mean(E)\n            E_std  = np.std(E, ddof=1)\n            E_err  = E_std / np.sqrt(n_e)\n\n            if T == 0:\n                continue\n            beta = 1.0 / T\n\n            var_M = (M2_mean - M_mean**2)\n            sus_val = beta * var_M / (norm_factor)\n            var_M_err = np.sqrt(M2_err**2 + (2 * M_mean * M_err)**2)\n            sus_err = beta * var_M_err / norm_factor\n\n            E2_mean = np.mean(E**2)\n            E2_std  = np.std(E**2, ddof=1)\n            E2_err  = E2_std / np.sqrt(n_e)\n            var_E   = (E2_mean - E_mean**2)\n            s_heat_val = beta**2 * var_E / norm_factor\n            var_E_err = np.sqrt(E2_err**2 + (2 * E_mean * E_err)**2)\n            s_heat_err = beta**2 * var_E_err / norm_factor\n\n            e_means.append(E_mean / norm_factor)\n            e_errs.append(E_err  / norm_factor)\n\n            mag_means.append(M_mean / norm_factor)\n            mag_errs.append(M_err  / norm_factor)\n\n            sus_vals.append(sus_val)\n            sus_errs.append(sus_err)\n            s_heat_vals.append(s_heat_val)\n            s_heat_errs.append(s_heat_err)\n\n            corr_list.append(data[\"correlation\"])\n\n            t_vals.append(T)\n            binder_vals.append(binder)\n            binder_errs.append(binder_err)\n\n        sort_idx = np.argsort(t_vals)\n        np.savez(\n            analysis_file,\n            t_vals        = np.array(t_vals)[sort_idx],\n            binder_vals   = np.array(binder_vals)[sort_idx],\n            binder_errs   = np.array(binder_errs)[sort_idx],\n            e_means       = np.array(e_means)[sort_idx],\n            e_errs        = np.array(e_errs)[sort_idx],\n            mag_means     = np.array(mag_means)[sort_idx],\n            mag_errs      = np.array(mag_errs)[sort_idx],\n            sus_vals      = np.array(sus_vals)[sort_idx],\n            sus_errs      = np.array(sus_errs)[sort_idx],\n            s_heat_vals   = np.array(s_heat_vals)[sort_idx],\n            s_heat_errs   = np.array(s_heat_errs)[sort_idx],\n            correlation   = np.array(corr_list)[sort_idx]\n        )\n\n        print(f\"Saved analysis for N={N} to {analysis_file}\")\n\n\n\n\ndef load_analysis(folder=\"data6\", sizes=[8, 16, 32]):\n    analysis_data = {}\n    for N in sizes:\n        filename = os.path.join(folder, f\"Analysis_N{N}.npz\")\n        if os.path.exists(filename):\n            data = np.load(filename)\n            analysis_data[N] = {\"t_vals\": data[\"t_vals\"],\n                              \"binder_vals\": data[\"binder_vals\"],\n                              \"binder_errs\": data[\"binder_errs\"],\n                              \"e_means\": data[\"e_means\"],\n                              \"e_errs\": data[\"e_errs\"],\n                              \"mag_means\": data[\"mag_means\"],\n                              \"mag_errs\": data[\"mag_errs\"],\n                              \"sus_vals\": data[\"sus_vals\"],\n                              \"sus_errs\": data[\"sus_errs\"],\n                              \"s_heat_vals\": data[\"s_heat_vals\"],\n                              \"s_heat_errs\": data[\"s_heat_errs\"],\n                              \"corr\": data[\"correlation\"] \n                              }\n        else:\n            print(f\"Analysis file not found for N={N}.\")\n    return analysis_data\n\ndef load_observables(input_folder=\"data6\", sizes=[8, 16, 32]):\n\n    observables_data = {}\n    for N in sizes:\n        filename = os.path.join(input_folder, f\"Analysis_N{N}.npz\")\n        if os.path.exists(filename):\n            data = np.load(filename)\n            observables_data[N] = {\n                \"t_vals\": data[\"t_vals\"],\n                \"e_means\": data[\"e_means\"],\n                \"e_errs\": data[\"e_errs\"],\n                \"mag_means\": data[\"mag_means\"],\n                \"mag_errs\": data[\"mag_errs\"],\n                \"sus_vals\": data[\"sus_vals\"],\n                \"sus_errs\": data[\"sus_errs\"],\n                \"s_heat_vals\": data[\"s_heat_vals\"],\n                \"s_heat_errs\": data[\"s_heat_errs\"],\n                \"corr\": data[\"correlation\"] \n            }\n        else:\n            print(f\"Analysis file not found for N={N}.\")\n    return observables_data\n\n\ndef plot_binder_values_with_critical(analysis_data, critical_temps, reference_size, \n                                     custom_T_low=None, custom_T_high=None,\n                                     inset_xlim=None, inset_ylim=None,\n                                     binder_text=\"(a)\", binder_text_pos=(0.05, 0.95),\n                                     inset_text=\"(y)\", inset_text_pos=(0.05, 0.90)):\n\n    plt.figure(figsize=(8, 6))\n    for N, data in analysis_data.items():\n        plt.errorbar(data[\"t_vals\"], data[\"binder_vals\"], yerr=data[\"binder_errs\"],\n                     fmt='o', label=f\"L={N}\", ecolor='black', capsize=5, alpha=0.5)\n    plt.axvline(x=2.269, color='red', linestyle='--', label=\"Expected $\\mathbf{T_c}$ (2.269)\")\n    if custom_T_low is not None and custom_T_high is not None:\n        plt.xlim(custom_T_low, custom_T_high)\n    plt.xlabel(\"Temperature, $\\mathbf{T}$\", fontsize=16)\n    plt.ylabel(\"Binder Cumulant, $\\mathbf{U_L}$\", fontsize=16)\n    plt.legend(fontsize=12, loc=\"upper right\")\n    plt.tick_params(axis='both', which='major', labelsize=14)\n\n    plt.gca().text(binder_text_pos[0], binder_text_pos[1], binder_text,\n                   transform=plt.gca().transAxes, fontsize=20, fontweight='bold')\n    \n    ax_inset = inset_axes(plt.gca(), width=\"100%\", height=\"100%\", \n                          bbox_to_anchor=(0.11, 0.09, 0.4, 0.5),\n                          bbox_transform=plt.gca().transAxes, borderpad=0)\n    \n    ratios = [N / reference_size for N in critical_temps.keys()]\n    Tc_values = [val[0] for val in critical_temps.values()]\n    Tc_errors = [val[1] for val in critical_temps.values()]\n    \n    ax_inset.errorbar(ratios, Tc_values, yerr=Tc_errors, fmt='o', color='blue',\n                      ecolor='black', capsize=4, alpha=0.8, label=\"Estimated $\\mathbf{T_c}$\")\n    \n    avg_Tc = np.mean(Tc_values)\n    avg_error = np.mean(Tc_errors)\n    ax_inset.axhline(y=avg_Tc, color='blue', linestyle='--',\n                     label=\"Avg $\\mathbf{T_c}$ = \" + f\"{avg_Tc:.3f}±{avg_error:.3f}\")\n    \n    ax_inset.axhline(y=2.269, color='red', linestyle='--', label=\"Expected $\\mathbf{T_c}$\")\n    \n    if inset_xlim is not None:\n        ax_inset.set_xlim(inset_xlim)\n    else:\n        margin = 0.1\n        ax_inset.set_xlim(min(ratios) - margin, max(ratios) + margin)\n    \n    if inset_ylim is not None:\n        ax_inset.set_ylim(inset_ylim)\n    \n    ax_inset.set_xticks(ratios)\n    ax_inset.set_xlabel(\"$\\mathbf{L / L_{min}}$\", fontsize=16)\n    ax_inset.xaxis.set_label_coords(0.5, -0.03)\n    ax_inset.set_ylabel(\"$\\mathbf{T}$\", fontsize=16, rotation=0)\n    ax_inset.yaxis.set_label_coords(-0.07, 1.03)\n    ax_inset.xaxis.label.set_bbox(dict(facecolor='white', edgecolor='black', pad=2))\n    ax_inset.yaxis.label.set_bbox(dict(facecolor='white', edgecolor='black', pad=3))\n    \n    ax_inset.tick_params(axis='both', which='major', labelsize=11)\n    ax_inset.legend(fontsize=11, loc='upper right', bbox_to_anchor=(1.00, 0.4))\n\n    \n    ax_inset.text(inset_text_pos[0], inset_text_pos[1], inset_text,\n                  transform=ax_inset.transAxes, fontsize=20, fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig(\"C:/Users/gianc/Documents/isingproject/final figs/bind_final.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n    plt.show()\n\n    \n    \ndef plot_binder_values(analysis_data, custom_T_low=None, custom_T_high=None):\n    plt.figure(figsize=(8, 6))\n    for N, data in analysis_data.items():\n        plt.errorbar(data[\"t_vals\"], data[\"binder_vals\"], yerr=data[\"binder_errs\"],\n                     fmt='o', label=f\"N={N}\", ecolor='black', capsize=5, alpha=0.5)\n    plt.axvline(x=2.269, color='red', linestyle='--', label=\"Expected $T_c$ (2.269)\")\n    if custom_T_low is not None and custom_T_high is not None:\n        plt.xlim(custom_T_low, custom_T_high)\n    plt.xlabel(\"Temperature T\")\n    plt.ylabel(\"Binder Cumulant\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n\n\ndef plot_corr_linear(observables_data, T_targets=(2.269, 2.3)):\n    plt.figure(figsize=(8, 6))\n    base_colors = plt.cm.tab10.colors  \n    num_base_colors = len(base_colors)\n    \n    for i, (N, data) in enumerate(sorted(observables_data.items())):\n        if data[\"corr\"] is None:\n            continue\n        base_color = base_colors[i % num_base_colors]\n        \n        for j, T in enumerate(T_targets):\n            if j == 0:\n                marker_alpha = 1.0\n                line_style = '-'\n            else:\n                marker_alpha = 0.5\n                line_style = ':'\n            \n            idx = np.argmin(np.abs(data[\"t_vals\"] - T))\n            corr = data[\"corr\"][idx]\n            r_norm = np.arange(len(corr)) / N\n            \n            plt.plot(r_norm, corr, 'o', color=base_color, alpha=marker_alpha)\n            \n            coeffs = np.polyfit(r_norm, corr, 10)\n            p = np.poly1d(coeffs)\n            x_fit = np.linspace(np.min(r_norm), np.max(r_norm), 100)\n            y_fit = p(x_fit)\n            plt.plot(x_fit, y_fit, linestyle=line_style, color=base_color, alpha=1.0,\n                     label=f\" N={N}, T={data['t_vals'][idx]:.3f}\")\n    \n    plt.xlabel(\"Normalized distance (r/N)\")\n    plt.ylabel(\"$G(r)$\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_corr_semilog(observables_data, T_target=2.269):\n    plt.figure(figsize=(8,6))\n    for N, data in observables_data.items():\n        if data[\"corr\"] is None:\n            continue\n        idx = np.argmin(np.abs(data[\"t_vals\"] - T_target))\n        corr = data[\"corr\"][idx]\n        r = np.arange(len(corr))\n        plt.semilogy(r, corr, 'o-', label=f\"N={N}, T={data['t_vals'][idx]:.3f}\")\n    plt.xlabel(\"Distance r\")\n    plt.ylabel(\"Connected Correlation Function $C_{conn}(r)$ (log scale)\")\n    plt.title(\"Semilog Plot of $C_{conn}(r)$ vs. r\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_corr_loglog(observables_data, T_target=2.269):\n    plt.figure(figsize=(8,6))\n    for N, data in observables_data.items():\n        if data[\"corr\"] is None:\n            continue\n        idx = np.argmin(np.abs(data[\"t_vals\"] - T_target))\n        corr = data[\"corr\"][idx]\n        r = np.arange(1, len(corr))\n        plt.loglog(r, corr[1:], 'o-', label=f\"N={N}, T={data['t_vals'][idx]:.3f}\")\n    plt.xlabel(\"Distance r (log scale)\")\n    plt.ylabel(\"$C_{conn}(r)$ (log scale)\")\n    plt.title(\"Log-Log Plot of $C_{conn}(r)$ vs. r\")\n    plt.legend()\n    plt.grid(True, which=\"both\", ls=\"--\")\n    plt.show()\n\ndef compute_correlation_length(corr, N, corr_err=None):\n    R = len(corr) - 1\n    \n    if N % 2 == 0:\n        S0 = corr[0] + 2 * np.sum(corr[1:R]) + corr[R]\n        S_k = (corr[0] + 2 * np.sum(corr[1:R] * np.cos(2*np.pi*np.arange(1, R)/N))\n               + corr[R]*np.cos(np.pi))\n        if corr_err is not None:\n            S0_err = np.sqrt(corr_err[0]**2 + 4*np.sum(corr_err[1:R]**2) + corr_err[R]**2)\n            S_k_err = np.sqrt(corr_err[0]**2 + 4*np.sum((np.cos(2*np.pi*np.arange(1,R)/N)**2 * corr_err[1:R]**2))\n                               + (np.cos(np.pi)*corr_err[R])**2)\n        else:\n            S0_err = S_k_err = np.nan\n    else:\n        S0 = corr[0] + 2 * np.sum(corr[1:R+1])\n        S_k = corr[0] + 2 * np.sum(corr[1:R+1] * np.cos(2*np.pi*np.arange(1, R+1)/N))\n        if corr_err is not None:\n            S0_err = np.sqrt(corr_err[0]**2 + 4*np.sum(corr_err[1:R+1]**2))\n            S_k_err = np.sqrt(corr_err[0]**2 + 4*np.sum((np.cos(2*np.pi*np.arange(1,R+1)/N)**2 * corr_err[1:R+1]**2))\n                               )\n        else:\n            S0_err = S_k_err = np.nan\n\n    ratio = S0/S_k - 1\n    if ratio < 0:\n        print(f\"Warning: Negative ratio encountered for N={N}: ratio = {ratio}, S0 = {S0}, S_k = {S_k}\")\n        return np.nan, np.nan\n    xi = 1.0/(2*np.sin(np.pi/N)) * np.sqrt(ratio)\n    \n    if corr_err is not None:\n        dR_dS0 = 1.0 / S_k\n        dR_dS_k = -S0 / (S_k**2)\n        ratio_err = np.sqrt((dR_dS0 * S0_err)**2 + (dR_dS_k * S_k_err)**2)\n        factor = 1.0/(2*np.sin(np.pi/N))\n        xi_err = factor/(2*np.sqrt(ratio)) * ratio_err\n    else:\n        xi_err = np.nan\n\n    return xi, xi_err\n\ndef plot_correlation_length(observables_data):\n    plt.figure(figsize=(8, 6))\n    for N, data in observables_data.items():\n        if data[\"corr\"] is None:\n            continue\n\n        t_vals = data[\"t_vals\"]\n        xi_norm_vals = []\n        xi_norm_errs = []\n\n        has_corr_err = \"corr_err\" in data\n\n        for i, corr_raw in enumerate(data[\"corr\"]):\n            m = data[\"mag_means\"][i]\n            corr_connected = corr_raw - m**2\n            corr_err = data[\"corr_err\"][i] if has_corr_err else None\n            xi, xi_err = compute_correlation_length(corr_connected, N, corr_err)\n            xi_norm_vals.append(xi / N)\n            xi_norm_errs.append(xi_err / N if xi_err is not None else np.nan)\n\n        xi_norm_vals = np.array(xi_norm_vals)\n        xi_norm_errs = np.array(xi_norm_errs)\n        plt.errorbar(t_vals, xi_norm_vals, yerr=xi_norm_errs, fmt='o-', capsize=5,\n                     label=f\"L={N}\")\n\n    plt.xlabel(\"Temperature,  T\")\n    plt.ylabel(\"Normalized Correlation Length, $\\\\xi/L$\")\n    plt.legend()\n    plt.savefig(\"C:/Users/gianc/Documents/isingproject/final figs/c_length_final.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n    plt.show()\n\ndef plot_fss_xi(observables_data, T_target=2.269):\n    sizes = []\n    xi_target = []\n    for N, data in observables_data.items():\n        if data[\"corr\"] is None:\n            continue\n        idx = np.argmin(np.abs(data[\"t_vals\"] - T_target))\n        xi = compute_correlation_length(data[\"corr\"][idx], N)\n        sizes.append(N)\n        xi_target.append(xi)\n    sizes = np.array(sizes)\n    xi_target = np.array(xi_target)\n    plt.figure(figsize=(8,6))\n    plt.loglog(sizes, xi_target, 'o-', label=f\"T={T_target:.3f}\")\n    slope, intercept = np.polyfit(np.log(sizes), np.log(xi_target), 1)\n    plt.loglog(sizes, np.exp(intercept)*sizes**slope, '--', label=f\"Fit: slope = {slope:.2f}\")\n    plt.xlabel(\"System Size N\")\n    plt.ylabel(\"Correlation Length $\\\\xi$\")\n    plt.title(\"Finite-Size Scaling of Correlation Length\")\n    plt.legend()\n    plt.grid(True, which='both', ls='--')\n    plt.show()\n\ndef plot_scaling_collapse(observables_data, T_target=2.269, eta=0.25, d=2):\n    plt.figure(figsize=(8,6))\n    for N, data in observables_data.items():\n        if data[\"corr\"] is None:\n            continue\n        idx = np.argmin(np.abs(data[\"t_vals\"] - T_target))\n        corr = data[\"corr\"][idx]\n        r = np.arange(len(corr))\n        scale_factor = N**(d-2+eta)\n        plt.plot(r/float(N), scale_factor * corr, 'o-', label=f\"N={N}\")\n    plt.xlabel(\"Scaled distance r/N\")\n    plt.ylabel(f\"Scaled Correlation: $N^{{d-2+\\\\eta}} C_{{conn}}(r)$\")\n    plt.title(f\"Scaling Collapse of Correlation Function at T={T_target:.3f}\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef build_splines(analysis_data, s=0):\n    splines = {}\n    for N, data in analysis_data.items():\n        T = data[\"t_vals\"]\n        binder = data[\"binder_vals\"]\n        spline = UnivariateSpline(T, binder, s=s)\n        binder_error = data[\"binder_errs\"]\n        error_spline = UnivariateSpline(T, binder_error, s=s)\n        splines[N] = {\"spline\": spline, \"error_spline\": error_spline}\n    return splines\n\ndef find_intersection(spline1, spline2, error_spline1, error_spline2, T_min, T_max, num_points=1000):\n    T_values = np.linspace(T_min, T_max, num_points)\n    diff = spline1(T_values) - spline2(T_values)\n    for i in range(len(diff) - 1):\n        if diff[i] * diff[i+1] < 0:\n            try:\n                Tc = brentq(lambda T: spline1(T) - spline2(T), T_values[i], T_values[i+1])\n                d_diff_dT = spline1.derivative()(Tc) - spline2.derivative()(Tc)\n                err1 = error_spline1(Tc)\n                err2 = error_spline2(Tc)\n                Tc_error = np.sqrt(err1**2 + err2**2) / np.abs(d_diff_dT) if d_diff_dT != 0 else np.inf\n                return Tc, Tc_error\n            except ValueError:\n                continue\n    return None, None\n\ndef calculate_all_intersections(analysis_data, s=0, custom_T_low=None, custom_T_high=None):\n    splines = build_splines(analysis_data, s=s)\n    intersection_dict = {}\n    sizes = sorted(analysis_data.keys())\n    for i in range(len(sizes)):\n        for j in range(i+1, len(sizes)):\n            N1 = sizes[i]\n            N2 = sizes[j]\n            \n            if custom_T_low is not None and custom_T_high is not None:\n                T_min = custom_T_low\n                T_max = custom_T_high\n            else:\n                T_min = max(np.min(analysis_data[N1][\"t_vals\"]), np.min(analysis_data[N2][\"t_vals\"]))\n                T_max = min(np.max(analysis_data[N1][\"t_vals\"]), np.max(analysis_data[N2][\"t_vals\"]))\n                \n            Tc, Tc_error = find_intersection(splines[N1][\"spline\"], splines[N2][\"spline\"],\n                                             splines[N1][\"error_spline\"], splines[N2][\"error_spline\"],\n                                             T_min, T_max)\n            if Tc is not None:\n                intersection_dict[(N1, N2)] = (Tc, Tc_error)\n                print(f\"Intersection for N={N1} and N={N2}: Tc = {Tc:.4f} ± {Tc_error:.4f}\")\n            else:\n                print(f\"No intersection found for N={N1} and N={N2} in range [{T_min:.4f}, {T_max:.4f}].\")\n    return intersection_dict\n\ndef calculate_critical_temperatures(analysis_data, custom_T_low=None, custom_T_high=None):\n    splines = build_splines(analysis_data)\n    reference_size = min(analysis_data.keys())\n    ref_spline = splines[reference_size][\"spline\"]\n    ref_error_spline = splines[reference_size][\"error_spline\"]\n    critical_temps = {}\n    for N, spline_data in splines.items():\n        if N == reference_size:\n            continue\n            \n        if custom_T_low is not None and custom_T_high is not None:\n            T_min = custom_T_low\n            T_max = custom_T_high\n        else:\n            T_min = max(np.min(analysis_data[reference_size][\"t_vals\"]), np.min(analysis_data[N][\"t_vals\"]))\n            T_max = min(np.max(analysis_data[reference_size][\"t_vals\"]), np.max(analysis_data[N][\"t_vals\"]))\n            \n        Tc, Tc_error = find_intersection(ref_spline, spline_data[\"spline\"],\n                                         ref_error_spline, spline_data[\"error_spline\"],\n                                         T_min, T_max)\n        if Tc is not None:\n            critical_temps[N] = (Tc, Tc_error)\n            print(f\"Intersection for N={N} (ratio {N/reference_size:.2f}): Tc = {Tc:.4f} ± {Tc_error:.4f}\")\n        else:\n            print(f\"No intersection found for N={N} in range [{T_min:.4f}, {T_max:.4f}].\")\n    return critical_temps, reference_size\n\ndef plot_all_intersections(analysis_data, intersections, zoom_margin=0.005, custom_T_low=None, custom_T_high=None):\n    splines = build_splines(analysis_data)\n    if custom_T_low is not None and custom_T_high is not None:\n        T_low, T_high = custom_T_low, custom_T_high\n    else:\n        if intersections:\n            Tc_values = [val[0] for val in intersections.values()]\n            T_low = min(Tc_values) - zoom_margin\n            T_high = max(Tc_values) + zoom_margin\n        else:\n            T_low, T_high = 2.25, 2.29\n    T_fine = np.linspace(T_low, T_high, 1000)\n    plt.figure(figsize=(8, 6))\n    for N, spline_data in splines.items():\n        spline = spline_data[\"spline\"]\n        plt.plot(T_fine, spline(T_fine), label=f\"N={N}\")\n        data = analysis_data[N]\n        mask = (data[\"t_vals\"] >= T_low) & (data[\"t_vals\"] <= T_high)\n        plt.errorbar(np.array(data[\"t_vals\"])[mask], np.array(data[\"binder_vals\"])[mask],\n                     yerr=np.array(data[\"binder_errs\"])[mask], fmt='o', markersize=4,\n                     ecolor='black', capsize=5, alpha=0.5)\n    for (N1, N2), (Tc, Tc_error) in intersections.items():\n        binder_val = splines[N1][\"spline\"](Tc)\n        plt.errorbar(Tc, binder_val, yerr=Tc_error, fmt='ko', markersize=8,\n                     ecolor='black', capsize=5, alpha=0.5)\n        plt.text(Tc, binder_val, f\" {Tc:.3f}±{Tc_error:.3f}\", fontsize=9, color='black')\n        plt.axvline(x=Tc, color='gray', linestyle='--', linewidth=0.5)\n    if T_low <= 2.269 <= T_high:\n        plt.axvline(x=2.269, color='red', linestyle='--', label=\"Expected $T_c$ (2.269)\")\n    plt.xlabel(\"Temperature T\")\n    plt.ylabel(\"Binder Cumulant\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_critical_temperatures(critical_temps, reference_size):\n    ratios = [N / reference_size for N in critical_temps.keys()]\n    Tc_values = [val[0] for val in critical_temps.values()]\n    Tc_errors = [val[1] for val in critical_temps.values()]\n    \n    plt.figure(figsize=(8, 6))\n    plt.errorbar(ratios, Tc_values, yerr=Tc_errors, fmt='o', color='blue',\n                 label=\"Estimated $T_c$\", ecolor='black', capsize=5, alpha=0.7)\n    \n    avg_Tc = np.mean(Tc_values)\n    avg_error = np.mean(Tc_errors)\n    \n    plt.axhline(y=avg_Tc, color='blue', linestyle='--',\n                label=f\"Average $T_c$ = {avg_Tc:.3f} ± {avg_error:.3f}\")\n    \n    plt.axhline(y=2.269, color='red', linestyle='--', label=\"Expected $T_c$ (2.269)\")\n    \n    plt.xlabel(\"System Size Ratio ($N / N_{small}$)\")\n    plt.ylabel(\"Critical Temperature $T_c$\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef load_observables_extended(input_folder=\"data6\", sizes=[8, 16, 32]):\n    \"\"\"\n    This function loads all observables including the connected correlation function.\n    \"\"\"\n    observables_data = {}\n    for N in sizes:\n        filename = os.path.join(input_folder, f\"Analysis_N{N}.npz\")\n        if os.path.exists(filename):\n            data = np.load(filename)\n            observables_data[N] = {\n                \"t_vals\": data[\"t_vals\"],\n                \"e_means\": data[\"e_means\"],\n                \"e_errs\": data[\"e_errs\"],\n                \"mag_means\": data[\"mag_means\"],\n                \"mag_errs\": data[\"mag_errs\"],\n                \"sus_vals\": data[\"sus_vals\"],\n                \"sus_errs\": data[\"sus_errs\"],\n                \"s_heat_vals\": data[\"s_heat_vals\"],\n                \"s_heat_errs\": data[\"s_heat_errs\"],\n                \"corr\": data[\"correlation\"] if \"correlation\" in data else None\n            }\n        else:\n            print(f\"Analysis file not found for N={N}.\")\n    return observables_data\n\ndef plot_observables(observables_data):\n    fig, axs = plt.subplots(4, 1, figsize=(12, 16))\n    \n    ax = axs[0]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"e_means\"], yerr=data[\"e_errs\"],\n                    fmt='o', label=f\"L={N}\", ecolor='black', capsize=5, alpha=0.5)\n    ax.set_xlabel(\"Temperature, $T$\")\n    ax.set_ylabel(\"Energy, $<H>$\")\n    ax.legend()\n    \n    ax = axs[1]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"mag_means\"], yerr=data[\"mag_errs\"],\n                    fmt='o', label=f\"L={N}\", ecolor='black', capsize=5, alpha=0.5)\n    all_T = np.concatenate([data[\"t_vals\"] for data in observables_data.values()])\n    T_min = np.min(all_T)\n    Tc = 2.269\n    T_vals = np.linspace(T_min, Tc, 300)\n    ax.plot([Tc, Tc], [0, 0.38], 'k--', lw=2)\n    m_ons = (1 - np.sinh(2/T_vals)**(-4))**(1/8)\n    ax.plot(T_vals, m_ons, 'k--', lw=2, label=\"Onsager\")\n    ax.set_xlabel(\"Temperature, $T$\")\n    ax.set_ylabel(\"Magnetisation, $M$\")\n    ax.legend()\n    \n    ax = axs[2]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"sus_vals\"], yerr=data[\"sus_errs\"],\n                    fmt='o', label=f\"L={N}\", ecolor='black', capsize=5, alpha=0.5)\n    ax.set_xlabel(\"Temperature, $T$\")\n    ax.set_ylabel(\"Susceptibility, $\\chi$\")\n    ax.legend()\n    \n    ax = axs[3]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"s_heat_vals\"], yerr=data[\"s_heat_errs\"],\n                    fmt='o', label=f\"L={N}\", ecolor='black', capsize=5, alpha=0.5)\n    ax.set_xlabel(\"Temperature, $T$\")\n    ax.set_ylabel(\"Specific Heat, $C$\")\n    ax.legend()\n    \n    plt.tight_layout()\n    plt.savefig(\"C:/Users/gianc/Documents/isingproject/final figs/obs.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n    plt.show()\n\ndef plot_loglog_observables(observables_data, intersections, cutoff=1e-5, Tc_avg=2.269, \n                            reduced_range_low=None, reduced_range_high=None, T_target=2.269,\n                            side='lower'):\n    import numpy as np\n    fig, axs = plt.subplots(4, 1, figsize=(8, 12))\n    \n    obs_keys = {\"magnetisation\": \"mag_means\",\n                \"susceptibility\": \"sus_vals\",\n                \"specific_heat\": \"s_heat_vals\"}\n    err_keys = {\"magnetisation\": \"mag_errs\",\n                \"susceptibility\": \"sus_errs\",\n                \"specific_heat\": \"s_heat_errs\"}\n    obs_titles = {\"magnetisation\": \"Magnetisation, $M$\", \n                  \"susceptibility\": \"Susceptibility, $\\\\chi$\", \n                  \"specific_heat\": \"Specific Heat, $C$\"}\n    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n\n    for i, (obs, key) in enumerate(obs_keys.items()):\n        ax = axs[i]\n        for j, N in enumerate(sorted(observables_data.keys())):\n            data = observables_data[N]\n            T = data[\"t_vals\"]\n            y = data[key]\n            y_err = data[err_keys[obs]]\n            if obs == \"magnetisation\":\n                y = np.abs(y)\n            if side.lower() == 'lower':\n                x = (Tc_avg - T) / Tc_avg\n            elif side.lower() == 'upper':\n                x = (T - Tc_avg) / Tc_avg\n            mask = x > cutoff\n            if reduced_range_low is not None:\n                mask &= (x >= reduced_range_low)\n            if reduced_range_high is not None:\n                mask &= (x <= reduced_range_high)\n            x_plot, y_plot = x[mask], y[mask]\n            y_err_plot = y_err[mask]\n            if len(x_plot) < 2:\n                continue\n            color = colors[j % len(colors)]\n            ax.errorbar(x_plot, y_plot, yerr=y_err_plot, fmt='o', color=color,\n                        ecolor='black', capsize=5, alpha=0.5)\n            logx, logy = np.log(x_plot), np.log(y_plot)\n            p, cov = np.polyfit(logx, logy, 1, cov=True)\n            slope, intercept = p\n            slope_error = np.sqrt(cov[0, 0])\n            x_fit = np.linspace(np.min(x_plot), np.max(x_plot), 100)\n            y_fit = np.exp(intercept) * x_fit**slope\n            ax.plot(x_fit, y_fit, '--', color=color,\n                    label=f\"L={N} fit: {slope:.3f}±{slope_error:.3f}\")\n            \n        ax.set_xscale('log')\n        ax.set_yscale('log')\n        xlabel = r\"Reduced Temperature, $\\mathbf{(T_c-T)/T_c}$\" if side.lower() == 'lower' else r\"Reduced Temperature, $\\mathbf{(T_c-T)/T_c}$\"\n        ax.set_xlabel(xlabel, fontsize=16)\n        ax.set_ylabel(obs_titles[obs], fontsize=16)\n        ax.legend(fontsize=12,loc=\"upper right\") if i == 2 else ax.legend(fontsize=12)\n        \n        ax.tick_params(axis='both', which='major', width=3)\n        ax.tick_params(axis='both', which='minor', width=1.5)\n\n    \n    ax = axs[3]\n    sizes = []\n    xi_target = []\n    xi_errs = []\n    for N, data in sorted(observables_data.items()):\n        if data[\"corr\"] is None:\n            continue\n        idx = np.argmin(np.abs(data[\"t_vals\"] - T_target))\n        corr = data[\"corr\"][idx]\n        corr_err = data[\"corr_err\"][idx] if \"corr_err\" in data else None\n        xi, xi_err = compute_correlation_length(corr, N, corr_err)\n        sizes.append(N)\n        xi_target.append(xi)\n        xi_errs.append(xi_err)\n    sizes = np.array(sizes)\n    xi_target = np.array(xi_target)\n    xi_errs = np.array(xi_errs)\n    ax.errorbar(sizes, xi_target, yerr=xi_errs, fmt='o-', capsize=5,\n                label=f\"T={T_target:.3f}\", ecolor='black')\n    if len(sizes) > 1:\n        p, cov = np.polyfit(np.log(sizes), np.log(xi_target), 1, cov=True)\n        slope, intercept = p\n        slope_error = np.sqrt(cov[0, 0])\n        fit_line = np.exp(intercept) * sizes**slope\n        ax.loglog(sizes, fit_line, '--',\n                  label=f\"Fit: slope = {slope:.2f}±{slope_error:.2f}\")\n    ax.set_xlabel(\"System Size, L\", fontsize=18)\n    ax.set_ylabel(\"Correlation Length, $\\\\xi$\", fontsize=15)\n    ax.legend(fontsize=15)\n    ax.tick_params(axis='both', which='major', width=3)\n    ax.tick_params(axis='both', which='minor', width=1.5)\n\n    \n    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n    plt.savefig(\"C:/Users/gianc/Documents/isingproject/final figs/exp.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n    plt.show()\n\ndef plot_observable_errors(observables_data):\n    err_keys = {\"energy\": \"e_errs\",\n                \"magnetisation\": \"mag_errs\",\n                \"susceptibility\": \"sus_errs\",\n                \"specific_heat\": \"s_heat_errs\"}\n    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n    ax = axs[0, 0]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"energy\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Energy Error\")\n    ax.set_title(\"Energy Error vs. Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[0, 1]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"magnetisation\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Magnetisation Error\")\n    ax.set_title(\"Magnetisation Error vs. Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[1, 0]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"susceptibility\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Susceptibility Error\")\n    ax.set_title(\"Susceptibility Error vs. Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[1, 1]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"specific_heat\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Specific Heat Error\")\n    ax.set_title(\"Specific Heat Error vs. Temperature\")\n    ax.legend()\n    plt.tight_layout()\n    plt.show()\n    \n\ndef plot_mag_vs_iterations_comparison(primary_folder, secondary_folder, temperature, system_size, max_iterations=None):\n\n    primary_pattern = os.path.join(primary_folder, f\"*T{temperature}*N{system_size}*.npz\")\n    primary_files = natsort.natsorted(glob.glob(primary_pattern))\n    if not primary_files:\n        print(f\"No file found in {primary_folder} for T={temperature} and N={system_size}\")\n        return\n    primary_file = primary_files[0]\n    data_primary = np.load(primary_file)\n    mag_primary = np.abs(data_primary['magnetisation'])\n    \n    secondary_pattern = os.path.join(secondary_folder, f\"*T{temperature}*N{system_size}*.npz\")\n    secondary_files = natsort.natsorted(glob.glob(secondary_pattern))\n    if not secondary_files:\n        print(f\"No file found in {secondary_folder} for T={temperature} and N={system_size}\")\n        return\n    secondary_file = secondary_files[0]\n    data_secondary = np.load(secondary_file)\n    mag_secondary = np.abs(data_secondary['magnetisation'])\n    \n    # Limit iterations if max_iterations is provided\n    if max_iterations is not None:\n        mag_primary = mag_primary[:max_iterations]\n        mag_secondary = mag_secondary[:max_iterations]\n    \n    iterations_primary = np.arange(len(mag_primary))\n    iterations_secondary = np.arange(len(mag_secondary))\n    \n    plt.figure(figsize=(8, 6))\n    plt.plot(iterations_primary, mag_primary, label=\"Wolfs Algorithm\", marker='o', linestyle='-')\n    plt.plot(iterations_secondary, mag_secondary, label=\"Metropolis Algorithm\", marker='s', linestyle='--')\n    plt.xlabel(\"Iteration\")\n    plt.ylabel(\"Magnetisation, M\")\n    plt.legend(fontsize=14, loc=\"upper right\")\n    plt.savefig(\"C:/Users/gianc/Documents/isingproject/final figs/w_vs_m_final.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    folder = \"final_cluster_exponent\"  \n    params_filepath = os.path.join(folder, \"simulation_parameters.npz\")\n    if os.path.exists(params_filepath):\n        params = np.load(params_filepath)\n        nt = int(params[\"nt\"])\n        n_list = params[\"n_list\"].tolist() #[16, 32, 64, 128]\n        eqSteps = int(params[\"eqSteps\"])\n        mcSteps = int(params[\"mcSteps\"])\n        T_arr = params[\"T_arr\"]\n        print(\"Loaded Simulation Parameters:\")\n        print(\"nt       =\", nt)\n        print(\"n_list   =\", n_list)\n        print(\"eqSteps  =\", eqSteps)\n        print(\"mcSteps  =\", mcSteps)\n    else:\n        print(f\"Simulation parameters file not found in {folder}. Using default sizes.\")\n        n_list = [8, 16, 32]\n        \n    \n    mpl.rcParams.update({\n        \"figure.dpi\": 300,        \n        \"savefig.dpi\": 300,      \n        \"font.size\": 13,\n        \"axes.titlesize\": 15,\n        \"axes.labelsize\": 13,\n        \"legend.fontsize\": 20,\n        \"text.usetex\": False, \n        \"font.family\": \"sans-serif\",  \n        \"font.sans-serif\": [\"DejaVu Sans\"],  \n        \"font.weight\": \"bold\",\n        \"axes.labelweight\": \"bold\",\n        \"axes.titleweight\": \"bold\",\n        \"mathtext.fontset\": \"dejavusans\",\n        \"axes.linewidth\": 0.8, \n        \"xtick.major.width\": 0.8,\n        \"ytick.major.width\": 0.8,\n        \"lines.linewidth\": 1.0,\n    })\n\n    \n    compute_analysis(input_folder=folder, output_folder=folder, sizes=n_list, dim=2)\n    analysis_data = load_analysis(folder=folder, sizes=n_list)\n    \n    # binder_range_low = 2.26\n    # binder_range_high = 2.3\n    \n    binder_range_low = 2.1\n    binder_range_high = 2.5\n    \n    intersection_range_low = 2.26\n    intersection_range_high = 2.27\n   \n    high_T_threshold = 3.0\n    \n    # binder_range_low = 4.4\n    # binder_range_high = 4.6\n    #plot_binder_values(analysis_data, custom_T_low=binder_range_low, custom_T_high=binder_range_high)\n    \n    \n    intersections = calculate_all_intersections(analysis_data, \n                                               custom_T_low=intersection_range_low, \n                                               custom_T_high=intersection_range_high)\n    # plot_all_intersections(analysis_data, intersections, zoom_margin=0.005, custom_T_low=2.2, custom_T_high=2.3)\n    \n    #plot_all_intersections(analysis_data, intersections, zoom_margin=0.005, custom_T_low=2.2685, custom_T_high=2.2695)\n    # plot_all_intersections(analysis_data, intersections, zoom_margin=0.005, custom_T_low=4.5, custom_T_high=4.515)\n    critical_temps, ref_size = calculate_critical_temperatures(analysis_data, custom_T_low=intersection_range_low, \n    custom_T_high=intersection_range_high )\n    \n    #plot_critical_temperatures(critical_temps, ref_size)\n    \n    observables_data = load_observables_extended(input_folder=folder, sizes=n_list)\n    \n    plot_observables(observables_data)\n    \n    T_target = 2.26\n    #plot_corr_linear(observables_data, T_targets=(2.269, 3))\n\n\n    plot_correlation_length(observables_data)\n    #plot_fss_xi(observables_data, T_target=T_target)\n\n    plot_loglog_observables(observables_data, intersections, Tc_avg=2.269, \n                        reduced_range_low=0.005, reduced_range_high=1, side='lower')\n\n\n    # plot_observable_errors(observables_data)\n    #plot_Cv_fss(observables_data, Tc=2.269)\n    #plot_semi_log_specific_heat(observables_data, Tc=2.269, T_range=(2, 2.269))\n\n    plot_mag_vs_iterations_comparison(\n        primary_folder=\"wolfs1\",\n        secondary_folder=\"metropolis1\",\n        temperature=2.275,\n        system_size=32,\n        max_iterations=500  \n    )\n    critical_temps, reference_size = calculate_critical_temperatures(analysis_data, \n                                      custom_T_low=intersection_range_low, \n                                      custom_T_high=intersection_range_high)\n    plot_binder_values_with_critical(analysis_data, critical_temps, reference_size, \n                                         custom_T_low=None, custom_T_high=None,\n                                         inset_xlim=None, inset_ylim=None,\n                                         binder_text=\"(a)\", binder_text_pos=(0.55, 0.90),\n                                         inset_text=\"(b)\", inset_text_pos=(0.1, 0.85))\n```\n:::\n\n\n",
    "supporting": [
      "analysis_text_files\\figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}