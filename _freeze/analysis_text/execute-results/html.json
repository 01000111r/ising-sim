{
  "hash": "0bbc8bfe491d1f77761b1d6a8ba081b7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Analysis Code\"\nformat: html\nexecute:\n  eval: false\n  echo: true  # Ensures code still appears\n  freeze: auto  # Prevents execution unless manually triggered\n\n---\n\n::: {#ec6105b2 .cell execution_count=1}\n``` {.python .cell-code}\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\nimport natsort\nimport os\nfrom scipy.interpolate import UnivariateSpline\nfrom scipy.optimize import brentq\n\ndef compute_analysis(input_folder, output_folder, sizes):\n    \"\"\"\n    \n\n    Parameters\n    ----------\n    input_folder : TYPE string\n        DESCRIPTION. string of input folder name in repo directory\n    output_folder : TYPE string\n        DESCRIPTION. string of input folder name in repo directory\n    sizes : TYPE list\n        DESCRIPTION. list of system sizes in input folder\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    #create new folder if dosnt exist\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n        \n    for N in sizes:\n        #open file/ create new one\n        analysis_file = os.path.join(output_folder, f\"Analysis_N{N}.npz\")\n        #skip if file exits\n        if os.path.exists(analysis_file):\n            print(f\"Analysis file for N={N} already exists. Skipping computation.\")\n            continue\n        #collect and sort runs associated with system size N\n        files = natsort.natsorted(glob.glob(f\"{input_folder}/*N{N}*.npz\"))\n        \n        print(f\"Processing system size N={N}\")\n        \n        #initialising main arrays\n        t_vals = []\n        binder_vals = []\n        binder_errs = []\n        e_means = []\n        e_errs = []\n        mag_means = []\n        mag_errs = []\n        sus_vals = []\n        sus_errs = []\n        s_heat_vals = []\n        s_heat_errs = []\n        \n        for f in files:\n            \n            data = np.load(f)\n            \n            try:\n                #extract temp value from filename (cheapskate method)\n                T = float(f.split(\"T\")[1].split(\"N\")[0])\n            except Exception as e:\n                print(f\"Error parsing temperature from {f}: {e}\")\n                continue\n            # Magnetisation calculations\n            mag = data['magnetisation']\n    \n            n_mag = len(mag)\n            m_mean = np.mean(mag)\n            m_std = np.std(mag, ddof=1)\n            m_err = m_std / np.sqrt(n_mag)\n            \n            m2 = np.mean(mag**2)\n            m4 = np.mean(mag**4)\n            \n            std_m2 = np.std(mag**2, ddof=1)\n            std_m4 = np.std(mag**4, ddof=1)\n            \n            err_m2 = std_m2 / np.sqrt(n_mag)\n            err_m4 = std_m4 / np.sqrt(n_mag)\n            \n            if m2 == 0:\n                continue\n            # Binder calculations\n            binder = 1 - m4 / (3 * m2**2)\n            binder_err = np.sqrt(((2 * m4 / (3 * m2**3)) * err_m2)**2 + ((1 / (3 * m2**2)) * err_m4)**2)\n            \n            #Energy calculations\n            e = data['energy']\n            n_e = len(e)\n            e_mean = np.mean(e)\n            e_std = np.std(e, ddof=1)\n            e_err = e_std / np.sqrt(n_e)\n            \n            #Susceptibility and specific heat calculations\n            beta = 1.0 / T\n            \n            sus_val = beta * (m2 - m_mean**2)\n            error_f = np.sqrt(err_m2**2 + (2 * m_mean * m_err)**2)\n            sus_err = beta * error_f\n            \n            e2 = np.mean(e**2)\n            std_e2 = np.std(e**2, ddof=1)\n            \n            e2_err = std_e2 / np.sqrt(n_e)\n            s_heat_val = beta**2 * (e2 - e_mean**2)\n            s_heat_err = beta**2 * np.sqrt(e2_err**2 + (2 * e_mean * e_err)**2)\n\n            #append all values to main lists\n            t_vals.append(T)\n            binder_vals.append(binder)\n            binder_errs.append(binder_err)\n            e_means.append(e_mean)\n            e_errs.append(e_err)\n            mag_means.append(m_mean)\n            mag_errs.append(m_err)\n            sus_vals.append(sus_val)\n            sus_errs.append(sus_err)\n            s_heat_vals.append(s_heat_val)\n            s_heat_errs.append(s_heat_err)\n            \n        #sorting index\n        sort_idx = np.argsort(t_vals)\n        \n        #save arrays to associated system size N file names \n        np.savez(analysis_file,\n                 t_vals=np.array(t_vals)[sort_idx],\n                 binder_vals=np.array(binder_vals)[sort_idx],\n                 binder_errs=np.array(binder_errs)[sort_idx],\n                 e_means=np.array(e_means)[sort_idx],\n                 e_errs=np.array(e_errs)[sort_idx],\n                 mag_means=np.array(mag_means)[sort_idx],\n                 mag_errs=np.array(mag_errs)[sort_idx],\n                 sus_vals=np.array(sus_vals)[sort_idx],\n                 sus_errs=np.array(sus_errs)[sort_idx],\n                 s_heat_vals=np.array(s_heat_vals)[sort_idx],\n                 s_heat_errs=np.array(s_heat_errs)[sort_idx])\n        \n        print(f\"Saved analysis for N={N} to {analysis_file}\")\n\ndef load_analysis(folder=\"data6\", sizes=[8, 16, 32]):\n    analysis_data = {}\n    for N in sizes:\n        filename = os.path.join(folder, f\"Analysis_N{N}.npz\")\n        if os.path.exists(filename):\n            data = np.load(filename)\n            analysis_data[N] = {\"t_vals\": data[\"t_vals\"],\n                              \"binder_vals\": data[\"binder_vals\"],\n                              \"binder_errs\": data[\"binder_errs\"],\n                              \"e_means\": data[\"e_means\"],\n                              \"e_errs\": data[\"e_errs\"],\n                              \"mag_means\": data[\"mag_means\"],\n                              \"mag_errs\": data[\"mag_errs\"],\n                              \"sus_vals\": data[\"sus_vals\"],\n                              \"sus_errs\": data[\"sus_errs\"],\n                              \"s_heat_vals\": data[\"s_heat_vals\"],\n                              \"s_heat_errs\": data[\"s_heat_errs\"]}\n        else:\n            print(f\"Binder file not found for N={N}.\")\n    return analysis_data\n\ndef plot_binder_values(analysis_data):\n    plt.figure(figsize=(8, 6))\n    for N, data in analysis_data.items():\n        plt.errorbar(data[\"t_vals\"], data[\"binder_vals\"], yerr=data[\"binder_errs\"],\n                     fmt='o', label=f\"N={N}\", ecolor='black', capsize=5, alpha=0.5)\n    plt.axvline(x=2.269, color='red', linestyle='--', label=\"Expected $T_c$ (2.269)\")\n    plt.xlabel(\"Temperature T\")\n    plt.ylabel(\"Binder Cumulant\")\n    plt.legend()\n    plt.grid(True)\n    plt.title(\"Binder Cumulant vs. Temperature\")\n    plt.show()\n\ndef build_splines(analysis_data, s=0):\n    splines = {}\n    for N, data in analysis_data.items():\n        T = data[\"t_vals\"]\n        binder = data[\"binder_vals\"]\n        spline = UnivariateSpline(T, binder, s=s)\n        binder_error = data[\"binder_errs\"]\n        error_spline = UnivariateSpline(T, binder_error, s=s)\n        splines[N] = {\"spline\": spline, \"error_spline\": error_spline}\n    return splines\n\ndef find_intersection(spline1, spline2, error_spline1, error_spline2, T_min, T_max, num_points=1000):\n    T_values = np.linspace(T_min, T_max, num_points)\n    diff = spline1(T_values) - spline2(T_values)\n    for i in range(len(diff) - 1):\n        if diff[i] * diff[i+1] < 0:\n            try:\n                Tc = brentq(lambda T: spline1(T) - spline2(T), T_values[i], T_values[i+1])\n                d_diff_dT = spline1.derivative()(Tc) - spline2.derivative()(Tc)\n                err1 = error_spline1(Tc)\n                err2 = error_spline2(Tc)\n                Tc_error = np.sqrt(err1**2 + err2**2) / np.abs(d_diff_dT) if d_diff_dT != 0 else np.inf\n                return Tc, Tc_error\n            except ValueError:\n                continue\n    return None, None\n\ndef calculate_all_intersections(analysis_data, s=0):\n    splines = build_splines(analysis_data, s=s)\n    intersection_dict = {}\n    sizes = sorted(analysis_data.keys())\n    for i in range(len(sizes)):\n        for j in range(i+1, len(sizes)):\n            N1 = sizes[i]\n            N2 = sizes[j]\n            T_min = max(np.min(analysis_data[N1][\"t_vals\"]), np.min(analysis_data[N2][\"t_vals\"]))\n            T_max = min(np.max(analysis_data[N1][\"t_vals\"]), np.max(analysis_data[N2][\"t_vals\"]))\n            Tc, Tc_error = find_intersection(splines[N1][\"spline\"], splines[N2][\"spline\"],\n                                             splines[N1][\"error_spline\"], splines[N2][\"error_spline\"],\n                                             T_min, T_max)\n            if Tc is not None:\n                intersection_dict[(N1, N2)] = (Tc, Tc_error)\n                print(f\"Intersection for N={N1} and N={N2}: Tc = {Tc:.4f} ± {Tc_error:.4f}\")\n            else:\n                print(f\"No intersection found for N={N1} and N={N2}.\")\n    return intersection_dict\n\n# def save_intersections(intersections, filename=\"critical_intersections.npz\"):\n#     intersections_to_save = {f\"{k[0]}_{k[1]}\": np.array(v) for k, v in intersections.items()}\n#     np.savez(filename, **intersections_to_save)\n#     print(f\"Saved intersections to {filename}\")\n\ndef calculate_critical_temperatures(analysis_data):\n    splines = build_splines(analysis_data)\n    reference_size = min(analysis_data.keys())\n    ref_spline = splines[reference_size][\"spline\"]\n    ref_error_spline = splines[reference_size][\"error_spline\"]\n    critical_temps = {}\n    for N, spline_data in splines.items():\n        if N == reference_size:\n            continue\n        T_min = max(np.min(analysis_data[reference_size][\"t_vals\"]), np.min(analysis_data[N][\"t_vals\"]))\n        T_max = min(np.max(analysis_data[reference_size][\"t_vals\"]), np.max(analysis_data[N][\"t_vals\"]))\n        Tc, Tc_error = find_intersection(ref_spline, spline_data[\"spline\"],\n                                         ref_error_spline, spline_data[\"error_spline\"],\n                                         T_min, T_max)\n        if Tc is not None:\n            critical_temps[N] = (Tc, Tc_error)\n            print(f\"Intersection for N={N} (ratio {N/reference_size:.2f}): Tc = {Tc:.4f} ± {Tc_error:.4f}\")\n        else:\n            print(f\"No intersection found for N={N}.\")\n    return critical_temps, reference_size\n\ndef plot_all_intersections(analysis_data, intersections, zoom_margin=0.005, custom_T_low=None, custom_T_high=None):\n    splines = build_splines(analysis_data)\n    if custom_T_low is not None and custom_T_high is not None:\n        T_low, T_high = custom_T_low, custom_T_high\n    else:\n        if intersections:\n            Tc_values = [val[0] for val in intersections.values()]\n            T_low = min(Tc_values) - zoom_margin\n            T_high = max(Tc_values) + zoom_margin\n        else:\n            T_low, T_high = 2.25, 2.29\n    T_fine = np.linspace(T_low, T_high, 1000)\n    plt.figure(figsize=(8, 6))\n    for N, spline_data in splines.items():\n        spline = spline_data[\"spline\"]\n        plt.plot(T_fine, spline(T_fine), label=f\"N={N}\")\n        data = analysis_data[N]\n        mask = (data[\"t_vals\"] >= T_low) & (data[\"t_vals\"] <= T_high)\n        plt.errorbar(np.array(data[\"t_vals\"])[mask], np.array(data[\"binder_vals\"])[mask],\n                     yerr=np.array(data[\"binder_errs\"])[mask], fmt='o', markersize=4,\n                     ecolor='black', capsize=5, alpha=0.5)\n    for (N1, N2), (Tc, Tc_error) in intersections.items():\n        binder_val = splines[N1][\"spline\"](Tc)\n        plt.errorbar(Tc, binder_val, yerr=Tc_error, fmt='ko', markersize=8,\n                     ecolor='black', capsize=5, alpha=0.5)\n        plt.text(Tc, binder_val, f\" {Tc:.3f}±{Tc_error:.3f}\", fontsize=9, color='black')\n        plt.axvline(x=Tc, color='gray', linestyle='--', linewidth=0.5)\n    if T_low <= 2.269 <= T_high:\n        plt.axvline(x=2.269, color='red', linestyle='--', label=\"Expected $T_c$ (2.269)\")\n    plt.xlabel(\"Temperature T\")\n    plt.ylabel(\"Binder Cumulant\")\n    plt.title(\"Zoomed-Out View: Binder Curve Intersections\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_critical_temperatures(critical_temps, reference_size):\n    ratios = [N / reference_size for N in critical_temps.keys()]\n    Tc_values = [val[0] for val in critical_temps.values()]\n    Tc_errors = [val[1] for val in critical_temps.values()]\n    plt.figure(figsize=(8, 6))\n    plt.errorbar(ratios, Tc_values, yerr=Tc_errors, fmt='o', color='blue', label=\"Estimated $T_c$\",\n                 ecolor='black', capsize=5, alpha=0.5)\n    plt.axhline(y=2.269, color='red', linestyle='--', label=\"Expected $T_c$ (2.269)\")\n    plt.xlabel(\"System Size Ratio ($N / N_{small}$)\")\n    plt.ylabel(\"Critical Temperature $T_c$\")\n    plt.title(\"Critical Temperature vs. System Size\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef load_observables(input_folder=\"data6\", sizes=[8, 16, 32]):\n    observables_data = {}\n    for N in sizes:\n        binder_file = os.path.join(input_folder, f\"Analysis_N{N}.npz\")\n        if os.path.exists(binder_file):\n            data = np.load(binder_file)\n            observables_data[N] = {\n                \"t_vals\": data[\"t_vals\"],\n                \"e_means\": data[\"e_means\"],\n                \"e_errs\": data[\"e_errs\"],\n                \"mag_means\": data[\"mag_means\"],\n                \"mag_errs\": data[\"mag_errs\"],\n                \"sus_vals\": data[\"sus_vals\"],\n                \"sus_errs\": data[\"sus_errs\"],\n                \"s_heat_vals\": data[\"s_heat_vals\"],\n                \"s_heat_errs\": data[\"s_heat_errs\"]\n            }\n        else:\n            print(f\"Binder file not found for N={N}.\")\n    return observables_data\n\ndef plot_observables(observables_data):\n    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n    ax = axs[0, 0]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"e_means\"], yerr=data[\"e_errs\"],\n                    fmt='o', label=f\"N={N}\", ecolor='black', capsize=5, alpha=0.5)\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Energy\")\n    ax.set_title(\"Energy vs Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[0, 1]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"mag_means\"], yerr=data[\"mag_errs\"],\n                    fmt='o', label=f\"N={N}\", ecolor='black', capsize=5, alpha=0.5)\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Magnetisation\")\n    ax.set_title(\"Magnetisation vs Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[1, 0]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"sus_vals\"], yerr=data[\"sus_errs\"],\n                    fmt='o', label=f\"N={N}\", ecolor='black', capsize=5, alpha=0.5)\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Susceptibility\")\n    ax.set_title(\"Susceptibility vs Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[1, 1]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"s_heat_vals\"], yerr=data[\"s_heat_errs\"],\n                    fmt='o', label=f\"N={N}\", ecolor='black', capsize=5, alpha=0.5)\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Specific Heat\")\n    ax.set_title(\"Specific Heat vs Temperature\")\n    ax.legend()\n    ax.grid(True)\n    plt.tight_layout()\n    plt.show()\n\ndef plot_loglog_observables(observables_data, intersections, cutoff=1e-3):\n    # if intersections:\n        # Tc_avg = np.mean([val[0] for val in intersections.values()])\n    # else:\n    Tc_avg = 4.5\n    obs_keys = {\"energy\": \"e_means\",\n                \"magnetisation\": \"mag_means\",\n                \"susceptibility\": \"sus_vals\",\n                \"specific_heat\": \"s_heat_vals\"}\n    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n    axs = axs.flatten()\n    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n    for i, obs in enumerate(obs_keys.keys()):\n        ax = axs[i]\n        side = \"above\" if obs in [\"energy\", \"susceptibility\", \"specific_heat\"] else \"below\"\n        for j, N in enumerate(sorted(observables_data.keys())):\n            data = observables_data[N]\n            T = data[\"t_vals\"]\n            y = data[obs_keys[obs]]\n            if obs in [\"energy\", \"magnetisation\"]:\n                y = np.abs(y)\n            x = T - Tc_avg if side == \"above\" else Tc_avg - T\n            mask = x > cutoff\n            x, y = x[mask], y[mask]\n            if len(x) < 2:\n                continue\n            color = colors[j % len(colors)]\n            ax.errorbar(x, y, fmt='o', color=color, label=f\"N={N}\",\n                        ecolor='black', capsize=5, alpha=0.5)\n            logx, logy = np.log(x), np.log(y)\n            p, cov = np.polyfit(logx, logy, 1, cov=True)\n            slope, intercept = p\n            slope_error = np.sqrt(cov[0, 0])\n            x_fit = np.linspace(np.min(x), np.max(x), 100)\n            y_fit = np.exp(intercept) * x_fit**slope\n            ax.plot(x_fit, y_fit, '--', color=color,\n                    label=f\"N={N} fit: {slope:.3f}±{slope_error:.3f}\")\n            ax.text(np.median(x), np.median(y_fit), f\"{slope:.3f}±{slope_error:.3f}\",\n                    color=color, fontsize=9, bbox=dict(facecolor='white', alpha=0.5))\n        ax.set_xscale('log')\n        ax.set_yscale('log')\n        xlabel = r\"$T-T_c$\" if side == \"above\" else r\"$T_c-T$\"\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(obs.capitalize())\n        ax.set_title(f\"Log-Log Plot of {obs.capitalize()}\")\n        ax.legend(fontsize='small')\n        ax.grid(True, which='both', ls='--')\n    plt.suptitle(f\"Log-Log Plots Translated by $T_c$ (Average $T_c$ = {Tc_avg:.3f})\", fontsize=16)\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.show()\n\ndef plot_observable_errors(observables_data):\n    err_keys = {\"energy\": \"e_errs\",\n                \"magnetisation\": \"mag_errs\",\n                \"susceptibility\": \"sus_errs\",\n                \"specific_heat\": \"s_heat_errs\"}\n    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n    ax = axs[0, 0]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"energy\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Energy Error\")\n    ax.set_title(\"Energy Error vs. Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[0, 1]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"magnetisation\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Magnetisation Error\")\n    ax.set_title(\"Magnetisation Error vs. Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[1, 0]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"susceptibility\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Susceptibility Error\")\n    ax.set_title(\"Susceptibility Error vs. Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[1, 1]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"specific_heat\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Specific Heat Error\")\n    ax.set_title(\"Specific Heat Error vs. Temperature\")\n    ax.legend()\n    ax.grid(True)\n    plt.tight_layout()\n    plt.show()\n\nif __name__ == \"__main__\":\n    folder = \"data10\"\n    params_filepath = os.path.join(folder, \"simulation_parameters.npz\")\n    if os.path.exists(params_filepath):\n        params = np.load(params_filepath)\n        nt = int(params[\"nt\"])\n        n_list = params[\"n_list\"].tolist()\n        eqSteps = int(params[\"eqSteps\"])\n        mcSteps = int(params[\"mcSteps\"])\n        T_arr = params[\"T_arr\"]\n        print(\"Loaded Simulation Parameters:\")\n        print(\"nt       =\", nt)\n        print(\"n_list   =\", n_list)\n        print(\"eqSteps  =\", eqSteps)\n        print(\"mcSteps  =\", mcSteps)\n\n    else:\n        print(f\"Simulation parameters file not found in {folder}. Using default sizes.\")\n        n_list = [8, 16, 32]\n    compute_analysis(input_folder=folder, output_folder=folder, sizes=n_list)\n    analysis_data = load_analysis(folder=folder, sizes=n_list)\n    plot_binder_values(analysis_data)\n    intersections = calculate_all_intersections(analysis_data)\n    # save_intersections(intersections, filename=\"critical_intersections.npz\")\n    plot_all_intersections(analysis_data, intersections, zoom_margin=0.005, custom_T_low=3.5, custom_T_high=4.5)\n    critical_temps, ref_size = calculate_critical_temperatures(analysis_data)\n    plot_critical_temperatures(critical_temps, ref_size)\n    observables_data = load_observables(input_folder=folder, sizes=n_list)\n    plot_observables(observables_data)\n    plot_loglog_observables(observables_data, intersections, cutoff=1e-1)\n    plot_observable_errors(observables_data)\n```\n:::\n\n\n",
    "supporting": [
      "analysis_text_files\\figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}