[
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "Week 6",
    "section": "",
    "text": "- Narrative\n    -what is the ising model?\n        - \n    -why is it interesting\n        -phase transition as temperature varied - spontaneous change\n            - what is phase transition\n                - order parameter\n            - what is second order phase transition\n            - critical temperature\n                - universality near critical temp\n            -critical exponents\n    - quantitative explanation of above\n    - Ising model\n        - Hamiltonian\n        - Partition function\n        - Observables ---&gt; derivations\n    - Methods\n        - Observables...\n        - Metropolis\n        - Cluster Algorithm\n        - Binder Cumulant - Critical Temp\n        - Critical Exponents\n    - Results\n        - Magnetisation vs iteration (wolfs vs metropolis)\n        - Binder cumulant \n        - Critical Exponents\n            - magnetisation\n            - susceplitibility\n            - specific temperature\n            - correlation function\n    - Conclusion\n\n\n\n- refining plan and researching literature\n- General \n    - Monte Carlo [Binder textbook](https://www.eng.uc.edu/~beaucag/Classes/AdvancedMaterialsThermodynamics/Books/David%20P.%20Landau,%20Kurt%20Binder%20-%20A%20Guide%20to%20Monte%20Carlo%20Simulations%20in%20Statistical%20Physics%20(2014,%20Cambridge%20University%20Press)%20-%20libgen.lc.pdf)\n    - ising model concerned with the physics of phase transitions\n    - phase transitions occur when a small change in a physical parameter causes a large scale change in the system\n        - water freezing at certain temperature\n        - spontaneous magnetisation - Ising model original purpose \n    - ising model seeks to describe how short range behaviour gives rise to large scale behaviour\n        - general mathematical model for this concept\n            - universality near critical temperature \n- Ising Model\n    - to investigate behaviour will approach it in the context of ferromagnetism and the mathematics of statistical Mechanics\n    - site has spin up or down\n    - Hamiltonian\n        - measures energy of whole system, assumes only nearest-neighbour interaction contribute to energy\n    -Partition function\n        - 1d mean field theory\n        - Observables --&gt; critical exponents\n    - 2^N calculation motivate statisctical maethods below\n- Methods\n    - Monte Carlo\n    - Metropolis\n    - Cluster algorithm\n    - Binder parameter --&gt; critical temperature\n    - use critical temperature to get critical exponents\n- Results\n    - Magnetisation graph (with analytical) and algorithm speed up \n    - phase diagram mag suc vs vs temp \n    - Binder cumulant and critical temperature comparison \n    - Critical exponents 2d and 3d\n        - multi-graph?\n    - errors\n- Conclusion\n      ;",
    "crumbs": [
      "Week 6"
    ]
  },
  {
    "objectID": "week6.html#morning-meeting",
    "href": "week6.html#morning-meeting",
    "title": "Week 6",
    "section": "",
    "text": "- Narrative\n    -what is the ising model?\n        - \n    -why is it interesting\n        -phase transition as temperature varied - spontaneous change\n            - what is phase transition\n                - order parameter\n            - what is second order phase transition\n            - critical temperature\n                - universality near critical temp\n            -critical exponents\n    - quantitative explanation of above\n    - Ising model\n        - Hamiltonian\n        - Partition function\n        - Observables ---&gt; derivations\n    - Methods\n        - Observables...\n        - Metropolis\n        - Cluster Algorithm\n        - Binder Cumulant - Critical Temp\n        - Critical Exponents\n    - Results\n        - Magnetisation vs iteration (wolfs vs metropolis)\n        - Binder cumulant \n        - Critical Exponents\n            - magnetisation\n            - susceplitibility\n            - specific temperature\n            - correlation function\n    - Conclusion",
    "crumbs": [
      "Week 6"
    ]
  },
  {
    "objectID": "week6.html#research-and-writing",
    "href": "week6.html#research-and-writing",
    "title": "Week 6",
    "section": "",
    "text": "- refining plan and researching literature\n- General \n    - Monte Carlo [Binder textbook](https://www.eng.uc.edu/~beaucag/Classes/AdvancedMaterialsThermodynamics/Books/David%20P.%20Landau,%20Kurt%20Binder%20-%20A%20Guide%20to%20Monte%20Carlo%20Simulations%20in%20Statistical%20Physics%20(2014,%20Cambridge%20University%20Press)%20-%20libgen.lc.pdf)\n    - ising model concerned with the physics of phase transitions\n    - phase transitions occur when a small change in a physical parameter causes a large scale change in the system\n        - water freezing at certain temperature\n        - spontaneous magnetisation - Ising model original purpose \n    - ising model seeks to describe how short range behaviour gives rise to large scale behaviour\n        - general mathematical model for this concept\n            - universality near critical temperature \n- Ising Model\n    - to investigate behaviour will approach it in the context of ferromagnetism and the mathematics of statistical Mechanics\n    - site has spin up or down\n    - Hamiltonian\n        - measures energy of whole system, assumes only nearest-neighbour interaction contribute to energy\n    -Partition function\n        - 1d mean field theory\n        - Observables --&gt; critical exponents\n    - 2^N calculation motivate statisctical maethods below\n- Methods\n    - Monte Carlo\n    - Metropolis\n    - Cluster algorithm\n    - Binder parameter --&gt; critical temperature\n    - use critical temperature to get critical exponents\n- Results\n    - Magnetisation graph (with analytical) and algorithm speed up \n    - phase diagram mag suc vs vs temp \n    - Binder cumulant and critical temperature comparison \n    - Critical exponents 2d and 3d\n        - multi-graph?\n    - errors\n- Conclusion\n      ;",
    "crumbs": [
      "Week 6"
    ]
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "Week 4",
    "section": "",
    "text": "- talked about finding errors \n- quick check on the right direction\n\n\n\n- function to import data in format for plotting/calculation\n- binder function that calculates the intersections between interpolating functions\n- plotting function that zooms in near the intersection and adds the binder intersections\n- plotting function that takes binder intersection temperatures and plots them with their associated system size ratio \n- critical exponents log-log graphs\n- configure the code generation for susceplitibility and heat capacity",
    "crumbs": [
      "Week 4"
    ]
  },
  {
    "objectID": "week4.html#morning-meeting",
    "href": "week4.html#morning-meeting",
    "title": "Week 4",
    "section": "",
    "text": "- talked about finding errors \n- quick check on the right direction",
    "crumbs": [
      "Week 4"
    ]
  },
  {
    "objectID": "week4.html#coding-plan",
    "href": "week4.html#coding-plan",
    "title": "Week 4",
    "section": "",
    "text": "- function to import data in format for plotting/calculation\n- binder function that calculates the intersections between interpolating functions\n- plotting function that zooms in near the intersection and adds the binder intersections\n- plotting function that takes binder intersection temperatures and plots them with their associated system size ratio \n- critical exponents log-log graphs\n- configure the code generation for susceplitibility and heat capacity",
    "crumbs": [
      "Week 4"
    ]
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "Week 2",
    "section": "",
    "text": "Critical exponents\n\ncritical behaviour relates to what happens around the critical temperature\ncritical exponent defines how a certain parameter grows around the critical temperature to first order in exponent\n\nDid exercies calculating theoretical critical exponnets for spin moment (β) and susceplitibility (γ) with and without field and the exponent for changing magnetic field (δ) with constant critical temperature\nScaling relations\n\ncritical exponents can have relations to one another, α + 2β + γ = 2, γ = β(δ − 1)\n\nScale -althought a mean field theory, seems to be more mathematically exact with higher dimensionality\nUsed in calculating/understanding critical exponents\n\nEdinburgh notes on mean field theory - Ising model\nStatistical Mechanics of phase transitions\n\n\n\n\n\n- Running time calibration\n    - Running time as function of size of the box\n    - Running time as function of total MC steps\n- deviations of numerically calulcated magnetisation from analytical solution (SEE [wikipedia: Exact_solution](https://en.wikipedia.org/wiki/Square_lattice_Ising_model#Exact_solution))\n- Critical exponents\n    - good experimental work on finding critical exponents using monte carlo methods\n    - find for higher dimensions\n- Later Ideas  \n    - Universality\n    - Renormalisation group",
    "crumbs": [
      "Week 2"
    ]
  },
  {
    "objectID": "week2.html#pdf-session-2",
    "href": "week2.html#pdf-session-2",
    "title": "Week 2",
    "section": "",
    "text": "Critical exponents\n\ncritical behaviour relates to what happens around the critical temperature\ncritical exponent defines how a certain parameter grows around the critical temperature to first order in exponent\n\nDid exercies calculating theoretical critical exponnets for spin moment (β) and susceplitibility (γ) with and without field and the exponent for changing magnetic field (δ) with constant critical temperature\nScaling relations\n\ncritical exponents can have relations to one another, α + 2β + γ = 2, γ = β(δ − 1)\n\nScale -althought a mean field theory, seems to be more mathematically exact with higher dimensionality\nUsed in calculating/understanding critical exponents\n\nEdinburgh notes on mean field theory - Ising model\nStatistical Mechanics of phase transitions",
    "crumbs": [
      "Week 2"
    ]
  },
  {
    "objectID": "week2.html#ideas-for-how-to-orient-project",
    "href": "week2.html#ideas-for-how-to-orient-project",
    "title": "Week 2",
    "section": "",
    "text": "- Running time calibration\n    - Running time as function of size of the box\n    - Running time as function of total MC steps\n- deviations of numerically calulcated magnetisation from analytical solution (SEE [wikipedia: Exact_solution](https://en.wikipedia.org/wiki/Square_lattice_Ising_model#Exact_solution))\n- Critical exponents\n    - good experimental work on finding critical exponents using monte carlo methods\n    - find for higher dimensions\n- Later Ideas  \n    - Universality\n    - Renormalisation group",
    "crumbs": [
      "Week 2"
    ]
  },
  {
    "objectID": "main_code_text.html",
    "href": "main_code_text.html",
    "title": "Main Code",
    "section": "",
    "text": "# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Feb 27 13:05:14 2025\n\n@author: gianc\n\"\"\"\n\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nfrom __future__ import division\nimport numpy as np\nfrom numba import njit\nimport math\nimport os\nimport multiprocessing as mp\nfrom functools import partial\n\n\n# Initialise state\ndef initialstate(N, dim, model, T):\n    \"\"\"\n    Generates a spin configuration.\n    For T &lt; Tc, we initialize in an ordered state to reduce equilibration time.\n    For T &gt; Tc, we initialize in a random state for faster exploration.\n    \"\"\"\n    if model == 'ising':\n        # For Ising model, use ordered state (all +1) for T &lt; 2.0, random state otherwise\n        # This helps with equilibration\n        if T &lt; 2.0:  # Below critical temperature\n            if dim == 2:\n                return np.ones((N, N), dtype=np.int8)\n            elif dim == 3:\n                return np.ones((N, N, N), dtype=np.int8)\n        else:  # Above critical temperature\n            if dim == 2:\n                return 2 * np.random.randint(0, 2, size=(N, N), dtype=np.int8) - 1\n            elif dim == 3:\n                return 2 * np.random.randint(0, 2, size=(N, N, N), dtype=np.int8) - 1\n    else:\n        raise ValueError(\"Model must be 'ising'\")\n\n# Metropolis Algorithms\n@njit\ndef mcmove2d(config, beta, N, model, delta):\n    \"\"\"\n    One sweep of local Metropolis moves on a 2D lattice.\n    model: 0=ising, 1=xy, 2=heisenberg.\n    \"\"\"\n    num_moves = N * N\n    for k in range(num_moves):\n        i = np.random.randint(0, N)\n        j = np.random.randint(0, N)\n        r = np.random.random()\n        if model == 0:\n            s = config[i, j]\n            nb = (config[(i+1)%N, j] + config[(i-1)%N, j] +\n                  config[i, (j+1)%N] + config[i, (j-1)%N])\n            cost = 2 * s * nb\n            if cost &lt; 0 or r &lt; math.exp(-beta * cost):\n                config[i, j] = -s\n    return config\n\n@njit\ndef mcmove3d(config, beta, N, model, delta):\n    \"\"\"\n    One sweep of local Metropolis moves on a 3D lattice.\n    \"\"\"\n    num_moves = N * N * N\n    for k in range(num_moves):\n        x = np.random.randint(0, N)\n        y = np.random.randint(0, N)\n        z = np.random.randint(0, N)\n        r = np.random.random()\n        if model == 0:\n            s = config[x, y, z]\n            nb = (config[(x+1)%N, y, z] + config[(x-1)%N, y, z] +\n                  config[x, (y+1)%N, z] + config[x, (y-1)%N, z] +\n                  config[x, y, (z+1)%N] + config[x, y, (z-1)%N])\n            cost = 2 * s * nb\n            if cost &lt; 0 or r &lt; math.exp(-beta * cost):\n                config[x, y, z] = -s\n    return config\n\n# Wolf Cluster Algorithms 2D\n@njit\ndef wolff_update_2d_ising(config, beta, N):\n    \"\"\"\n    Wolff cluster update for 2D Ising model.\n    The implementation creates and flips a single cluster.\n    \"\"\"\n    # Handle the T=0 case explicitly to avoid division by zero\n    if beta &gt; 1e6:  # For very low temperatures\n        return config  # At T=0, no spins flip\n    \n    # Create array to store sites to be flipped (cluster membership)\n    cluster = np.zeros((N, N), dtype=np.int8)\n    \n    # Create stack to store site coordinates to be searched\n    stack = np.empty((N*N, 2), dtype=np.int64)\n    # Pointer for number of sites left to search\n    stack_ptr = 0\n    \n    # Pick a random site \n    i = np.random.randint(0, N)\n    j = np.random.randint(0, N)\n    \n    # Get the original spin value\n    s0 = config[i, j]\n    \n    # Flip the seed spin\n    config[i, j] = -s0\n    \n    # Mark as part of cluster and add to stack\n    cluster[i, j] = 1\n    stack[0, 0] = i\n    stack[0, 1] = j\n    stack_ptr = 1\n    \n    # Probability of adding a neighbor to the cluster\n    p_add = 1.0 - math.exp(-2.0 * beta)\n\n    # Grow the cluster\n    while stack_ptr &gt; 0:\n        stack_ptr -= 1\n        # Retrieve next site coordinates\n        i = stack[stack_ptr, 0]\n        j = stack[stack_ptr, 1]\n        \n        # For each neighbor:\n        for di, dj in ((1,0), (-1,0), (0,1), (0,-1)):\n            ni = (i + di) % N\n            nj = (j + dj) % N\n            \n            # If neighbor is not yet in the cluster and has the same spin as the original seed:\n            if cluster[ni, nj] == 0 and config[ni, nj] == s0:\n                # Add neighbor with probability p_add\n                if np.random.random() &lt; p_add:\n                    # Flip the neighbor to the opposite of the seed\n                    config[ni, nj] = -s0\n                    \n                    # Mark as part of cluster and add to stack\n                    cluster[ni, nj] = 1\n                    stack[stack_ptr, 0] = ni\n                    stack[stack_ptr, 1] = nj\n                    stack_ptr += 1\n                    \n    return config\n\n# 3D Cluster Updates\n@njit\ndef wolff_update_3d_ising(config, beta, N):\n    \"\"\"\n    Wolff cluster update for 3D Ising model.\n    \"\"\"\n    # Handle the T=0 case explicitly to avoid division by zero\n    if beta &gt; 1e6:  # For very low temperatures\n        return config  # At T=0, no spins flip\n    \n    # Create array to store sites to be flipped (cluster membership)\n    cluster = np.zeros((N, N, N), dtype=np.int8)\n    \n    # Create stack to store site coordinates to be searched\n    stack = np.empty((N*N*N, 3), dtype=np.int64)\n    stack_ptr = 0\n    \n    # Pick a random site\n    x = np.random.randint(0, N)\n    y = np.random.randint(0, N)\n    z = np.random.randint(0, N)\n    \n    # Get the original spin value\n    s0 = config[x, y, z]\n    \n    # Flip the seed spin\n    config[x, y, z] = -s0\n    \n    # Mark seed as in the cluster and add to stack\n    cluster[x, y, z] = 1\n    stack[0, 0] = x\n    stack[0, 1] = y\n    stack[0, 2] = z\n    stack_ptr = 1\n    \n    # Probability of adding a neighbor to the cluster\n    p_add = 1.0 - math.exp(-2.0 * beta)\n    \n    # Grow the cluster\n    while stack_ptr &gt; 0:\n        stack_ptr -= 1\n        x = stack[stack_ptr, 0]\n        y = stack[stack_ptr, 1]\n        z = stack[stack_ptr, 2]\n        \n        # Iterate over the six nearest neighbors in 3D\n        for dx, dy, dz in ((1,0,0), (-1,0,0), (0,1,0), (0,-1,0), (0,0,1), (0,0,-1)):\n            nx = (x + dx) % N\n            ny = (y + dy) % N\n            nz = (z + dz) % N\n            \n            # If neighbor is not yet in cluster and has same spin as original seed\n            if cluster[nx, ny, nz] == 0 and config[nx, ny, nz] == s0:\n                if np.random.random() &lt; p_add:\n                    # Flip neighbor to opposite of seed\n                    config[nx, ny, nz] = -s0\n                    \n                    # Mark as part of cluster and add to stack\n                    cluster[nx, ny, nz] = 1\n                    stack[stack_ptr, 0] = nx\n                    stack[stack_ptr, 1] = ny\n                    stack[stack_ptr, 2] = nz\n                    stack_ptr += 1\n                    \n    return config\n\n@njit\ndef wolff_update_2d(config, beta, N, model):\n    if model == 0:\n        return wolff_update_2d_ising(config, beta, N)\n    \n@njit\ndef wolff_update_3d(config, beta, N, model):\n    if model == 0:\n        return wolff_update_3d_ising(config, beta, N)\n\n\n\n#measurements\n\n\n@njit\ndef measure2d_all(config, N, model):\n    \"\"\"\n    Measures energy, magnetization, and correlation function for 2D lattice.\n    Returns the raw values - normalization happens later.\n    \"\"\"\n    R = N // 2\n    energy = 0.0\n    if model == 0:\n        mag = 0.0\n        corr = np.zeros(R+1, dtype=np.float64)\n        # Loop over all lattice sites once.\n        for i in range(N):\n            for j in range(N):\n                S = config[i, j]\n                # Energy from right and down neighbors (periodic BCs)\n                energy += -S * (config[i, (j+1)%N] + config[(i+1)%N, j])\n                mag += S\n                # Update correlation for displacements r along the i-direction.\n                for r in range(R+1):\n                    corr[r] += S * config[(i+r)%N, j]\n        # Normalize correlation (each r gets N*N contributions)\n        norm = N * N\n        for r in range(R+1):\n            corr[r] /= norm\n        return energy, mag, corr\n\n@njit\ndef measure3d_all(config, N, model):\n    \"\"\"\n    Measures energy, magnetization, and correlation function for 3D lattice.\n    \"\"\"\n    R = N // 2\n    energy = 0.0\n    if model == 0:\n        mag = 0.0\n        corr = np.zeros(R+1, dtype=np.float64)\n        for x in range(N):\n            for y in range(N):\n                for z in range(N):\n                    S = config[x, y, z]\n                    energy += -S * (config[(x+1)%N, y, z] +\n                                    config[x, (y+1)%N, z] +\n                                    config[x, y, (z+1)%N])\n                    mag += S\n                    # Correlation along the x-direction (for each displacement r)\n                    for r in range(R+1):\n                        corr[r] += S * config[(x+r)%N, y, z]\n        norm = N * N * N\n        for r in range(R+1):\n            corr[r] /= norm\n        return energy, mag, corr\n\n@njit\ndef compute_connected_correlation(corr, mag, N, dim):\n    \"\"\"\n    Converts raw correlation to connected correlation function.\n    C_conn(r) = &lt;S(0)S(r)&gt; - &lt;S&gt;²\n    \"\"\"\n    R = len(corr) - 1\n    m_squared = (mag / (N**dim))**2\n    connected_corr = np.zeros_like(corr)\n    \n    for r in range(R+1):\n        connected_corr[r] = corr[r] - m_squared\n        \n    return connected_corr\n\n\n#SIMULATION\n\n\ndef run_simulation(config, beta, eqSteps, mcSteps, N, dim, model, delta, update_type):\n    \"\"\"\n    Runs equilibration then measurement sweeps with adaptive cluster update count.\n    \"\"\"\n    # Convert model to numeric code: 0=ising\n    if model == 'ising':\n        mcode = 0\n    else:\n        raise ValueError(\"Unknown model\")\n    \n\n    # Equilibration:\n    for _ in range(eqSteps):\n        if update_type == 'local':\n            if dim == 2:\n                mcmove2d(config, beta, N, mcode, delta)\n            else:\n                mcmove3d(config, beta, N, mcode, delta)\n        elif update_type == 'cluster':\n\n            if dim == 2:\n                wolff_update_2d(config, beta, N, mcode)\n            else:\n                wolff_update_3d(config, beta, N, mcode)\n    \n    # Measurement:\n    m_i = np.empty(mcSteps, dtype=np.float64)\n    e_i = np.empty(mcSteps, dtype=np.float64)\n    R = N // 2\n    corr_sum = np.zeros(R+1, dtype=np.float64)\n    \n    for i in range(mcSteps):\n        if update_type == 'local':\n            if dim == 2:\n                mcmove2d(config, beta, N, mcode, delta)\n            else:\n                mcmove3d(config, beta, N, mcode, delta)\n        elif update_type == 'cluster':\n            \n\n            if dim == 2:\n                wolff_update_2d(config, beta, N, mcode)\n            else:\n                wolff_update_3d(config, beta, N, mcode)\n        \n        if dim == 2:\n            e, m, corr = measure2d_all(config, N, mcode)\n        else:\n            e, m, corr = measure3d_all(config, N, mcode)\n        \n        e_i[i] = e\n        m_i[i] = m\n        corr_sum += corr\n    \n    corr_avg = corr_sum / mcSteps\n    \n\n    avg_mag = np.mean(m_i)\n    connected_corr = compute_connected_correlation(corr_avg, avg_mag, N, dim)\n    \n    return m_i, e_i, corr_avg, connected_corr\n\n\n\n# multiprocessor wrapper\n\ndef simulate_temp(args, output_folder, dim, model, delta, update_type):\n    \"\"\"\n    Runs simulation for given N and T_value and saves data.\n    \"\"\"\n    N, T_value, eqSteps, mcSteps = args\n    \n    # Handle T=0 case\n    if T_value &lt; 0.01:\n        T_value = 0.01  # Prevent division by zero\n    \n    beta = 1.0 / T_value\n    \n    # Smart initialization based on temperature\n    config = initialstate(N, dim, model, T_value)\n\n    m_i, e_i, corr_avg, connected_corr = run_simulation(config, beta, eqSteps, mcSteps, N, dim, model, delta, update_type)\n\n \n    filename = os.path.join(output_folder, f\"run-T{T_value:.3f}N{N}D{dim}-{model}-{update_type}.npz\")\n    np.savez(filename,\n             energy=e_i,\n             magnetisation=m_i,\n             correlation=corr_avg,\n             connected_correlation=connected_corr,)\n    \n    return T_value, N, m_i, e_i, corr_avg\n\n\n\n\n# MAIN LOOP\n\n\n\ndef create_data(output_folder, nt, n_list, eqSteps, mcSteps, T_arr, dim, model, delta, update_type):\n    if os.path.exists(output_folder):\n        print(f\"Folder '{output_folder}' already exists.\")\n    else:\n        os.makedirs(output_folder)\n    \n\n    T_arr = np.copy(T_arr)\n    T_arr[T_arr &lt; 0.01] = 0.01\n    \n    params_filepath = os.path.join(output_folder, \"simulation_parameters.npz\")\n    np.savez(params_filepath,\n             nt=nt,\n             n_list=np.array(n_list),\n             eqSteps=eqSteps,\n             mcSteps=mcSteps,\n             T_arr=T_arr,\n             dim=dim,\n             model=model,\n             delta=delta,\n             update_type=update_type)\n    print(f\"Simulation parameters saved to {params_filepath}\")\n    \n    \n    Tc = 2.269 if dim == 2 else 4.51\n    critical_tasks = []\n    normal_tasks = []\n    \n    for N in n_list:\n        for T_val in T_arr:\n            if abs(T_val - Tc) &lt; 0.5:\n                critical_tasks.append((N, T_val, eqSteps, mcSteps))\n            else:\n                normal_tasks.append((N, T_val, eqSteps, mcSteps))\n    \n    all_tasks = critical_tasks + normal_tasks\n    total_tasks = len(all_tasks)\n    completed_tasks = 0\n    \n    # Increase number of processes based on available CPU cores\n    num_processes = mp.cpu_count()\n    print(f\"Using {num_processes} CPU cores for parallel processing\")\n    \n    pool = mp.Pool(processes=8)\n    sim_func = partial(simulate_temp, output_folder=output_folder, dim=dim, model=model, delta=delta, update_type=update_type)\n    \n    for result in pool.imap_unordered(sim_func, all_tasks):\n        completed_tasks += 1\n        print(f\"Progress: {completed_tasks}/{total_tasks} simulations completed.\")\n    \n    pool.close()\n    pool.join()\n\n\n\n# ==========================================================\n# MAIN EXECUTION\n# ==========================================================\nif __name__ == '__main__':\n    output_folder = \"metropolis1\"\n\n    nt          = 1                    # Number of temperature points (reduced for efficiency)\n    n_list      = [32]      # Lattice sizes\n    eqSteps     = 1024 * 100             # Equilibration sweeps (reduced)\n    mcSteps     = 1024 * 100            # Measurement sweeps (reduced)\n    \n    # Focus more points near the critical temperature\n    # T_low = np.linspace(0.5, 1.8, nt//4)\n    # T_crit = np.linspace(1.9, 2.6, nt//2)  # More points near critical point\n    # T_high = np.linspace(2.7, 4.0, nt//4)\n    # T_arr = np.concatenate([T_low, T_crit, T_high])\n    \n    #T_arr = np.linspace(2.1, 2.5, nt)\n    T_arr = [2.275]\n    \n    dim         = 2                       # 2 or 3\n    model       = 'ising'                 # 'ising', 'xy', or 'heisenberg'\n    delta       = 0.3                     # For local moves (not used in cluster)\n    update_type = 'local'               # Choose 'local' or 'cluster'\n    \n    create_data(output_folder, nt, n_list, eqSteps, mcSteps, T_arr, dim, model, delta, update_type)",
    "crumbs": [
      "Main Code",
      "Main Code"
    ]
  },
  {
    "objectID": "analysis_text.html",
    "href": "analysis_text.html",
    "title": "Analysis Code",
    "section": "",
    "text": "# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Wed Feb 26 14:14:04 2025\n\n@author: gianc\n\"\"\"\n\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\nimport natsort\nimport os\nfrom scipy.interpolate import UnivariateSpline\nfrom scipy.optimize import brentq\nimport matplotlib as mpl\nfrom mpl_toolkits.axes_grid1.inset_locator import inset_axes\n\n\n\ndef compute_analysis(input_folder, output_folder, sizes, dim=2):\n    \"\"\"\n    Compute and save analysis for each system size.\n    This function averages observables (energy, magnetisation, Binder cumulant, etc.)\n    over simulation runs at each temperature, storing them in per–spin units.\n\n    The final arrays (e_means, mag_means, sus_vals, s_heat_vals) will be:\n      e_means, mag_means:        E/N^2,  M/N^2\n      sus_vals, s_heat_vals:     per–spin definitions of susceptibility & specific heat\n    \"\"\"\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    for N in sizes:\n        analysis_file = os.path.join(output_folder, f\"Analysis_N{N}.npz\")\n        # Remove or comment out this block if you want to overwrite existing files:\n        if os.path.exists(analysis_file):\n            print(f\"Analysis file for N={N} already exists. Skipping computation.\")\n            continue\n\n        files = natsort.natsorted(glob.glob(f\"{input_folder}/*N{N}*.npz\"))\n        print(f\"Processing system size N={N}\")\n\n        norm_factor = N**dim  \n\n        t_vals = []\n        binder_vals = []\n        binder_errs = []\n        e_means = []\n        e_errs = []\n        mag_means = []\n        mag_errs = []\n        sus_vals = []\n        sus_errs = []\n        s_heat_vals = []\n        s_heat_errs = []\n        corr_list = []\n\n        for f in files:\n            data = np.load(f)\n\n            try:\n                T = float(f.split(\"T\")[1].split(\"N\")[0])\n            except Exception as e:\n                print(f\"Error parsing temperature from {f}: {e}\")\n                continue\n\n            M = np.abs(data[\"magnetisation\"])\n            n_mag = len(M)\n            M_mean = np.mean(M)\n            M_std  = np.std(M, ddof=1)\n            M_err  = M_std / np.sqrt(n_mag)\n\n            M2_mean = np.mean(M**2)\n            M4_mean = np.mean(M**4)\n            M2_std  = np.std(M**2, ddof=1)\n            M4_std  = np.std(M**4, ddof=1)\n            M2_err  = M2_std / np.sqrt(n_mag)\n            M4_err  = M4_std / np.sqrt(n_mag)\n\n            if M2_mean == 0:\n                continue\n            binder = 1 - M4_mean / (3 * M2_mean**2)\n            binder_err = np.sqrt(\n                ((2 * M4_mean / (3 * M2_mean**3)) * M2_err)**2\n                + ((1 / (3 * M2_mean**2)) * M4_err)**2\n            )\n\n            E = data[\"energy\"]\n            n_e = len(E)\n            E_mean = np.mean(E)\n            E_std  = np.std(E, ddof=1)\n            E_err  = E_std / np.sqrt(n_e)\n\n            if T == 0:\n                continue\n            beta = 1.0 / T\n\n            var_M = (M2_mean - M_mean**2)\n            sus_val = beta * var_M / (norm_factor)\n            var_M_err = np.sqrt(M2_err**2 + (2 * M_mean * M_err)**2)\n            sus_err = beta * var_M_err / norm_factor\n\n            E2_mean = np.mean(E**2)\n            E2_std  = np.std(E**2, ddof=1)\n            E2_err  = E2_std / np.sqrt(n_e)\n            var_E   = (E2_mean - E_mean**2)\n            s_heat_val = beta**2 * var_E / norm_factor\n            var_E_err = np.sqrt(E2_err**2 + (2 * E_mean * E_err)**2)\n            s_heat_err = beta**2 * var_E_err / norm_factor\n\n            e_means.append(E_mean / norm_factor)\n            e_errs.append(E_err  / norm_factor)\n\n            mag_means.append(M_mean / norm_factor)\n            mag_errs.append(M_err  / norm_factor)\n\n            sus_vals.append(sus_val)\n            sus_errs.append(sus_err)\n            s_heat_vals.append(s_heat_val)\n            s_heat_errs.append(s_heat_err)\n\n            corr_list.append(data[\"correlation\"])\n\n            t_vals.append(T)\n            binder_vals.append(binder)\n            binder_errs.append(binder_err)\n\n        sort_idx = np.argsort(t_vals)\n        np.savez(\n            analysis_file,\n            t_vals        = np.array(t_vals)[sort_idx],\n            binder_vals   = np.array(binder_vals)[sort_idx],\n            binder_errs   = np.array(binder_errs)[sort_idx],\n            e_means       = np.array(e_means)[sort_idx],\n            e_errs        = np.array(e_errs)[sort_idx],\n            mag_means     = np.array(mag_means)[sort_idx],\n            mag_errs      = np.array(mag_errs)[sort_idx],\n            sus_vals      = np.array(sus_vals)[sort_idx],\n            sus_errs      = np.array(sus_errs)[sort_idx],\n            s_heat_vals   = np.array(s_heat_vals)[sort_idx],\n            s_heat_errs   = np.array(s_heat_errs)[sort_idx],\n            correlation   = np.array(corr_list)[sort_idx]\n        )\n\n        print(f\"Saved analysis for N={N} to {analysis_file}\")\n\n\n\n\ndef load_analysis(folder=\"data6\", sizes=[8, 16, 32]):\n    analysis_data = {}\n    for N in sizes:\n        filename = os.path.join(folder, f\"Analysis_N{N}.npz\")\n        if os.path.exists(filename):\n            data = np.load(filename)\n            analysis_data[N] = {\"t_vals\": data[\"t_vals\"],\n                              \"binder_vals\": data[\"binder_vals\"],\n                              \"binder_errs\": data[\"binder_errs\"],\n                              \"e_means\": data[\"e_means\"],\n                              \"e_errs\": data[\"e_errs\"],\n                              \"mag_means\": data[\"mag_means\"],\n                              \"mag_errs\": data[\"mag_errs\"],\n                              \"sus_vals\": data[\"sus_vals\"],\n                              \"sus_errs\": data[\"sus_errs\"],\n                              \"s_heat_vals\": data[\"s_heat_vals\"],\n                              \"s_heat_errs\": data[\"s_heat_errs\"],\n                              \"corr\": data[\"correlation\"] \n                              }\n        else:\n            print(f\"Analysis file not found for N={N}.\")\n    return analysis_data\n\ndef load_observables(input_folder=\"data6\", sizes=[8, 16, 32]):\n\n    observables_data = {}\n    for N in sizes:\n        filename = os.path.join(input_folder, f\"Analysis_N{N}.npz\")\n        if os.path.exists(filename):\n            data = np.load(filename)\n            observables_data[N] = {\n                \"t_vals\": data[\"t_vals\"],\n                \"e_means\": data[\"e_means\"],\n                \"e_errs\": data[\"e_errs\"],\n                \"mag_means\": data[\"mag_means\"],\n                \"mag_errs\": data[\"mag_errs\"],\n                \"sus_vals\": data[\"sus_vals\"],\n                \"sus_errs\": data[\"sus_errs\"],\n                \"s_heat_vals\": data[\"s_heat_vals\"],\n                \"s_heat_errs\": data[\"s_heat_errs\"],\n                \"corr\": data[\"correlation\"] \n            }\n        else:\n            print(f\"Analysis file not found for N={N}.\")\n    return observables_data\n\n\ndef plot_binder_values_with_critical(analysis_data, critical_temps, reference_size, \n                                     custom_T_low=None, custom_T_high=None,\n                                     inset_xlim=None, inset_ylim=None,\n                                     binder_text=\"(a)\", binder_text_pos=(0.05, 0.95),\n                                     inset_text=\"(y)\", inset_text_pos=(0.05, 0.90)):\n\n    plt.figure(figsize=(8, 6))\n    for N, data in analysis_data.items():\n        plt.errorbar(data[\"t_vals\"], data[\"binder_vals\"], yerr=data[\"binder_errs\"],\n                     fmt='o', label=f\"L={N}\", ecolor='black', capsize=5, alpha=0.5)\n    plt.axvline(x=2.269, color='red', linestyle='--', label=\"Expected $\\mathbf{T_c}$ (2.269)\")\n    if custom_T_low is not None and custom_T_high is not None:\n        plt.xlim(custom_T_low, custom_T_high)\n    plt.xlabel(\"Temperature, $\\mathbf{T}$\", fontsize=16)\n    plt.ylabel(\"Binder Cumulant, $\\mathbf{U_L}$\", fontsize=16)\n    plt.legend(fontsize=12, loc=\"upper right\")\n    plt.tick_params(axis='both', which='major', labelsize=14)\n\n    plt.gca().text(binder_text_pos[0], binder_text_pos[1], binder_text,\n                   transform=plt.gca().transAxes, fontsize=20, fontweight='bold')\n    \n    ax_inset = inset_axes(plt.gca(), width=\"100%\", height=\"100%\", \n                          bbox_to_anchor=(0.11, 0.09, 0.4, 0.5),\n                          bbox_transform=plt.gca().transAxes, borderpad=0)\n    \n    ratios = [N / reference_size for N in critical_temps.keys()]\n    Tc_values = [val[0] for val in critical_temps.values()]\n    Tc_errors = [val[1] for val in critical_temps.values()]\n    \n    ax_inset.errorbar(ratios, Tc_values, yerr=Tc_errors, fmt='o', color='blue',\n                      ecolor='black', capsize=4, alpha=0.8, label=\"Estimated $\\mathbf{T_c}$\")\n    \n    avg_Tc = np.mean(Tc_values)\n    avg_error = np.mean(Tc_errors)\n    ax_inset.axhline(y=avg_Tc, color='blue', linestyle='--',\n                     label=\"Avg $\\mathbf{T_c}$ = \" + f\"{avg_Tc:.3f}±{avg_error:.3f}\")\n    \n    ax_inset.axhline(y=2.269, color='red', linestyle='--', label=\"Expected $\\mathbf{T_c}$\")\n    \n    if inset_xlim is not None:\n        ax_inset.set_xlim(inset_xlim)\n    else:\n        margin = 0.1\n        ax_inset.set_xlim(min(ratios) - margin, max(ratios) + margin)\n    \n    if inset_ylim is not None:\n        ax_inset.set_ylim(inset_ylim)\n    \n    ax_inset.set_xticks(ratios)\n    ax_inset.set_xlabel(\"$\\mathbf{L / L_{min}}$\", fontsize=16)\n    ax_inset.xaxis.set_label_coords(0.5, -0.03)\n    ax_inset.set_ylabel(\"$\\mathbf{T}$\", fontsize=16, rotation=0)\n    ax_inset.yaxis.set_label_coords(-0.07, 1.03)\n    ax_inset.xaxis.label.set_bbox(dict(facecolor='white', edgecolor='black', pad=2))\n    ax_inset.yaxis.label.set_bbox(dict(facecolor='white', edgecolor='black', pad=3))\n    \n    ax_inset.tick_params(axis='both', which='major', labelsize=11)\n    ax_inset.legend(fontsize=11, loc='upper right', bbox_to_anchor=(1.00, 0.4))\n\n    \n    ax_inset.text(inset_text_pos[0], inset_text_pos[1], inset_text,\n                  transform=ax_inset.transAxes, fontsize=20, fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig(\"C:/Users/gianc/Documents/isingproject/final figs/bind_final.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n    plt.show()\n\n    \n    \ndef plot_binder_values(analysis_data, custom_T_low=None, custom_T_high=None):\n    plt.figure(figsize=(8, 6))\n    for N, data in analysis_data.items():\n        plt.errorbar(data[\"t_vals\"], data[\"binder_vals\"], yerr=data[\"binder_errs\"],\n                     fmt='o', label=f\"N={N}\", ecolor='black', capsize=5, alpha=0.5)\n    plt.axvline(x=2.269, color='red', linestyle='--', label=\"Expected $T_c$ (2.269)\")\n    if custom_T_low is not None and custom_T_high is not None:\n        plt.xlim(custom_T_low, custom_T_high)\n    plt.xlabel(\"Temperature T\")\n    plt.ylabel(\"Binder Cumulant\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n\n\ndef plot_corr_linear(observables_data, T_targets=(2.269, 2.3)):\n    plt.figure(figsize=(8, 6))\n    base_colors = plt.cm.tab10.colors  \n    num_base_colors = len(base_colors)\n    \n    for i, (N, data) in enumerate(sorted(observables_data.items())):\n        if data[\"corr\"] is None:\n            continue\n        base_color = base_colors[i % num_base_colors]\n        \n        for j, T in enumerate(T_targets):\n            if j == 0:\n                marker_alpha = 1.0\n                line_style = '-'\n            else:\n                marker_alpha = 0.5\n                line_style = ':'\n            \n            idx = np.argmin(np.abs(data[\"t_vals\"] - T))\n            corr = data[\"corr\"][idx]\n            r_norm = np.arange(len(corr)) / N\n            \n            plt.plot(r_norm, corr, 'o', color=base_color, alpha=marker_alpha)\n            \n            coeffs = np.polyfit(r_norm, corr, 10)\n            p = np.poly1d(coeffs)\n            x_fit = np.linspace(np.min(r_norm), np.max(r_norm), 100)\n            y_fit = p(x_fit)\n            plt.plot(x_fit, y_fit, linestyle=line_style, color=base_color, alpha=1.0,\n                     label=f\" N={N}, T={data['t_vals'][idx]:.3f}\")\n    \n    plt.xlabel(\"Normalized distance (r/N)\")\n    plt.ylabel(\"$G(r)$\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_corr_semilog(observables_data, T_target=2.269):\n    plt.figure(figsize=(8,6))\n    for N, data in observables_data.items():\n        if data[\"corr\"] is None:\n            continue\n        idx = np.argmin(np.abs(data[\"t_vals\"] - T_target))\n        corr = data[\"corr\"][idx]\n        r = np.arange(len(corr))\n        plt.semilogy(r, corr, 'o-', label=f\"N={N}, T={data['t_vals'][idx]:.3f}\")\n    plt.xlabel(\"Distance r\")\n    plt.ylabel(\"Connected Correlation Function $C_{conn}(r)$ (log scale)\")\n    plt.title(\"Semilog Plot of $C_{conn}(r)$ vs. r\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_corr_loglog(observables_data, T_target=2.269):\n    plt.figure(figsize=(8,6))\n    for N, data in observables_data.items():\n        if data[\"corr\"] is None:\n            continue\n        idx = np.argmin(np.abs(data[\"t_vals\"] - T_target))\n        corr = data[\"corr\"][idx]\n        r = np.arange(1, len(corr))\n        plt.loglog(r, corr[1:], 'o-', label=f\"N={N}, T={data['t_vals'][idx]:.3f}\")\n    plt.xlabel(\"Distance r (log scale)\")\n    plt.ylabel(\"$C_{conn}(r)$ (log scale)\")\n    plt.title(\"Log-Log Plot of $C_{conn}(r)$ vs. r\")\n    plt.legend()\n    plt.grid(True, which=\"both\", ls=\"--\")\n    plt.show()\n\ndef compute_correlation_length(corr, N, corr_err=None):\n    R = len(corr) - 1\n    \n    if N % 2 == 0:\n        S0 = corr[0] + 2 * np.sum(corr[1:R]) + corr[R]\n        S_k = (corr[0] + 2 * np.sum(corr[1:R] * np.cos(2*np.pi*np.arange(1, R)/N))\n               + corr[R]*np.cos(np.pi))\n        if corr_err is not None:\n            S0_err = np.sqrt(corr_err[0]**2 + 4*np.sum(corr_err[1:R]**2) + corr_err[R]**2)\n            S_k_err = np.sqrt(corr_err[0]**2 + 4*np.sum((np.cos(2*np.pi*np.arange(1,R)/N)**2 * corr_err[1:R]**2))\n                               + (np.cos(np.pi)*corr_err[R])**2)\n        else:\n            S0_err = S_k_err = np.nan\n    else:\n        S0 = corr[0] + 2 * np.sum(corr[1:R+1])\n        S_k = corr[0] + 2 * np.sum(corr[1:R+1] * np.cos(2*np.pi*np.arange(1, R+1)/N))\n        if corr_err is not None:\n            S0_err = np.sqrt(corr_err[0]**2 + 4*np.sum(corr_err[1:R+1]**2))\n            S_k_err = np.sqrt(corr_err[0]**2 + 4*np.sum((np.cos(2*np.pi*np.arange(1,R+1)/N)**2 * corr_err[1:R+1]**2))\n                               )\n        else:\n            S0_err = S_k_err = np.nan\n\n    ratio = S0/S_k - 1\n    if ratio &lt; 0:\n        print(f\"Warning: Negative ratio encountered for N={N}: ratio = {ratio}, S0 = {S0}, S_k = {S_k}\")\n        return np.nan, np.nan\n    xi = 1.0/(2*np.sin(np.pi/N)) * np.sqrt(ratio)\n    \n    if corr_err is not None:\n        dR_dS0 = 1.0 / S_k\n        dR_dS_k = -S0 / (S_k**2)\n        ratio_err = np.sqrt((dR_dS0 * S0_err)**2 + (dR_dS_k * S_k_err)**2)\n        factor = 1.0/(2*np.sin(np.pi/N))\n        xi_err = factor/(2*np.sqrt(ratio)) * ratio_err\n    else:\n        xi_err = np.nan\n\n    return xi, xi_err\n\ndef plot_correlation_length(observables_data):\n    plt.figure(figsize=(8, 6))\n    for N, data in observables_data.items():\n        if data[\"corr\"] is None:\n            continue\n\n        t_vals = data[\"t_vals\"]\n        xi_norm_vals = []\n        xi_norm_errs = []\n\n        has_corr_err = \"corr_err\" in data\n\n        for i, corr_raw in enumerate(data[\"corr\"]):\n            m = data[\"mag_means\"][i]\n            corr_connected = corr_raw - m**2\n            corr_err = data[\"corr_err\"][i] if has_corr_err else None\n            xi, xi_err = compute_correlation_length(corr_connected, N, corr_err)\n            xi_norm_vals.append(xi / N)\n            xi_norm_errs.append(xi_err / N if xi_err is not None else np.nan)\n\n        xi_norm_vals = np.array(xi_norm_vals)\n        xi_norm_errs = np.array(xi_norm_errs)\n        plt.errorbar(t_vals, xi_norm_vals, yerr=xi_norm_errs, fmt='o-', capsize=5,\n                     label=f\"L={N}\")\n\n    plt.xlabel(\"Temperature,  T\")\n    plt.ylabel(\"Normalized Correlation Length, $\\\\xi/L$\")\n    plt.legend()\n    plt.savefig(\"C:/Users/gianc/Documents/isingproject/final figs/c_length_final.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n    plt.show()\n\ndef plot_fss_xi(observables_data, T_target=2.269):\n    sizes = []\n    xi_target = []\n    for N, data in observables_data.items():\n        if data[\"corr\"] is None:\n            continue\n        idx = np.argmin(np.abs(data[\"t_vals\"] - T_target))\n        xi = compute_correlation_length(data[\"corr\"][idx], N)\n        sizes.append(N)\n        xi_target.append(xi)\n    sizes = np.array(sizes)\n    xi_target = np.array(xi_target)\n    plt.figure(figsize=(8,6))\n    plt.loglog(sizes, xi_target, 'o-', label=f\"T={T_target:.3f}\")\n    slope, intercept = np.polyfit(np.log(sizes), np.log(xi_target), 1)\n    plt.loglog(sizes, np.exp(intercept)*sizes**slope, '--', label=f\"Fit: slope = {slope:.2f}\")\n    plt.xlabel(\"System Size N\")\n    plt.ylabel(\"Correlation Length $\\\\xi$\")\n    plt.title(\"Finite-Size Scaling of Correlation Length\")\n    plt.legend()\n    plt.grid(True, which='both', ls='--')\n    plt.show()\n\ndef plot_scaling_collapse(observables_data, T_target=2.269, eta=0.25, d=2):\n    plt.figure(figsize=(8,6))\n    for N, data in observables_data.items():\n        if data[\"corr\"] is None:\n            continue\n        idx = np.argmin(np.abs(data[\"t_vals\"] - T_target))\n        corr = data[\"corr\"][idx]\n        r = np.arange(len(corr))\n        scale_factor = N**(d-2+eta)\n        plt.plot(r/float(N), scale_factor * corr, 'o-', label=f\"N={N}\")\n    plt.xlabel(\"Scaled distance r/N\")\n    plt.ylabel(f\"Scaled Correlation: $N^{{d-2+\\\\eta}} C_{{conn}}(r)$\")\n    plt.title(f\"Scaling Collapse of Correlation Function at T={T_target:.3f}\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef build_splines(analysis_data, s=0):\n    splines = {}\n    for N, data in analysis_data.items():\n        T = data[\"t_vals\"]\n        binder = data[\"binder_vals\"]\n        spline = UnivariateSpline(T, binder, s=s)\n        binder_error = data[\"binder_errs\"]\n        error_spline = UnivariateSpline(T, binder_error, s=s)\n        splines[N] = {\"spline\": spline, \"error_spline\": error_spline}\n    return splines\n\ndef find_intersection(spline1, spline2, error_spline1, error_spline2, T_min, T_max, num_points=1000):\n    T_values = np.linspace(T_min, T_max, num_points)\n    diff = spline1(T_values) - spline2(T_values)\n    for i in range(len(diff) - 1):\n        if diff[i] * diff[i+1] &lt; 0:\n            try:\n                Tc = brentq(lambda T: spline1(T) - spline2(T), T_values[i], T_values[i+1])\n                d_diff_dT = spline1.derivative()(Tc) - spline2.derivative()(Tc)\n                err1 = error_spline1(Tc)\n                err2 = error_spline2(Tc)\n                Tc_error = np.sqrt(err1**2 + err2**2) / np.abs(d_diff_dT) if d_diff_dT != 0 else np.inf\n                return Tc, Tc_error\n            except ValueError:\n                continue\n    return None, None\n\ndef calculate_all_intersections(analysis_data, s=0, custom_T_low=None, custom_T_high=None):\n    splines = build_splines(analysis_data, s=s)\n    intersection_dict = {}\n    sizes = sorted(analysis_data.keys())\n    for i in range(len(sizes)):\n        for j in range(i+1, len(sizes)):\n            N1 = sizes[i]\n            N2 = sizes[j]\n            \n            if custom_T_low is not None and custom_T_high is not None:\n                T_min = custom_T_low\n                T_max = custom_T_high\n            else:\n                T_min = max(np.min(analysis_data[N1][\"t_vals\"]), np.min(analysis_data[N2][\"t_vals\"]))\n                T_max = min(np.max(analysis_data[N1][\"t_vals\"]), np.max(analysis_data[N2][\"t_vals\"]))\n                \n            Tc, Tc_error = find_intersection(splines[N1][\"spline\"], splines[N2][\"spline\"],\n                                             splines[N1][\"error_spline\"], splines[N2][\"error_spline\"],\n                                             T_min, T_max)\n            if Tc is not None:\n                intersection_dict[(N1, N2)] = (Tc, Tc_error)\n                print(f\"Intersection for N={N1} and N={N2}: Tc = {Tc:.4f} ± {Tc_error:.4f}\")\n            else:\n                print(f\"No intersection found for N={N1} and N={N2} in range [{T_min:.4f}, {T_max:.4f}].\")\n    return intersection_dict\n\ndef calculate_critical_temperatures(analysis_data, custom_T_low=None, custom_T_high=None):\n    splines = build_splines(analysis_data)\n    reference_size = min(analysis_data.keys())\n    ref_spline = splines[reference_size][\"spline\"]\n    ref_error_spline = splines[reference_size][\"error_spline\"]\n    critical_temps = {}\n    for N, spline_data in splines.items():\n        if N == reference_size:\n            continue\n            \n        if custom_T_low is not None and custom_T_high is not None:\n            T_min = custom_T_low\n            T_max = custom_T_high\n        else:\n            T_min = max(np.min(analysis_data[reference_size][\"t_vals\"]), np.min(analysis_data[N][\"t_vals\"]))\n            T_max = min(np.max(analysis_data[reference_size][\"t_vals\"]), np.max(analysis_data[N][\"t_vals\"]))\n            \n        Tc, Tc_error = find_intersection(ref_spline, spline_data[\"spline\"],\n                                         ref_error_spline, spline_data[\"error_spline\"],\n                                         T_min, T_max)\n        if Tc is not None:\n            critical_temps[N] = (Tc, Tc_error)\n            print(f\"Intersection for N={N} (ratio {N/reference_size:.2f}): Tc = {Tc:.4f} ± {Tc_error:.4f}\")\n        else:\n            print(f\"No intersection found for N={N} in range [{T_min:.4f}, {T_max:.4f}].\")\n    return critical_temps, reference_size\n\ndef plot_all_intersections(analysis_data, intersections, zoom_margin=0.005, custom_T_low=None, custom_T_high=None):\n    splines = build_splines(analysis_data)\n    if custom_T_low is not None and custom_T_high is not None:\n        T_low, T_high = custom_T_low, custom_T_high\n    else:\n        if intersections:\n            Tc_values = [val[0] for val in intersections.values()]\n            T_low = min(Tc_values) - zoom_margin\n            T_high = max(Tc_values) + zoom_margin\n        else:\n            T_low, T_high = 2.25, 2.29\n    T_fine = np.linspace(T_low, T_high, 1000)\n    plt.figure(figsize=(8, 6))\n    for N, spline_data in splines.items():\n        spline = spline_data[\"spline\"]\n        plt.plot(T_fine, spline(T_fine), label=f\"N={N}\")\n        data = analysis_data[N]\n        mask = (data[\"t_vals\"] &gt;= T_low) & (data[\"t_vals\"] &lt;= T_high)\n        plt.errorbar(np.array(data[\"t_vals\"])[mask], np.array(data[\"binder_vals\"])[mask],\n                     yerr=np.array(data[\"binder_errs\"])[mask], fmt='o', markersize=4,\n                     ecolor='black', capsize=5, alpha=0.5)\n    for (N1, N2), (Tc, Tc_error) in intersections.items():\n        binder_val = splines[N1][\"spline\"](Tc)\n        plt.errorbar(Tc, binder_val, yerr=Tc_error, fmt='ko', markersize=8,\n                     ecolor='black', capsize=5, alpha=0.5)\n        plt.text(Tc, binder_val, f\" {Tc:.3f}±{Tc_error:.3f}\", fontsize=9, color='black')\n        plt.axvline(x=Tc, color='gray', linestyle='--', linewidth=0.5)\n    if T_low &lt;= 2.269 &lt;= T_high:\n        plt.axvline(x=2.269, color='red', linestyle='--', label=\"Expected $T_c$ (2.269)\")\n    plt.xlabel(\"Temperature T\")\n    plt.ylabel(\"Binder Cumulant\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_critical_temperatures(critical_temps, reference_size):\n    ratios = [N / reference_size for N in critical_temps.keys()]\n    Tc_values = [val[0] for val in critical_temps.values()]\n    Tc_errors = [val[1] for val in critical_temps.values()]\n    \n    plt.figure(figsize=(8, 6))\n    plt.errorbar(ratios, Tc_values, yerr=Tc_errors, fmt='o', color='blue',\n                 label=\"Estimated $T_c$\", ecolor='black', capsize=5, alpha=0.7)\n    \n    avg_Tc = np.mean(Tc_values)\n    avg_error = np.mean(Tc_errors)\n    \n    plt.axhline(y=avg_Tc, color='blue', linestyle='--',\n                label=f\"Average $T_c$ = {avg_Tc:.3f} ± {avg_error:.3f}\")\n    \n    plt.axhline(y=2.269, color='red', linestyle='--', label=\"Expected $T_c$ (2.269)\")\n    \n    plt.xlabel(\"System Size Ratio ($N / N_{small}$)\")\n    plt.ylabel(\"Critical Temperature $T_c$\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef load_observables_extended(input_folder=\"data6\", sizes=[8, 16, 32]):\n    \"\"\"\n    This function loads all observables including the connected correlation function.\n    \"\"\"\n    observables_data = {}\n    for N in sizes:\n        filename = os.path.join(input_folder, f\"Analysis_N{N}.npz\")\n        if os.path.exists(filename):\n            data = np.load(filename)\n            observables_data[N] = {\n                \"t_vals\": data[\"t_vals\"],\n                \"e_means\": data[\"e_means\"],\n                \"e_errs\": data[\"e_errs\"],\n                \"mag_means\": data[\"mag_means\"],\n                \"mag_errs\": data[\"mag_errs\"],\n                \"sus_vals\": data[\"sus_vals\"],\n                \"sus_errs\": data[\"sus_errs\"],\n                \"s_heat_vals\": data[\"s_heat_vals\"],\n                \"s_heat_errs\": data[\"s_heat_errs\"],\n                \"corr\": data[\"correlation\"] if \"correlation\" in data else None\n            }\n        else:\n            print(f\"Analysis file not found for N={N}.\")\n    return observables_data\n\ndef plot_observables(observables_data):\n    fig, axs = plt.subplots(4, 1, figsize=(12, 16))\n    \n    ax = axs[0]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"e_means\"], yerr=data[\"e_errs\"],\n                    fmt='o', label=f\"L={N}\", ecolor='black', capsize=5, alpha=0.5)\n    ax.set_xlabel(\"Temperature, $T$\")\n    ax.set_ylabel(\"Energy, $&lt;H&gt;$\")\n    ax.legend()\n    \n    ax = axs[1]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"mag_means\"], yerr=data[\"mag_errs\"],\n                    fmt='o', label=f\"L={N}\", ecolor='black', capsize=5, alpha=0.5)\n    all_T = np.concatenate([data[\"t_vals\"] for data in observables_data.values()])\n    T_min = np.min(all_T)\n    Tc = 2.269\n    T_vals = np.linspace(T_min, Tc, 300)\n    ax.plot([Tc, Tc], [0, 0.38], 'k--', lw=2)\n    m_ons = (1 - np.sinh(2/T_vals)**(-4))**(1/8)\n    ax.plot(T_vals, m_ons, 'k--', lw=2, label=\"Onsager\")\n    ax.set_xlabel(\"Temperature, $T$\")\n    ax.set_ylabel(\"Magnetisation, $M$\")\n    ax.legend()\n    \n    ax = axs[2]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"sus_vals\"], yerr=data[\"sus_errs\"],\n                    fmt='o', label=f\"L={N}\", ecolor='black', capsize=5, alpha=0.5)\n    ax.set_xlabel(\"Temperature, $T$\")\n    ax.set_ylabel(\"Susceptibility, $\\chi$\")\n    ax.legend()\n    \n    ax = axs[3]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"s_heat_vals\"], yerr=data[\"s_heat_errs\"],\n                    fmt='o', label=f\"L={N}\", ecolor='black', capsize=5, alpha=0.5)\n    ax.set_xlabel(\"Temperature, $T$\")\n    ax.set_ylabel(\"Specific Heat, $C$\")\n    ax.legend()\n    \n    plt.tight_layout()\n    plt.savefig(\"C:/Users/gianc/Documents/isingproject/final figs/obs.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n    plt.show()\n\ndef plot_loglog_observables(observables_data, intersections, cutoff=1e-5, Tc_avg=2.269, \n                            reduced_range_low=None, reduced_range_high=None, T_target=2.269,\n                            side='lower'):\n    import numpy as np\n    fig, axs = plt.subplots(4, 1, figsize=(8, 12))\n    \n    obs_keys = {\"magnetisation\": \"mag_means\",\n                \"susceptibility\": \"sus_vals\",\n                \"specific_heat\": \"s_heat_vals\"}\n    err_keys = {\"magnetisation\": \"mag_errs\",\n                \"susceptibility\": \"sus_errs\",\n                \"specific_heat\": \"s_heat_errs\"}\n    obs_titles = {\"magnetisation\": \"Magnetisation, $M$\", \n                  \"susceptibility\": \"Susceptibility, $\\\\chi$\", \n                  \"specific_heat\": \"Specific Heat, $C$\"}\n    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n\n    for i, (obs, key) in enumerate(obs_keys.items()):\n        ax = axs[i]\n        for j, N in enumerate(sorted(observables_data.keys())):\n            data = observables_data[N]\n            T = data[\"t_vals\"]\n            y = data[key]\n            y_err = data[err_keys[obs]]\n            if obs == \"magnetisation\":\n                y = np.abs(y)\n            if side.lower() == 'lower':\n                x = (Tc_avg - T) / Tc_avg\n            elif side.lower() == 'upper':\n                x = (T - Tc_avg) / Tc_avg\n            mask = x &gt; cutoff\n            if reduced_range_low is not None:\n                mask &= (x &gt;= reduced_range_low)\n            if reduced_range_high is not None:\n                mask &= (x &lt;= reduced_range_high)\n            x_plot, y_plot = x[mask], y[mask]\n            y_err_plot = y_err[mask]\n            if len(x_plot) &lt; 2:\n                continue\n            color = colors[j % len(colors)]\n            ax.errorbar(x_plot, y_plot, yerr=y_err_plot, fmt='o', color=color,\n                        ecolor='black', capsize=5, alpha=0.5)\n            logx, logy = np.log(x_plot), np.log(y_plot)\n            p, cov = np.polyfit(logx, logy, 1, cov=True)\n            slope, intercept = p\n            slope_error = np.sqrt(cov[0, 0])\n            x_fit = np.linspace(np.min(x_plot), np.max(x_plot), 100)\n            y_fit = np.exp(intercept) * x_fit**slope\n            ax.plot(x_fit, y_fit, '--', color=color,\n                    label=f\"L={N} fit: {slope:.3f}±{slope_error:.3f}\")\n            \n        ax.set_xscale('log')\n        ax.set_yscale('log')\n        xlabel = r\"Reduced Temperature, $\\mathbf{(T_c-T)/T_c}$\" if side.lower() == 'lower' else r\"Reduced Temperature, $\\mathbf{(T_c-T)/T_c}$\"\n        ax.set_xlabel(xlabel, fontsize=16)\n        ax.set_ylabel(obs_titles[obs], fontsize=16)\n        ax.legend(fontsize=12,loc=\"upper right\") if i == 2 else ax.legend(fontsize=12)\n        \n        ax.tick_params(axis='both', which='major', width=3)\n        ax.tick_params(axis='both', which='minor', width=1.5)\n\n    \n    ax = axs[3]\n    sizes = []\n    xi_target = []\n    xi_errs = []\n    for N, data in sorted(observables_data.items()):\n        if data[\"corr\"] is None:\n            continue\n        idx = np.argmin(np.abs(data[\"t_vals\"] - T_target))\n        corr = data[\"corr\"][idx]\n        corr_err = data[\"corr_err\"][idx] if \"corr_err\" in data else None\n        xi, xi_err = compute_correlation_length(corr, N, corr_err)\n        sizes.append(N)\n        xi_target.append(xi)\n        xi_errs.append(xi_err)\n    sizes = np.array(sizes)\n    xi_target = np.array(xi_target)\n    xi_errs = np.array(xi_errs)\n    ax.errorbar(sizes, xi_target, yerr=xi_errs, fmt='o-', capsize=5,\n                label=f\"T={T_target:.3f}\", ecolor='black')\n    if len(sizes) &gt; 1:\n        p, cov = np.polyfit(np.log(sizes), np.log(xi_target), 1, cov=True)\n        slope, intercept = p\n        slope_error = np.sqrt(cov[0, 0])\n        fit_line = np.exp(intercept) * sizes**slope\n        ax.loglog(sizes, fit_line, '--',\n                  label=f\"Fit: slope = {slope:.2f}±{slope_error:.2f}\")\n    ax.set_xlabel(\"System Size, L\", fontsize=18)\n    ax.set_ylabel(\"Correlation Length, $\\\\xi$\", fontsize=15)\n    ax.legend(fontsize=15)\n    ax.tick_params(axis='both', which='major', width=3)\n    ax.tick_params(axis='both', which='minor', width=1.5)\n\n    \n    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n    plt.savefig(\"C:/Users/gianc/Documents/isingproject/final figs/exp.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n    plt.show()\n\ndef plot_observable_errors(observables_data):\n    err_keys = {\"energy\": \"e_errs\",\n                \"magnetisation\": \"mag_errs\",\n                \"susceptibility\": \"sus_errs\",\n                \"specific_heat\": \"s_heat_errs\"}\n    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n    ax = axs[0, 0]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"energy\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Energy Error\")\n    ax.set_title(\"Energy Error vs. Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[0, 1]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"magnetisation\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Magnetisation Error\")\n    ax.set_title(\"Magnetisation Error vs. Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[1, 0]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"susceptibility\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Susceptibility Error\")\n    ax.set_title(\"Susceptibility Error vs. Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[1, 1]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"specific_heat\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Specific Heat Error\")\n    ax.set_title(\"Specific Heat Error vs. Temperature\")\n    ax.legend()\n    plt.tight_layout()\n    plt.show()\n    \n\ndef plot_mag_vs_iterations_comparison(primary_folder, secondary_folder, temperature, system_size, max_iterations=None):\n\n    primary_pattern = os.path.join(primary_folder, f\"*T{temperature}*N{system_size}*.npz\")\n    primary_files = natsort.natsorted(glob.glob(primary_pattern))\n    if not primary_files:\n        print(f\"No file found in {primary_folder} for T={temperature} and N={system_size}\")\n        return\n    primary_file = primary_files[0]\n    data_primary = np.load(primary_file)\n    mag_primary = np.abs(data_primary['magnetisation'])\n    \n    secondary_pattern = os.path.join(secondary_folder, f\"*T{temperature}*N{system_size}*.npz\")\n    secondary_files = natsort.natsorted(glob.glob(secondary_pattern))\n    if not secondary_files:\n        print(f\"No file found in {secondary_folder} for T={temperature} and N={system_size}\")\n        return\n    secondary_file = secondary_files[0]\n    data_secondary = np.load(secondary_file)\n    mag_secondary = np.abs(data_secondary['magnetisation'])\n    \n    # Limit iterations if max_iterations is provided\n    if max_iterations is not None:\n        mag_primary = mag_primary[:max_iterations]\n        mag_secondary = mag_secondary[:max_iterations]\n    \n    iterations_primary = np.arange(len(mag_primary))\n    iterations_secondary = np.arange(len(mag_secondary))\n    \n    plt.figure(figsize=(8, 6))\n    plt.plot(iterations_primary, mag_primary, label=\"Wolfs Algorithm\", marker='o', linestyle='-')\n    plt.plot(iterations_secondary, mag_secondary, label=\"Metropolis Algorithm\", marker='s', linestyle='--')\n    plt.xlabel(\"Iteration\")\n    plt.ylabel(\"Magnetisation, M\")\n    plt.legend(fontsize=14, loc=\"upper right\")\n    plt.savefig(\"C:/Users/gianc/Documents/isingproject/final figs/w_vs_m_final.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    folder = \"final_cluster_exponent\"  \n    params_filepath = os.path.join(folder, \"simulation_parameters.npz\")\n    if os.path.exists(params_filepath):\n        params = np.load(params_filepath)\n        nt = int(params[\"nt\"])\n        n_list = params[\"n_list\"].tolist() #[16, 32, 64, 128]\n        eqSteps = int(params[\"eqSteps\"])\n        mcSteps = int(params[\"mcSteps\"])\n        T_arr = params[\"T_arr\"]\n        print(\"Loaded Simulation Parameters:\")\n        print(\"nt       =\", nt)\n        print(\"n_list   =\", n_list)\n        print(\"eqSteps  =\", eqSteps)\n        print(\"mcSteps  =\", mcSteps)\n    else:\n        print(f\"Simulation parameters file not found in {folder}. Using default sizes.\")\n        n_list = [8, 16, 32]\n        \n    \n    mpl.rcParams.update({\n        \"figure.dpi\": 300,        \n        \"savefig.dpi\": 300,      \n        \"font.size\": 13,\n        \"axes.titlesize\": 15,\n        \"axes.labelsize\": 13,\n        \"legend.fontsize\": 20,\n        \"text.usetex\": False, \n        \"font.family\": \"sans-serif\",  \n        \"font.sans-serif\": [\"DejaVu Sans\"],  \n        \"font.weight\": \"bold\",\n        \"axes.labelweight\": \"bold\",\n        \"axes.titleweight\": \"bold\",\n        \"mathtext.fontset\": \"dejavusans\",\n        \"axes.linewidth\": 0.8, \n        \"xtick.major.width\": 0.8,\n        \"ytick.major.width\": 0.8,\n        \"lines.linewidth\": 1.0,\n    })\n\n    \n    compute_analysis(input_folder=folder, output_folder=folder, sizes=n_list, dim=2)\n    analysis_data = load_analysis(folder=folder, sizes=n_list)\n    \n    # binder_range_low = 2.26\n    # binder_range_high = 2.3\n    \n    binder_range_low = 2.1\n    binder_range_high = 2.5\n    \n    intersection_range_low = 2.26\n    intersection_range_high = 2.27\n   \n    high_T_threshold = 3.0\n    \n    # binder_range_low = 4.4\n    # binder_range_high = 4.6\n    #plot_binder_values(analysis_data, custom_T_low=binder_range_low, custom_T_high=binder_range_high)\n    \n    \n    intersections = calculate_all_intersections(analysis_data, \n                                               custom_T_low=intersection_range_low, \n                                               custom_T_high=intersection_range_high)\n    # plot_all_intersections(analysis_data, intersections, zoom_margin=0.005, custom_T_low=2.2, custom_T_high=2.3)\n    \n    #plot_all_intersections(analysis_data, intersections, zoom_margin=0.005, custom_T_low=2.2685, custom_T_high=2.2695)\n    # plot_all_intersections(analysis_data, intersections, zoom_margin=0.005, custom_T_low=4.5, custom_T_high=4.515)\n    critical_temps, ref_size = calculate_critical_temperatures(analysis_data, custom_T_low=intersection_range_low, \n    custom_T_high=intersection_range_high )\n    \n    #plot_critical_temperatures(critical_temps, ref_size)\n    \n    observables_data = load_observables_extended(input_folder=folder, sizes=n_list)\n    \n    plot_observables(observables_data)\n    \n    T_target = 2.26\n    #plot_corr_linear(observables_data, T_targets=(2.269, 3))\n\n\n    plot_correlation_length(observables_data)\n    #plot_fss_xi(observables_data, T_target=T_target)\n\n    plot_loglog_observables(observables_data, intersections, Tc_avg=2.269, \n                        reduced_range_low=0.005, reduced_range_high=1, side='lower')\n\n\n    # plot_observable_errors(observables_data)\n    #plot_Cv_fss(observables_data, Tc=2.269)\n    #plot_semi_log_specific_heat(observables_data, Tc=2.269, T_range=(2, 2.269))\n\n    plot_mag_vs_iterations_comparison(\n        primary_folder=\"wolfs1\",\n        secondary_folder=\"metropolis1\",\n        temperature=2.275,\n        system_size=32,\n        max_iterations=500  \n    )\n    critical_temps, reference_size = calculate_critical_temperatures(analysis_data, \n                                      custom_T_low=intersection_range_low, \n                                      custom_T_high=intersection_range_high)\n    plot_binder_values_with_critical(analysis_data, critical_temps, reference_size, \n                                         custom_T_low=None, custom_T_high=None,\n                                         inset_xlim=None, inset_ylim=None,\n                                         binder_text=\"(a)\", binder_text_pos=(0.55, 0.90),\n                                         inset_text=\"(b)\", inset_text_pos=(0.1, 0.85))",
    "crumbs": [
      "Main Code",
      "Analysis Code"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Information",
    "section": "",
    "text": "Information\nIsing Model Project Lab Book - Giancarlo Ramirez\nemail: zj22662@bristol.ac.uk",
    "crumbs": [
      "Information"
    ]
  },
  {
    "objectID": "notebook.html",
    "href": "notebook.html",
    "title": "Example in jupyter",
    "section": "",
    "text": "from __future__ import division\nimport numpy as np\nfrom numpy.random import rand\nimport matplotlib.pyplot as plt\n\n\n#----------------------------------------------------------------------\n##  BLOCK OF FUNCTIONS USED IN THE MAIN CODE\n#----------------------------------------------------------------------\ndef initialstate(N):   \n    ''' generates a random spin configuration for initial condition'''\n    state = 2*np.random.randint(2, size=(N,N))-1\n    return state\n\n\ndef mcmove(config, beta):\n    '''Monte Carlo move using Metropolis algorithm '''\n    for i in range(N):\n        for j in range(N):\n                a = np.random.randint(0, N)\n                b = np.random.randint(0, N)\n                s =  config[a, b]\n                nb = config[(a+1)%N,b] + config[a,(b+1)%N] + config[(a-1)%N,b] + config[a,(b-1)%N]\n                cost = 2*s*nb\n                if cost &lt; 0:\n                    s *= -1\n                elif rand() &lt; np.exp(-cost*beta):\n                    s *= -1\n                config[a, b] = s\n    return config\n\n\ndef calcEnergy(config):\n    '''Energy of a given configuration'''\n    energy = 0\n    for i in range(len(config)):\n        for j in range(len(config)):\n            S = config[i,j]\n            nb = config[(i+1)%N, j] + config[i,(j+1)%N] + config[(i-1)%N, j] + config[i,(j-1)%N]\n            energy += -nb*S\n    return energy/4.\n\n\ndef calcMag(config):\n    '''Magnetization of a given configuration'''\n    mag = np.sum(config)\n    return mag\n\n\n## change these parameters for a smaller (faster) simulation \nnt      = 4        #  number of temperature points\nN       = 16         #  size of the lattice, N x N\neqSteps = 1024       #  number of MC sweeps for equilibration\nmcSteps = 1024       #  number of MC sweeps for calculation\n\nT       = np.linspace(1.53, 3.28, nt) \nE,M,C,X = np.zeros(nt), np.zeros(nt), np.zeros(nt), np.zeros(nt)\nn1, n2  = 1.0/(mcSteps*N*N), 1.0/(mcSteps*mcSteps*N*N) \n# divide by number of samples, and by system size to get intensive values\n\n7 mins nt = 10 # number of temperature points N = 32 # size of the lattice, N x N eqSteps = 1024 # number of MC sweeps for equilibration mcSteps = 1024 # number of MC sweeps for calculation\n20seconds nt = 4 N = 16\n\n#----------------------------------------------------------------------\n#  MAIN PART OF THE CODE\n#----------------------------------------------------------------------\nfor tt in range(nt):\n    print(tt)\n    E1 = M1 = E2 = M2 = 0\n    config = initialstate(N)\n    iT=1.0/T[tt]; iT2=iT*iT;\n    \n    for i in range(eqSteps):         # equilibrate\n        mcmove(config, iT)           # Monte Carlo moves\n\n    for i in range(mcSteps):\n        mcmove(config, iT)           \n        Ene = calcEnergy(config)     # calculate the energy\n        Mag = calcMag(config)        # calculate the magnetisation\n\n        E1 = E1 + Ene\n        M1 = M1 + Mag\n        M2 = M2 + Mag*Mag \n        E2 = E2 + Ene*Ene\n\n    E[tt] = n1*E1\n    M[tt] = n1*M1\n    C[tt] = (n1*E2 - n2*E1*E1)*iT2\n    X[tt] = (n1*M2 - n2*M1*M1)*iT\n\n0\n1\n2\n3\n\n\n\nf = plt.figure(figsize=(9, 5)); # plot the calculated values    \n\nsp =  f.add_subplot(1, 1, 1 );\nplt.scatter(T, E, s=50, marker='o', color='IndianRed')\nplt.xlabel(\"Temperature (T)\", fontsize=20);\nplt.ylabel(\"Energy \", fontsize=20);         plt.axis('tight');\n\nsp =  f.add_subplot(1, 1, 2 );\nplt.scatter(T, abs(M), s=50, marker='o', color='RoyalBlue')\nplt.xlabel(\"Temperature (T)\", fontsize=20); \nplt.ylabel(\"Magnetization \", fontsize=20);   plt.axis('tight');\n\nsp =  f.add_subplot(1, 1, 3 );\nplt.scatter(T, C, s=50, marker='o', color='IndianRed')\nplt.xlabel(\"Temperature (T)\", fontsize=20);  \nplt.ylabel(\"Specific Heat \", fontsize=20);   plt.axis('tight');   \n\nsp =  f.add_subplot(1, 1, 4 );\nplt.scatter(T, X, s=50, marker='o', color='RoyalBlue')\nplt.xlabel(\"Temperature (T)\", fontsize=20); \nplt.ylabel(\"Susceptibility\", fontsize=20);   plt.axis('tight');\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[24], line 8\n      5 plt.xlabel(\"Temperature (T)\", fontsize=20);\n      6 plt.ylabel(\"Energy \", fontsize=20);         plt.axis('tight');\n----&gt; 8 sp =  f.add_subplot(1, 1, 2 );\n      9 plt.scatter(T, abs(M), s=50, marker='o', color='RoyalBlue')\n     10 plt.xlabel(\"Temperature (T)\", fontsize=20); \n\nFile ~/Documents/Ising_Project/minimal-quarto-lab-book/venv/lib/python3.13/site-packages/matplotlib/figure.py:768, in FigureBase.add_subplot(self, *args, **kwargs)\n    766         args = tuple(map(int, str(args[0])))\n    767     projection_class, pkw = self._process_projection_requirements(**kwargs)\n--&gt; 768     ax = projection_class(self, *args, **pkw)\n    769     key = (projection_class, pkw)\n    770 return self._add_axes_internal(ax, key)\n\nFile ~/Documents/Ising_Project/minimal-quarto-lab-book/venv/lib/python3.13/site-packages/matplotlib/axes/_base.py:656, in _AxesBase.__init__(self, fig, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, forward_navigation_events, *args, **kwargs)\n    654 else:\n    655     self._position = self._originalPosition = mtransforms.Bbox.unit()\n--&gt; 656     subplotspec = SubplotSpec._from_subplot_args(fig, args)\n    657 if self._position.width &lt; 0 or self._position.height &lt; 0:\n    658     raise ValueError('Width and height specified must be non-negative')\n\nFile ~/Documents/Ising_Project/minimal-quarto-lab-book/venv/lib/python3.13/site-packages/matplotlib/gridspec.py:589, in SubplotSpec._from_subplot_args(figure, args)\n    587 else:\n    588     if not isinstance(num, Integral) or num &lt; 1 or num &gt; rows*cols:\n--&gt; 589         raise ValueError(\n    590             f\"num must be an integer with 1 &lt;= num &lt;= {rows*cols}, \"\n    591             f\"not {num!r}\"\n    592         )\n    593     i = j = num\n    594 return gs[i-1:j]\n\nValueError: num must be an integer with 1 &lt;= num &lt;= 1, not 2\n\n\n\n\n\n\n\n\n\n\n\nclass Ising():\n    ''' Simulating the Ising model '''    \n    ## monte carlo moves\n    def mcmove(self, config, N, beta):\n        ''' This is to execute the monte carlo moves using \n        Metropolis algorithm such that detailed\n        balance condition is satisified'''\n        for i in range(N):\n            for j in range(N):            \n                    a = np.random.randint(0, N)\n                    b = np.random.randint(0, N)\n                    s =  config[a, b]\n                    nb = config[(a+1)%N,b] + config[a,(b+1)%N] + config[(a-1)%N,b] + config[a,(b-1)%N]\n                    cost = 2*s*nb\n                    if cost &lt; 0:    \n                        s *= -1\n                    elif rand() &lt; np.exp(-cost*beta):\n                        s *= -1\n                    config[a, b] = s\n        return config\n    \n    def simulate(self):   \n        ''' This module simulates the Ising model'''\n        N, temp     = 64, .4        # Initialse the lattice\n        config = 2*np.random.randint(2, size=(N,N))-1\n        f = plt.figure(figsize=(15, 15), dpi=80);    \n        self.configPlot(f, config, 0, N, 1);\n        \n        msrmnt = 1001\n        for i in range(msrmnt):\n            self.mcmove(config, N, 1.0/temp)\n            if i == 1:       self.configPlot(f, config, i, N, 2);\n            if i == 4:       self.configPlot(f, config, i, N, 3);\n            if i == 32:      self.configPlot(f, config, i, N, 4);\n            if i == 100:     self.configPlot(f, config, i, N, 5);\n            if i == 1000:    self.configPlot(f, config, i, N, 6);\n                 \n                    \n    def configPlot(self, f, config, i, N, n_):\n        ''' This modules plts the configuration once passed to it along with time etc '''\n        X, Y = np.meshgrid(range(N), range(N))\n        sp =  f.add_subplot(3, 3, n_ )  \n        plt.setp(sp.get_yticklabels(), visible=False)\n        plt.setp(sp.get_xticklabels(), visible=False)      \n        plt.pcolormesh(X, Y, config, cmap=plt.cm.RdBu);\n        plt.title('Time=%d'%i); plt.axis('tight')    \n    plt.show()\n\n\nrm = Ising()\n\n\nrm.simulate()"
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "Week 1",
    "section": "",
    "text": "Topics:\n\nRenormalisation\nCritical exponents\nScaling laws\nPhase transitions\nClusters\nFundamental model\nMetropolis algorithm\nBlueCrystal HPC\n\nResearch and understand/experiment with code\nAim idea: ‘create popular account using research as structure’\n\n\n\n\n\nIntro\n\nMonte Carlo sampling method\nUse Ising to model magnetism, understand magnetic phase transition\nMain: 2D-square lattice, investigate parameters close to phase transition\nExtra: exact solution 1D, Potts/XY models 2D\n\nPhase transitions\n\nVan der Waals example, gas doesn’t resist being compressed —&gt; must have phase transition\nMagnetism\n\nAll sites spin up/down\nNeighbouring atoms favour same direction, absolute zero has ground states ,all down(m=-ve)/up(m=+ve)\nAbove T=0, entropy favours random spin, high temperatures —&gt; p=1/2 for up/down —&gt; M=0 (zero external field)\nCritical temp T_c when M=0\n\nOther PT’s: superfluids, superconductors\nPT example of spontaneously-broken symmetry\n\nIsing Model\n\nEach site assigned spin value σ = ±1 (up or down)\nEnergy Hamiltonian, H = − Σ J.σ_i.σ_j − Σ B.σ_i , can be hard to calculate, N sites —&gt; 2^N configurations of system\nFirst Σ over all NN’s (2D - 4 bonds),\n\nJ: exchange energy,\n\nJ &lt; 0 —&gt; system favours NN’s same direction spin (ferromagnet), J&gt;0 —&gt; anti-ferromagnet\n\n\nNote: not using SI units in computation , (σ =±ℏ/2)\nNote: real magnetic system, spin can be in any direction —&gt;crystal lattice leads to preferred directions —&gt; ‘spin-orbit’ coupling\nNote: Ising model can be used to model any system where each lattices site has two possible states\n\nStatistical Physics\n\nProbability of state occurring = p = (1/Z).(exp (−H/kBT))\nPartition function (Z) encodes other observables: Z = Σexp (−H/kBT), sum over all states\n\nU =  = - ∂ln(Z)/∂β = (1/Z).ΣH.exp(−H/k_B.T), β = 1/kBT\nF = −kBT ln (Z) : Helmholtz free energy\n\ndF = −SdT + MdB\nS = ∂F/∂T\n\nS = −k_B.Σp.ln(p) , ’Shannon Entropy\n\nM = ∂F/∂B\n\nM = Σ &lt;σ&gt; = ∂/∂B\n\n\n\n\nSingle site exact solution\n\nH = -Bσ = ±B , (σ = ±1)\nZ = exp (−B/kBT) + exp (B/k_B.T)\n&lt;σ&gt; = (1/Z). Σσ.exp(−H/k_B.T) = tanh (B/k_B.T)\nExercise in notebook?\n\nMean-Field Theory\n\nAssume each site experiences NN’s effects as an average effective energy\nH = − ΣB_eff.σ_i , B_eff = B + J.&lt;σ&gt;.z , z = No. Neighbours\nEach spin equivalent on average, each neighbour has same average spin\n2D-square-lattice —&gt; B_eff = B + 4.J.&lt;σ&gt;\n\nFrom single site equation, &lt;σ&gt; = tanh (B_eff /k_B.T) = tanh (B + 4.J.&lt;σ&gt; /k_B.T)\n\nTransendental equation\nIf parameter are such that zJ/kBT &gt; 1, in addition to trivial sol. &lt;σ&gt; = 0, there are two others &lt;σ&gt; &gt; 0 & &lt;σ&gt; &lt; 0\n\nSystem will spontaneously choose of these solutions &lt;—&gt; ferromagnet with spontaneous magnetic moment\nThis happens in the approx solution at T_c = z.J/k_B\nExample of Symmetry Breaking\n\n\n\n\n\n\n\n\nMetrolopolis Algorithms\n\n1: Initialise random starting configuration\n2: Choose one site randomly, calculate energy change of system if spin flipped\n3: If energy reduced –&gt; flip spin, If not –&gt; generate random number 0&lt;p&lt;1, flip if p&lt;exp(-k_b.t.delta_E), [flip with probability = boltzman factor]\n4: Iterate steps 2 and 3 until maximum number of monte carlo (MC) steps reached, observables calculated from all accepted configurations\n\nThings to calulcate\n\nRunning time as function of size of the box\nRunning time as function of total MC steps\ndeviations of numerically calulcated magnetisation from analytical solution (SEE https://en.wikipedia.org/wiki/Square_lattice_Ising_model#Exact_solution)\ncharacteristic configurations patterns for different temperatures\nexploit finite size scaling\n\n\n\n\n\n\nhttps://www.youtube.com/watch?v=OgO1gpXSUzU\nhttps://www.youtube.com/watch?v=EaR3C4e600k\nBasically random sampling and using law of large numbers (as no.trials increases –&gt; average of samples converges to true expected value)",
    "crumbs": [
      "Week 1"
    ]
  },
  {
    "objectID": "week1.html#initial-meeting",
    "href": "week1.html#initial-meeting",
    "title": "Week 1",
    "section": "",
    "text": "Topics:\n\nRenormalisation\nCritical exponents\nScaling laws\nPhase transitions\nClusters\nFundamental model\nMetropolis algorithm\nBlueCrystal HPC\n\nResearch and understand/experiment with code\nAim idea: ‘create popular account using research as structure’",
    "crumbs": [
      "Week 1"
    ]
  },
  {
    "objectID": "week1.html#pdf-session-1---key-concepts-and-background",
    "href": "week1.html#pdf-session-1---key-concepts-and-background",
    "title": "Week 1",
    "section": "",
    "text": "Intro\n\nMonte Carlo sampling method\nUse Ising to model magnetism, understand magnetic phase transition\nMain: 2D-square lattice, investigate parameters close to phase transition\nExtra: exact solution 1D, Potts/XY models 2D\n\nPhase transitions\n\nVan der Waals example, gas doesn’t resist being compressed —&gt; must have phase transition\nMagnetism\n\nAll sites spin up/down\nNeighbouring atoms favour same direction, absolute zero has ground states ,all down(m=-ve)/up(m=+ve)\nAbove T=0, entropy favours random spin, high temperatures —&gt; p=1/2 for up/down —&gt; M=0 (zero external field)\nCritical temp T_c when M=0\n\nOther PT’s: superfluids, superconductors\nPT example of spontaneously-broken symmetry\n\nIsing Model\n\nEach site assigned spin value σ = ±1 (up or down)\nEnergy Hamiltonian, H = − Σ J.σ_i.σ_j − Σ B.σ_i , can be hard to calculate, N sites —&gt; 2^N configurations of system\nFirst Σ over all NN’s (2D - 4 bonds),\n\nJ: exchange energy,\n\nJ &lt; 0 —&gt; system favours NN’s same direction spin (ferromagnet), J&gt;0 —&gt; anti-ferromagnet\n\n\nNote: not using SI units in computation , (σ =±ℏ/2)\nNote: real magnetic system, spin can be in any direction —&gt;crystal lattice leads to preferred directions —&gt; ‘spin-orbit’ coupling\nNote: Ising model can be used to model any system where each lattices site has two possible states\n\nStatistical Physics\n\nProbability of state occurring = p = (1/Z).(exp (−H/kBT))\nPartition function (Z) encodes other observables: Z = Σexp (−H/kBT), sum over all states\n\nU =  = - ∂ln(Z)/∂β = (1/Z).ΣH.exp(−H/k_B.T), β = 1/kBT\nF = −kBT ln (Z) : Helmholtz free energy\n\ndF = −SdT + MdB\nS = ∂F/∂T\n\nS = −k_B.Σp.ln(p) , ’Shannon Entropy\n\nM = ∂F/∂B\n\nM = Σ &lt;σ&gt; = ∂/∂B\n\n\n\n\nSingle site exact solution\n\nH = -Bσ = ±B , (σ = ±1)\nZ = exp (−B/kBT) + exp (B/k_B.T)\n&lt;σ&gt; = (1/Z). Σσ.exp(−H/k_B.T) = tanh (B/k_B.T)\nExercise in notebook?\n\nMean-Field Theory\n\nAssume each site experiences NN’s effects as an average effective energy\nH = − ΣB_eff.σ_i , B_eff = B + J.&lt;σ&gt;.z , z = No. Neighbours\nEach spin equivalent on average, each neighbour has same average spin\n2D-square-lattice —&gt; B_eff = B + 4.J.&lt;σ&gt;\n\nFrom single site equation, &lt;σ&gt; = tanh (B_eff /k_B.T) = tanh (B + 4.J.&lt;σ&gt; /k_B.T)\n\nTransendental equation\nIf parameter are such that zJ/kBT &gt; 1, in addition to trivial sol. &lt;σ&gt; = 0, there are two others &lt;σ&gt; &gt; 0 & &lt;σ&gt; &lt; 0\n\nSystem will spontaneously choose of these solutions &lt;—&gt; ferromagnet with spontaneous magnetic moment\nThis happens in the approx solution at T_c = z.J/k_B\nExample of Symmetry Breaking",
    "crumbs": [
      "Week 1"
    ]
  },
  {
    "objectID": "week1.html#ising-exercise-powerpoints",
    "href": "week1.html#ising-exercise-powerpoints",
    "title": "Week 1",
    "section": "",
    "text": "Metrolopolis Algorithms\n\n1: Initialise random starting configuration\n2: Choose one site randomly, calculate energy change of system if spin flipped\n3: If energy reduced –&gt; flip spin, If not –&gt; generate random number 0&lt;p&lt;1, flip if p&lt;exp(-k_b.t.delta_E), [flip with probability = boltzman factor]\n4: Iterate steps 2 and 3 until maximum number of monte carlo (MC) steps reached, observables calculated from all accepted configurations\n\nThings to calulcate\n\nRunning time as function of size of the box\nRunning time as function of total MC steps\ndeviations of numerically calulcated magnetisation from analytical solution (SEE https://en.wikipedia.org/wiki/Square_lattice_Ising_model#Exact_solution)\ncharacteristic configurations patterns for different temperatures\nexploit finite size scaling",
    "crumbs": [
      "Week 1"
    ]
  },
  {
    "objectID": "week1.html#monte-carlo-method-videos",
    "href": "week1.html#monte-carlo-method-videos",
    "title": "Week 1",
    "section": "",
    "text": "https://www.youtube.com/watch?v=OgO1gpXSUzU\nhttps://www.youtube.com/watch?v=EaR3C4e600k\nBasically random sampling and using law of large numbers (as no.trials increases –&gt; average of samples converges to true expected value)",
    "crumbs": [
      "Week 1"
    ]
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "Week 3",
    "section": "",
    "text": "- Kurtosis/ Binder Parameter \n    - measure of \"gausian'ness\" \n    - can capture change in distribution\n- Finite size scaling\n    - plot different size systems on kurtosis vs temp\n    - all approach same value near criticality\n    - can be used to approximate critical temperature\n- Applying slight field can make system prefer one spin direction\n-Numba package\n    - Just in time computation\n    - @numba.njit decorator above function\n- Critical slowing down\n    - approaching critical point from above, system takes longer to be change\n    - Cluster move algorithms\n        - Swendsen\n        - Woldd\n    - Locality, equilibrium\n- Measuring cluster sizes?\n\n\n\n- Get plots for observables vs iterations\n- understand how to extract kurtosis efficiently for different temperatures\n- get to a plot of kurtosis vs temperature with different size systems\n\n\n\n- reworked the main code to simulate for different sizes of system --&gt; different temperatures\n- used namba to speed up alot of functions\n- created plotting functions\n    -statistic vs temperature --- different system sizes\n    -obvservable vs iteration --- \n\n\n\n- adapted code to save data",
    "crumbs": [
      "Week 3"
    ]
  },
  {
    "objectID": "week3.html#meeting",
    "href": "week3.html#meeting",
    "title": "Week 3",
    "section": "",
    "text": "- Kurtosis/ Binder Parameter \n    - measure of \"gausian'ness\" \n    - can capture change in distribution\n- Finite size scaling\n    - plot different size systems on kurtosis vs temp\n    - all approach same value near criticality\n    - can be used to approximate critical temperature\n- Applying slight field can make system prefer one spin direction\n-Numba package\n    - Just in time computation\n    - @numba.njit decorator above function\n- Critical slowing down\n    - approaching critical point from above, system takes longer to be change\n    - Cluster move algorithms\n        - Swendsen\n        - Woldd\n    - Locality, equilibrium\n- Measuring cluster sizes?",
    "crumbs": [
      "Week 3"
    ]
  },
  {
    "objectID": "week3.html#coding-plan",
    "href": "week3.html#coding-plan",
    "title": "Week 3",
    "section": "",
    "text": "- Get plots for observables vs iterations\n- understand how to extract kurtosis efficiently for different temperatures\n- get to a plot of kurtosis vs temperature with different size systems",
    "crumbs": [
      "Week 3"
    ]
  },
  {
    "objectID": "week3.html#coding-work",
    "href": "week3.html#coding-work",
    "title": "Week 3",
    "section": "",
    "text": "- reworked the main code to simulate for different sizes of system --&gt; different temperatures\n- used namba to speed up alot of functions\n- created plotting functions\n    -statistic vs temperature --- different system sizes\n    -obvservable vs iteration ---",
    "crumbs": [
      "Week 3"
    ]
  },
  {
    "objectID": "week3.html#final-meeting",
    "href": "week3.html#final-meeting",
    "title": "Week 3",
    "section": "",
    "text": "- adapted code to save data",
    "crumbs": [
      "Week 3"
    ]
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "Week 5",
    "section": "",
    "text": "- Report\n    - talking report structure\n    - blackboard latex template\n    - how to find references\n    - zotero\n    - zotero overleaf\n- Code \n    - make sure graphs look good in report\n    - explore Renormalisation\n\n\n\n- make sure error bars are valid\n- read through book and try to code 3x3 renormalisation graph\n- show errors decrease with run time, large N has higher error right now\n- create plan for writeup (probably do first to orient other avenues)\n- other Ideas  \n    - extend to xy model, 3d model\n    - implement other resampling methods (e.g. jackknife)\n    - cluster algorithms to explore closer to critical temp\n    - explore different lattice geometries\n\nError handling\n- made sure all errors was plotted\n    - took mean and standard error from time series of magnetisation and energy for each temperature\n    - used those errors and propogated for the binder cumulant\n    - \n\n\n\n- Introduction (1/2 page)\n    - Background and Motivation\n        - Phase transition/critcality ---&gt; Ising Model\n- Theory (1 1/2 page)\n    - Ising Model\n    - Behavior at critical temperature\n    - critical exponents\n    - need for numerical simulation\n- Methods (1/2 page)\n    - Algorithmic details (Metropolis Algorithm)\n    - Error analysis \n    - Binder cumulant to find Critical temperature\n    - Using critical temperature to extract critical exponents\n- Results (1 page)\n    - Observables analysis\n    - Binder Cumulant analysis\n    - Critical Exponents analysis  \n    - Error vs temperature analysis\n- Conclusion\n    -?\n- Bibliogrphy",
    "crumbs": [
      "Week 5"
    ]
  },
  {
    "objectID": "week5.html#morning-meeting",
    "href": "week5.html#morning-meeting",
    "title": "Week 5",
    "section": "",
    "text": "- Report\n    - talking report structure\n    - blackboard latex template\n    - how to find references\n    - zotero\n    - zotero overleaf\n- Code \n    - make sure graphs look good in report\n    - explore Renormalisation",
    "crumbs": [
      "Week 5"
    ]
  },
  {
    "objectID": "week5.html#potential-to-dos",
    "href": "week5.html#potential-to-dos",
    "title": "Week 5",
    "section": "",
    "text": "- make sure error bars are valid\n- read through book and try to code 3x3 renormalisation graph\n- show errors decrease with run time, large N has higher error right now\n- create plan for writeup (probably do first to orient other avenues)\n- other Ideas  \n    - extend to xy model, 3d model\n    - implement other resampling methods (e.g. jackknife)\n    - cluster algorithms to explore closer to critical temp\n    - explore different lattice geometries\n\nError handling\n- made sure all errors was plotted\n    - took mean and standard error from time series of magnetisation and energy for each temperature\n    - used those errors and propogated for the binder cumulant\n    -",
    "crumbs": [
      "Week 5"
    ]
  },
  {
    "objectID": "week5.html#write-up-plan",
    "href": "week5.html#write-up-plan",
    "title": "Week 5",
    "section": "",
    "text": "- Introduction (1/2 page)\n    - Background and Motivation\n        - Phase transition/critcality ---&gt; Ising Model\n- Theory (1 1/2 page)\n    - Ising Model\n    - Behavior at critical temperature\n    - critical exponents\n    - need for numerical simulation\n- Methods (1/2 page)\n    - Algorithmic details (Metropolis Algorithm)\n    - Error analysis \n    - Binder cumulant to find Critical temperature\n    - Using critical temperature to extract critical exponents\n- Results (1 page)\n    - Observables analysis\n    - Binder Cumulant analysis\n    - Critical Exponents analysis  \n    - Error vs temperature analysis\n- Conclusion\n    -?\n- Bibliogrphy",
    "crumbs": [
      "Week 5"
    ]
  }
]