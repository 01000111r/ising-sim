[
  {
    "objectID": "analysis_text.html",
    "href": "analysis_text.html",
    "title": "Analysis Code",
    "section": "",
    "text": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\nimport natsort\nimport os\nfrom scipy.interpolate import UnivariateSpline\nfrom scipy.optimize import brentq\n\ndef compute_analysis(input_folder, output_folder, sizes):\n    \"\"\"\n    \n\n    Parameters\n    ----------\n    input_folder : TYPE string\n        DESCRIPTION. string of input folder name in repo directory\n    output_folder : TYPE string\n        DESCRIPTION. string of input folder name in repo directory\n    sizes : TYPE list\n        DESCRIPTION. list of system sizes in input folder\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    #create new folder if dosnt exist\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n        \n    for N in sizes:\n        #open file/ create new one\n        analysis_file = os.path.join(output_folder, f\"Analysis_N{N}.npz\")\n        #skip if file exits\n        if os.path.exists(analysis_file):\n            print(f\"Analysis file for N={N} already exists. Skipping computation.\")\n            continue\n        #collect and sort runs associated with system size N\n        files = natsort.natsorted(glob.glob(f\"{input_folder}/*N{N}*.npz\"))\n        \n        print(f\"Processing system size N={N}\")\n        \n        #initialising main arrays\n        t_vals = []\n        binder_vals = []\n        binder_errs = []\n        e_means = []\n        e_errs = []\n        mag_means = []\n        mag_errs = []\n        sus_vals = []\n        sus_errs = []\n        s_heat_vals = []\n        s_heat_errs = []\n        \n        for f in files:\n            \n            data = np.load(f)\n            \n            try:\n                #extract temp value from filename (cheapskate method)\n                T = float(f.split(\"T\")[1].split(\"N\")[0])\n            except Exception as e:\n                print(f\"Error parsing temperature from {f}: {e}\")\n                continue\n            # Magnetisation calculations\n            mag = data['magnetisation']\n    \n            n_mag = len(mag)\n            m_mean = np.mean(mag)\n            m_std = np.std(mag, ddof=1)\n            m_err = m_std / np.sqrt(n_mag)\n            \n            m2 = np.mean(mag**2)\n            m4 = np.mean(mag**4)\n            \n            std_m2 = np.std(mag**2, ddof=1)\n            std_m4 = np.std(mag**4, ddof=1)\n            \n            err_m2 = std_m2 / np.sqrt(n_mag)\n            err_m4 = std_m4 / np.sqrt(n_mag)\n            \n            if m2 == 0:\n                continue\n            # Binder calculations\n            binder = 1 - m4 / (3 * m2**2)\n            binder_err = np.sqrt(((2 * m4 / (3 * m2**3)) * err_m2)**2 + ((1 / (3 * m2**2)) * err_m4)**2)\n            \n            #Energy calculations\n            e = data['energy']\n            n_e = len(e)\n            e_mean = np.mean(e)\n            e_std = np.std(e, ddof=1)\n            e_err = e_std / np.sqrt(n_e)\n            \n            #Susceptibility and specific heat calculations\n            beta = 1.0 / T\n            \n            sus_val = beta * (m2 - m_mean**2)\n            error_f = np.sqrt(err_m2**2 + (2 * m_mean * m_err)**2)\n            sus_err = beta * error_f\n            \n            e2 = np.mean(e**2)\n            std_e2 = np.std(e**2, ddof=1)\n            \n            e2_err = std_e2 / np.sqrt(n_e)\n            s_heat_val = beta**2 * (e2 - e_mean**2)\n            s_heat_err = beta**2 * np.sqrt(e2_err**2 + (2 * e_mean * e_err)**2)\n\n            #append all values to main lists\n            t_vals.append(T)\n            binder_vals.append(binder)\n            binder_errs.append(binder_err)\n            e_means.append(e_mean)\n            e_errs.append(e_err)\n            mag_means.append(m_mean)\n            mag_errs.append(m_err)\n            sus_vals.append(sus_val)\n            sus_errs.append(sus_err)\n            s_heat_vals.append(s_heat_val)\n            s_heat_errs.append(s_heat_err)\n            \n        #sorting index\n        sort_idx = np.argsort(t_vals)\n        \n        #save arrays to associated system size N file names \n        np.savez(analysis_file,\n                 t_vals=np.array(t_vals)[sort_idx],\n                 binder_vals=np.array(binder_vals)[sort_idx],\n                 binder_errs=np.array(binder_errs)[sort_idx],\n                 e_means=np.array(e_means)[sort_idx],\n                 e_errs=np.array(e_errs)[sort_idx],\n                 mag_means=np.array(mag_means)[sort_idx],\n                 mag_errs=np.array(mag_errs)[sort_idx],\n                 sus_vals=np.array(sus_vals)[sort_idx],\n                 sus_errs=np.array(sus_errs)[sort_idx],\n                 s_heat_vals=np.array(s_heat_vals)[sort_idx],\n                 s_heat_errs=np.array(s_heat_errs)[sort_idx])\n        \n        print(f\"Saved analysis for N={N} to {analysis_file}\")\n\ndef load_analysis(folder=\"data6\", sizes=[8, 16, 32]):\n    analysis_data = {}\n    for N in sizes:\n        filename = os.path.join(folder, f\"Analysis_N{N}.npz\")\n        if os.path.exists(filename):\n            data = np.load(filename)\n            analysis_data[N] = {\"t_vals\": data[\"t_vals\"],\n                              \"binder_vals\": data[\"binder_vals\"],\n                              \"binder_errs\": data[\"binder_errs\"],\n                              \"e_means\": data[\"e_means\"],\n                              \"e_errs\": data[\"e_errs\"],\n                              \"mag_means\": data[\"mag_means\"],\n                              \"mag_errs\": data[\"mag_errs\"],\n                              \"sus_vals\": data[\"sus_vals\"],\n                              \"sus_errs\": data[\"sus_errs\"],\n                              \"s_heat_vals\": data[\"s_heat_vals\"],\n                              \"s_heat_errs\": data[\"s_heat_errs\"]}\n        else:\n            print(f\"Binder file not found for N={N}.\")\n    return analysis_data\n\ndef plot_binder_values(analysis_data):\n    plt.figure(figsize=(8, 6))\n    for N, data in analysis_data.items():\n        plt.errorbar(data[\"t_vals\"], data[\"binder_vals\"], yerr=data[\"binder_errs\"],\n                     fmt='o', label=f\"N={N}\", ecolor='black', capsize=5, alpha=0.5)\n    plt.axvline(x=2.269, color='red', linestyle='--', label=\"Expected $T_c$ (2.269)\")\n    plt.xlabel(\"Temperature T\")\n    plt.ylabel(\"Binder Cumulant\")\n    plt.legend()\n    plt.grid(True)\n    plt.title(\"Binder Cumulant vs. Temperature\")\n    plt.show()\n\ndef build_splines(analysis_data, s=0):\n    splines = {}\n    for N, data in analysis_data.items():\n        T = data[\"t_vals\"]\n        binder = data[\"binder_vals\"]\n        spline = UnivariateSpline(T, binder, s=s)\n        binder_error = data[\"binder_errs\"]\n        error_spline = UnivariateSpline(T, binder_error, s=s)\n        splines[N] = {\"spline\": spline, \"error_spline\": error_spline}\n    return splines\n\ndef find_intersection(spline1, spline2, error_spline1, error_spline2, T_min, T_max, num_points=1000):\n    T_values = np.linspace(T_min, T_max, num_points)\n    diff = spline1(T_values) - spline2(T_values)\n    for i in range(len(diff) - 1):\n        if diff[i] * diff[i+1] &lt; 0:\n            try:\n                Tc = brentq(lambda T: spline1(T) - spline2(T), T_values[i], T_values[i+1])\n                d_diff_dT = spline1.derivative()(Tc) - spline2.derivative()(Tc)\n                err1 = error_spline1(Tc)\n                err2 = error_spline2(Tc)\n                Tc_error = np.sqrt(err1**2 + err2**2) / np.abs(d_diff_dT) if d_diff_dT != 0 else np.inf\n                return Tc, Tc_error\n            except ValueError:\n                continue\n    return None, None\n\ndef calculate_all_intersections(analysis_data, s=0):\n    splines = build_splines(analysis_data, s=s)\n    intersection_dict = {}\n    sizes = sorted(analysis_data.keys())\n    for i in range(len(sizes)):\n        for j in range(i+1, len(sizes)):\n            N1 = sizes[i]\n            N2 = sizes[j]\n            T_min = max(np.min(analysis_data[N1][\"t_vals\"]), np.min(analysis_data[N2][\"t_vals\"]))\n            T_max = min(np.max(analysis_data[N1][\"t_vals\"]), np.max(analysis_data[N2][\"t_vals\"]))\n            Tc, Tc_error = find_intersection(splines[N1][\"spline\"], splines[N2][\"spline\"],\n                                             splines[N1][\"error_spline\"], splines[N2][\"error_spline\"],\n                                             T_min, T_max)\n            if Tc is not None:\n                intersection_dict[(N1, N2)] = (Tc, Tc_error)\n                print(f\"Intersection for N={N1} and N={N2}: Tc = {Tc:.4f} ± {Tc_error:.4f}\")\n            else:\n                print(f\"No intersection found for N={N1} and N={N2}.\")\n    return intersection_dict\n\n# def save_intersections(intersections, filename=\"critical_intersections.npz\"):\n#     intersections_to_save = {f\"{k[0]}_{k[1]}\": np.array(v) for k, v in intersections.items()}\n#     np.savez(filename, **intersections_to_save)\n#     print(f\"Saved intersections to {filename}\")\n\ndef calculate_critical_temperatures(analysis_data):\n    splines = build_splines(analysis_data)\n    reference_size = min(analysis_data.keys())\n    ref_spline = splines[reference_size][\"spline\"]\n    ref_error_spline = splines[reference_size][\"error_spline\"]\n    critical_temps = {}\n    for N, spline_data in splines.items():\n        if N == reference_size:\n            continue\n        T_min = max(np.min(analysis_data[reference_size][\"t_vals\"]), np.min(analysis_data[N][\"t_vals\"]))\n        T_max = min(np.max(analysis_data[reference_size][\"t_vals\"]), np.max(analysis_data[N][\"t_vals\"]))\n        Tc, Tc_error = find_intersection(ref_spline, spline_data[\"spline\"],\n                                         ref_error_spline, spline_data[\"error_spline\"],\n                                         T_min, T_max)\n        if Tc is not None:\n            critical_temps[N] = (Tc, Tc_error)\n            print(f\"Intersection for N={N} (ratio {N/reference_size:.2f}): Tc = {Tc:.4f} ± {Tc_error:.4f}\")\n        else:\n            print(f\"No intersection found for N={N}.\")\n    return critical_temps, reference_size\n\ndef plot_all_intersections(analysis_data, intersections, zoom_margin=0.005, custom_T_low=None, custom_T_high=None):\n    splines = build_splines(analysis_data)\n    if custom_T_low is not None and custom_T_high is not None:\n        T_low, T_high = custom_T_low, custom_T_high\n    else:\n        if intersections:\n            Tc_values = [val[0] for val in intersections.values()]\n            T_low = min(Tc_values) - zoom_margin\n            T_high = max(Tc_values) + zoom_margin\n        else:\n            T_low, T_high = 2.25, 2.29\n    T_fine = np.linspace(T_low, T_high, 1000)\n    plt.figure(figsize=(8, 6))\n    for N, spline_data in splines.items():\n        spline = spline_data[\"spline\"]\n        plt.plot(T_fine, spline(T_fine), label=f\"N={N}\")\n        data = analysis_data[N]\n        mask = (data[\"t_vals\"] &gt;= T_low) & (data[\"t_vals\"] &lt;= T_high)\n        plt.errorbar(np.array(data[\"t_vals\"])[mask], np.array(data[\"binder_vals\"])[mask],\n                     yerr=np.array(data[\"binder_errs\"])[mask], fmt='o', markersize=4,\n                     ecolor='black', capsize=5, alpha=0.5)\n    for (N1, N2), (Tc, Tc_error) in intersections.items():\n        binder_val = splines[N1][\"spline\"](Tc)\n        plt.errorbar(Tc, binder_val, yerr=Tc_error, fmt='ko', markersize=8,\n                     ecolor='black', capsize=5, alpha=0.5)\n        plt.text(Tc, binder_val, f\" {Tc:.3f}±{Tc_error:.3f}\", fontsize=9, color='black')\n        plt.axvline(x=Tc, color='gray', linestyle='--', linewidth=0.5)\n    if T_low &lt;= 2.269 &lt;= T_high:\n        plt.axvline(x=2.269, color='red', linestyle='--', label=\"Expected $T_c$ (2.269)\")\n    plt.xlabel(\"Temperature T\")\n    plt.ylabel(\"Binder Cumulant\")\n    plt.title(\"Zoomed-Out View: Binder Curve Intersections\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_critical_temperatures(critical_temps, reference_size):\n    ratios = [N / reference_size for N in critical_temps.keys()]\n    Tc_values = [val[0] for val in critical_temps.values()]\n    Tc_errors = [val[1] for val in critical_temps.values()]\n    plt.figure(figsize=(8, 6))\n    plt.errorbar(ratios, Tc_values, yerr=Tc_errors, fmt='o', color='blue', label=\"Estimated $T_c$\",\n                 ecolor='black', capsize=5, alpha=0.5)\n    plt.axhline(y=2.269, color='red', linestyle='--', label=\"Expected $T_c$ (2.269)\")\n    plt.xlabel(\"System Size Ratio ($N / N_{small}$)\")\n    plt.ylabel(\"Critical Temperature $T_c$\")\n    plt.title(\"Critical Temperature vs. System Size\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef load_observables(input_folder=\"data6\", sizes=[8, 16, 32]):\n    observables_data = {}\n    for N in sizes:\n        binder_file = os.path.join(input_folder, f\"Analysis_N{N}.npz\")\n        if os.path.exists(binder_file):\n            data = np.load(binder_file)\n            observables_data[N] = {\n                \"t_vals\": data[\"t_vals\"],\n                \"e_means\": data[\"e_means\"],\n                \"e_errs\": data[\"e_errs\"],\n                \"mag_means\": data[\"mag_means\"],\n                \"mag_errs\": data[\"mag_errs\"],\n                \"sus_vals\": data[\"sus_vals\"],\n                \"sus_errs\": data[\"sus_errs\"],\n                \"s_heat_vals\": data[\"s_heat_vals\"],\n                \"s_heat_errs\": data[\"s_heat_errs\"]\n            }\n        else:\n            print(f\"Binder file not found for N={N}.\")\n    return observables_data\n\ndef plot_observables(observables_data):\n    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n    ax = axs[0, 0]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"e_means\"], yerr=data[\"e_errs\"],\n                    fmt='o', label=f\"N={N}\", ecolor='black', capsize=5, alpha=0.5)\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Energy\")\n    ax.set_title(\"Energy vs Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[0, 1]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"mag_means\"], yerr=data[\"mag_errs\"],\n                    fmt='o', label=f\"N={N}\", ecolor='black', capsize=5, alpha=0.5)\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Magnetisation\")\n    ax.set_title(\"Magnetisation vs Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[1, 0]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"sus_vals\"], yerr=data[\"sus_errs\"],\n                    fmt='o', label=f\"N={N}\", ecolor='black', capsize=5, alpha=0.5)\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Susceptibility\")\n    ax.set_title(\"Susceptibility vs Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[1, 1]\n    for N, data in observables_data.items():\n        ax.errorbar(data[\"t_vals\"], data[\"s_heat_vals\"], yerr=data[\"s_heat_errs\"],\n                    fmt='o', label=f\"N={N}\", ecolor='black', capsize=5, alpha=0.5)\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Specific Heat\")\n    ax.set_title(\"Specific Heat vs Temperature\")\n    ax.legend()\n    ax.grid(True)\n    plt.tight_layout()\n    plt.show()\n\ndef plot_loglog_observables(observables_data, intersections, cutoff=1e-3):\n    # if intersections:\n        # Tc_avg = np.mean([val[0] for val in intersections.values()])\n    # else:\n    Tc_avg = 4.5\n    obs_keys = {\"energy\": \"e_means\",\n                \"magnetisation\": \"mag_means\",\n                \"susceptibility\": \"sus_vals\",\n                \"specific_heat\": \"s_heat_vals\"}\n    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n    axs = axs.flatten()\n    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n    for i, obs in enumerate(obs_keys.keys()):\n        ax = axs[i]\n        side = \"above\" if obs in [\"energy\", \"susceptibility\", \"specific_heat\"] else \"below\"\n        for j, N in enumerate(sorted(observables_data.keys())):\n            data = observables_data[N]\n            T = data[\"t_vals\"]\n            y = data[obs_keys[obs]]\n            if obs in [\"energy\", \"magnetisation\"]:\n                y = np.abs(y)\n            x = T - Tc_avg if side == \"above\" else Tc_avg - T\n            mask = x &gt; cutoff\n            x, y = x[mask], y[mask]\n            if len(x) &lt; 2:\n                continue\n            color = colors[j % len(colors)]\n            ax.errorbar(x, y, fmt='o', color=color, label=f\"N={N}\",\n                        ecolor='black', capsize=5, alpha=0.5)\n            logx, logy = np.log(x), np.log(y)\n            p, cov = np.polyfit(logx, logy, 1, cov=True)\n            slope, intercept = p\n            slope_error = np.sqrt(cov[0, 0])\n            x_fit = np.linspace(np.min(x), np.max(x), 100)\n            y_fit = np.exp(intercept) * x_fit**slope\n            ax.plot(x_fit, y_fit, '--', color=color,\n                    label=f\"N={N} fit: {slope:.3f}±{slope_error:.3f}\")\n            ax.text(np.median(x), np.median(y_fit), f\"{slope:.3f}±{slope_error:.3f}\",\n                    color=color, fontsize=9, bbox=dict(facecolor='white', alpha=0.5))\n        ax.set_xscale('log')\n        ax.set_yscale('log')\n        xlabel = r\"$T-T_c$\" if side == \"above\" else r\"$T_c-T$\"\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(obs.capitalize())\n        ax.set_title(f\"Log-Log Plot of {obs.capitalize()}\")\n        ax.legend(fontsize='small')\n        ax.grid(True, which='both', ls='--')\n    plt.suptitle(f\"Log-Log Plots Translated by $T_c$ (Average $T_c$ = {Tc_avg:.3f})\", fontsize=16)\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.show()\n\ndef plot_observable_errors(observables_data):\n    err_keys = {\"energy\": \"e_errs\",\n                \"magnetisation\": \"mag_errs\",\n                \"susceptibility\": \"sus_errs\",\n                \"specific_heat\": \"s_heat_errs\"}\n    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n    ax = axs[0, 0]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"energy\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Energy Error\")\n    ax.set_title(\"Energy Error vs. Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[0, 1]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"magnetisation\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Magnetisation Error\")\n    ax.set_title(\"Magnetisation Error vs. Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[1, 0]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"susceptibility\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Susceptibility Error\")\n    ax.set_title(\"Susceptibility Error vs. Temperature\")\n    ax.legend()\n    ax.grid(True)\n    ax = axs[1, 1]\n    for N, data in observables_data.items():\n        ax.scatter(data[\"t_vals\"], data[err_keys[\"specific_heat\"]], label=f\"N={N}\")\n    ax.set_xlabel(\"Temperature T\")\n    ax.set_ylabel(\"Specific Heat Error\")\n    ax.set_title(\"Specific Heat Error vs. Temperature\")\n    ax.legend()\n    ax.grid(True)\n    plt.tight_layout()\n    plt.show()\n\nif __name__ == \"__main__\":\n    folder = \"data10\"\n    params_filepath = os.path.join(folder, \"simulation_parameters.npz\")\n    if os.path.exists(params_filepath):\n        params = np.load(params_filepath)\n        nt = int(params[\"nt\"])\n        n_list = params[\"n_list\"].tolist()\n        eqSteps = int(params[\"eqSteps\"])\n        mcSteps = int(params[\"mcSteps\"])\n        T_arr = params[\"T_arr\"]\n        print(\"Loaded Simulation Parameters:\")\n        print(\"nt       =\", nt)\n        print(\"n_list   =\", n_list)\n        print(\"eqSteps  =\", eqSteps)\n        print(\"mcSteps  =\", mcSteps)\n\n    else:\n        print(f\"Simulation parameters file not found in {folder}. Using default sizes.\")\n        n_list = [8, 16, 32]\n    compute_analysis(input_folder=folder, output_folder=folder, sizes=n_list)\n    analysis_data = load_analysis(folder=folder, sizes=n_list)\n    plot_binder_values(analysis_data)\n    intersections = calculate_all_intersections(analysis_data)\n    # save_intersections(intersections, filename=\"critical_intersections.npz\")\n    plot_all_intersections(analysis_data, intersections, zoom_margin=0.005, custom_T_low=3.5, custom_T_high=4.5)\n    critical_temps, ref_size = calculate_critical_temperatures(analysis_data)\n    plot_critical_temperatures(critical_temps, ref_size)\n    observables_data = load_observables(input_folder=folder, sizes=n_list)\n    plot_observables(observables_data)\n    plot_loglog_observables(observables_data, intersections, cutoff=1e-1)\n    plot_observable_errors(observables_data)",
    "crumbs": [
      "Main Code",
      "Analysis Code"
    ]
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "Week 4",
    "section": "",
    "text": "- talked about finding errors \n- quick check on the right direction\n\n\n\n- function to import data in format for plotting/calculation\n- binder function that calculates the intersections between interpolating functions\n- plotting function that zooms in near the intersection and adds the binder intersections\n- plotting function that takes binder intersection temperatures and plots them with their associated system size ratio \n- critical exponents log-log graphs\n- configure the code generation for susceplitibility and heat capacity",
    "crumbs": [
      "Week 4"
    ]
  },
  {
    "objectID": "week4.html#morning-meeting",
    "href": "week4.html#morning-meeting",
    "title": "Week 4",
    "section": "",
    "text": "- talked about finding errors \n- quick check on the right direction",
    "crumbs": [
      "Week 4"
    ]
  },
  {
    "objectID": "week4.html#coding-plan",
    "href": "week4.html#coding-plan",
    "title": "Week 4",
    "section": "",
    "text": "- function to import data in format for plotting/calculation\n- binder function that calculates the intersections between interpolating functions\n- plotting function that zooms in near the intersection and adds the binder intersections\n- plotting function that takes binder intersection temperatures and plots them with their associated system size ratio \n- critical exponents log-log graphs\n- configure the code generation for susceplitibility and heat capacity",
    "crumbs": [
      "Week 4"
    ]
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "Week 3",
    "section": "",
    "text": "- Kurtosis/ Binder Parameter \n    - measure of \"gausian'ness\" \n    - can capture change in distribution\n- Finite size scaling\n    - plot different size systems on kurtosis vs temp\n    - all approach same value near criticality\n    - can be used to approximate critical temperature\n- Applying slight field can make system prefer one spin direction\n-Numba package\n    - Just in time computation\n    - @numba.njit decorator above function\n- Critical slowing down\n    - approaching critical point from above, system takes longer to be change\n    - Cluster move algorithms\n        - Swendsen\n        - Woldd\n    - Locality, equilibrium\n- Measuring cluster sizes?\n\n\n\n- Get plots for observables vs iterations\n- understand how to extract kurtosis efficiently for different temperatures\n- get to a plot of kurtosis vs temperature with different size systems\n\n\n\n- reworked the main code to simulate for different sizes of system --&gt; different temperatures\n- used namba to speed up alot of functions\n- created plotting functions\n    -statistic vs temperature --- different system sizes\n    -obvservable vs iteration --- \n\n\n\n- adapted code to save data",
    "crumbs": [
      "Week 3"
    ]
  },
  {
    "objectID": "week3.html#meeting",
    "href": "week3.html#meeting",
    "title": "Week 3",
    "section": "",
    "text": "- Kurtosis/ Binder Parameter \n    - measure of \"gausian'ness\" \n    - can capture change in distribution\n- Finite size scaling\n    - plot different size systems on kurtosis vs temp\n    - all approach same value near criticality\n    - can be used to approximate critical temperature\n- Applying slight field can make system prefer one spin direction\n-Numba package\n    - Just in time computation\n    - @numba.njit decorator above function\n- Critical slowing down\n    - approaching critical point from above, system takes longer to be change\n    - Cluster move algorithms\n        - Swendsen\n        - Woldd\n    - Locality, equilibrium\n- Measuring cluster sizes?",
    "crumbs": [
      "Week 3"
    ]
  },
  {
    "objectID": "week3.html#coding-plan",
    "href": "week3.html#coding-plan",
    "title": "Week 3",
    "section": "",
    "text": "- Get plots for observables vs iterations\n- understand how to extract kurtosis efficiently for different temperatures\n- get to a plot of kurtosis vs temperature with different size systems",
    "crumbs": [
      "Week 3"
    ]
  },
  {
    "objectID": "week3.html#coding-work",
    "href": "week3.html#coding-work",
    "title": "Week 3",
    "section": "",
    "text": "- reworked the main code to simulate for different sizes of system --&gt; different temperatures\n- used namba to speed up alot of functions\n- created plotting functions\n    -statistic vs temperature --- different system sizes\n    -obvservable vs iteration ---",
    "crumbs": [
      "Week 3"
    ]
  },
  {
    "objectID": "week3.html#final-meeting",
    "href": "week3.html#final-meeting",
    "title": "Week 3",
    "section": "",
    "text": "- adapted code to save data",
    "crumbs": [
      "Week 3"
    ]
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "Week 2",
    "section": "",
    "text": "Critical exponents\n\ncritical behaviour relates to what happens around the critical temperature\ncritical exponent defines how a certain parameter grows around the critical temperature to first order in exponent\n\nDid exercies calculating theoretical critical exponnets for spin moment (β) and susceplitibility (γ) with and without field and the exponent for changing magnetic field (δ) with constant critical temperature\nScaling relations\n\ncritical exponents can have relations to one another, α + 2β + γ = 2, γ = β(δ − 1)\n\nScale -althought a mean field theory, seems to be more mathematically exact with higher dimensionality\nUsed in calculating/understanding critical exponents\n\nEdinburgh notes on mean field theory - Ising model\nStatistical Mechanics of phase transitions\n\n\n\n\n\n- Running time calibration\n    - Running time as function of size of the box\n    - Running time as function of total MC steps\n- deviations of numerically calulcated magnetisation from analytical solution (SEE [wikipedia: Exact_solution](https://en.wikipedia.org/wiki/Square_lattice_Ising_model#Exact_solution))\n- Critical exponents\n    - good experimental work on finding critical exponents using monte carlo methods\n    - find for higher dimensions\n- Later Ideas  \n    - Universality\n    - Renormalisation group",
    "crumbs": [
      "Week 2"
    ]
  },
  {
    "objectID": "week2.html#pdf-session-2",
    "href": "week2.html#pdf-session-2",
    "title": "Week 2",
    "section": "",
    "text": "Critical exponents\n\ncritical behaviour relates to what happens around the critical temperature\ncritical exponent defines how a certain parameter grows around the critical temperature to first order in exponent\n\nDid exercies calculating theoretical critical exponnets for spin moment (β) and susceplitibility (γ) with and without field and the exponent for changing magnetic field (δ) with constant critical temperature\nScaling relations\n\ncritical exponents can have relations to one another, α + 2β + γ = 2, γ = β(δ − 1)\n\nScale -althought a mean field theory, seems to be more mathematically exact with higher dimensionality\nUsed in calculating/understanding critical exponents\n\nEdinburgh notes on mean field theory - Ising model\nStatistical Mechanics of phase transitions",
    "crumbs": [
      "Week 2"
    ]
  },
  {
    "objectID": "week2.html#ideas-for-how-to-orient-project",
    "href": "week2.html#ideas-for-how-to-orient-project",
    "title": "Week 2",
    "section": "",
    "text": "- Running time calibration\n    - Running time as function of size of the box\n    - Running time as function of total MC steps\n- deviations of numerically calulcated magnetisation from analytical solution (SEE [wikipedia: Exact_solution](https://en.wikipedia.org/wiki/Square_lattice_Ising_model#Exact_solution))\n- Critical exponents\n    - good experimental work on finding critical exponents using monte carlo methods\n    - find for higher dimensions\n- Later Ideas  \n    - Universality\n    - Renormalisation group",
    "crumbs": [
      "Week 2"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Information",
    "section": "",
    "text": "Information\nIsing Model Project Lab Book - Giancarlo Ramirez\nemail: zj22662@bristol.ac.uk",
    "crumbs": [
      "Information"
    ]
  },
  {
    "objectID": "main_code_text.html",
    "href": "main_code_text.html",
    "title": "Main Code",
    "section": "",
    "text": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nfrom __future__ import division\nimport numpy as np\nfrom numba import njit\nimport math\nimport os\nimport multiprocessing as mp\nfrom functools import partial\n\n# Initialise state\n\ndef initialstate(N, dim, model):\n    \"\"\"\n    Generates a random spin configuration.\n    \n    For 'ising': spins are ±1.\n    For 'xy'   : spins are angles in [0,2π).\n    For 'heisenberg': spins are 3D unit vectors.\n    \n    For 2D: shape (N,N) or (N,N,3); for 3D: shape (N,N,N) or (N,N,N,3).\n    \"\"\"\n    if model == 'ising':\n        if dim == 2:\n            return 2 * np.random.randint(0, 2, size=(N, N)) - 1\n        elif dim == 3:\n            return 2 * np.random.randint(0, 2, size=(N, N, N)) - 1\n    elif model == 'xy':\n        if dim == 2:\n            return np.random.uniform(0, 2*math.pi, size=(N, N))\n        elif dim == 3:\n            return np.random.uniform(0, 2*math.pi, size=(N, N, N))\n    elif model == 'heisenberg':\n        if dim == 2:\n            config = np.random.normal(size=(N, N, 3))\n            for i in range(N):\n                for j in range(N):\n                    norm = math.sqrt(config[i, j, 0]**2 + config[i, j, 1]**2 + config[i, j, 2]**2)\n                    config[i, j, 0] /= norm\n                    config[i, j, 1] /= norm\n                    config[i, j, 2] /= norm\n            return config\n        elif dim == 3:\n            config = np.random.normal(size=(N, N, N, 3))\n            for i in range(N):\n                for j in range(N):\n                    for k in range(N):\n                        norm = math.sqrt(config[i, j, k, 0]**2 + config[i, j, k, 1]**2 + config[i, j, k, 2]**2)\n                        config[i, j, k, 0] /= norm\n                        config[i, j, k, 1] /= norm\n                        config[i, j, k, 2] /= norm\n            return config\n    else:\n        raise ValueError(\"Model must be 'ising', 'xy', or 'heisenberg'.\")\n\n# Metropolis Algorithms\n\n@njit\ndef mcmove2d(config, beta, N, model, delta):\n    \"\"\"\n    One sweep of local Metropolis moves on a 2D lattice.\n    model: 0=ising, 1=xy, 2=heisenberg.\n    \"\"\"\n    num_moves = N * N\n    for k in range(num_moves):\n        i = np.random.randint(0, N)\n        j = np.random.randint(0, N)\n        r = np.random.random()\n        if model == 0:\n            s = config[i, j]\n            nb = (config[(i+1)%N, j] + config[(i-1)%N, j] +\n                  config[i, (j+1)%N] + config[i, (j-1)%N])\n            cost = 2 * s * nb\n            if cost &lt; 0 or r &lt; math.exp(-beta * cost):\n                config[i, j] = -s\n        elif model == 1:\n            theta = config[i, j]\n            theta_r = config[(i+1)%N, j]\n            theta_l = config[(i-1)%N, j]\n            theta_u = config[i, (j+1)%N]\n            theta_d = config[i, (j-1)%N]\n            oldE = - (math.cos(theta - theta_r) + math.cos(theta - theta_l) +\n                      math.cos(theta - theta_u) + math.cos(theta - theta_d))\n            new_theta = theta + np.random.uniform(-delta, delta)\n            newE = - (math.cos(new_theta - theta_r) + math.cos(new_theta - theta_l) +\n                      math.cos(new_theta - theta_u) + math.cos(new_theta - theta_d))\n            dE = newE - oldE\n            if dE &lt; 0 or r &lt; math.exp(-beta * dE):\n                config[i, j] = new_theta\n        elif model == 2:\n            s0 = config[i, j, 0]\n            s1 = config[i, j, 1]\n            s2 = config[i, j, 2]\n            nb0 = (config[(i+1)%N, j, 0] + config[(i-1)%N, j, 0] +\n                   config[i, (j+1)%N, 0] + config[i, (j-1)%N, 0])\n            nb1 = (config[(i+1)%N, j, 1] + config[(i-1)%N, j, 1] +\n                   config[i, (j+1)%N, 1] + config[i, (j-1)%N, 1])\n            nb2 = (config[(i+1)%N, j, 2] + config[(i-1)%N, j, 2] +\n                   config[i, (j+1)%N, 2] + config[i, (j-1)%N, 2])\n            oldE = - (s0 * nb0 + s1 * nb1 + s2 * nb2)\n            new0 = s0 + delta * np.random.normal()\n            new1 = s1 + delta * np.random.normal()\n            new2 = s2 + delta * np.random.normal()\n            norm = math.sqrt(new0*new0 + new1*new1 + new2*new2)\n            new0 /= norm; new1 /= norm; new2 /= norm\n            new_nb0 = (config[(i+1)%N, j, 0] + config[(i-1)%N, j, 0] +\n                       config[i, (j+1)%N, 0] + config[i, (j-1)%N, 0])\n            new_nb1 = (config[(i+1)%N, j, 1] + config[(i-1)%N, j, 1] +\n                       config[i, (j+1)%N, 1] + config[i, (j-1)%N, 1])\n            new_nb2 = (config[(i+1)%N, j, 2] + config[(i-1)%N, j, 2] +\n                       config[i, (j+1)%N, 2] + config[i, (j-1)%N, 2])\n            newE = - (new0 * new_nb0 + new1 * new_nb1 + new2 * new_nb2)\n            dE = newE - oldE\n            if dE &lt; 0 or r &lt; math.exp(-beta * dE):\n                config[i, j, 0] = new0\n                config[i, j, 1] = new1\n                config[i, j, 2] = new2\n    return config\n\n@njit\ndef mcmove3d(config, beta, N, model, delta):\n    \"\"\"\n    One sweep of local Metropolis moves on a 3D lattice.\n    \"\"\"\n    num_moves = N * N * N\n    for k in range(num_moves):\n        x = np.random.randint(0, N)\n        y = np.random.randint(0, N)\n        z = np.random.randint(0, N)\n        r = np.random.random()\n        if model == 0:\n            s = config[x, y, z]\n            nb = (config[(x+1)%N, y, z] + config[(x-1)%N, y, z] +\n                  config[x, (y+1)%N, z] + config[x, (y-1)%N, z] +\n                  config[x, y, (z+1)%N] + config[x, y, (z-1)%N])\n            cost = 2 * s * nb\n            if cost &lt; 0 or r &lt; math.exp(-beta * cost):\n                config[x, y, z] = -s\n        elif model == 1:\n            theta = config[x, y, z]\n            t1 = config[(x+1)%N, y, z]\n            t2 = config[(x-1)%N, y, z]\n            t3 = config[x, (y+1)%N, z]\n            t4 = config[x, (y-1)%N, z]\n            t5 = config[x, y, (z+1)%N]\n            t6 = config[x, y, (z-1)%N]\n            oldE = - (math.cos(theta - t1) + math.cos(theta - t2) +\n                      math.cos(theta - t3) + math.cos(theta - t4) +\n                      math.cos(theta - t5) + math.cos(theta - t6))\n            new_theta = theta + np.random.uniform(-delta, delta)\n            newE = - (math.cos(new_theta - t1) + math.cos(new_theta - t2) +\n                      math.cos(new_theta - t3) + math.cos(new_theta - t4) +\n                      math.cos(new_theta - t5) + math.cos(new_theta - t6))\n            dE = newE - oldE\n            if dE &lt; 0 or r &lt; math.exp(-beta * dE):\n                config[x, y, z] = new_theta\n        elif model == 2:\n            s0 = config[x, y, z, 0]\n            s1 = config[x, y, z, 1]\n            s2 = config[x, y, z, 2]\n            nb0 = (config[(x+1)%N, y, z, 0] + config[(x-1)%N, y, z, 0] +\n                   config[x, (y+1)%N, z, 0] + config[x, (y-1)%N, z, 0] +\n                   config[x, y, (z+1)%N, 0] + config[x, y, (z-1)%N, 0])\n            nb1 = (config[(x+1)%N, y, z, 1] + config[(x-1)%N, y, z, 1] +\n                   config[x, (y+1)%N, z, 1] + config[x, (y-1)%N, z, 1] +\n                   config[x, y, (z+1)%N, 1] + config[x, y, (z-1)%N, 1])\n            nb2 = (config[(x+1)%N, y, z, 2] + config[(x-1)%N, y, z, 2] +\n                   config[x, (y+1)%N, z, 2] + config[x, (y-1)%N, z, 2] +\n                   config[x, y, (z+1)%N, 2] + config[x, y, (z-1)%N, 2])\n            oldE = - (s0 * nb0 + s1 * nb1 + s2 * nb2)\n            new0 = s0 + delta * np.random.normal()\n            new1 = s1 + delta * np.random.normal()\n            new2 = s2 + delta * np.random.normal()\n            norm = math.sqrt(new0*new0 + new1*new1 + new2*new2)\n            new0 /= norm; new1 /= norm; new2 /= norm\n            new_nb0 = (config[(x+1)%N, y, z, 0] + config[(x-1)%N, y, z, 0] +\n                       config[x, (y+1)%N, z, 0] + config[x, (y-1)%N, z, 0] +\n                       config[x, y, (z+1)%N, 0] + config[x, y, (z-1)%N, 0])\n            new_nb1 = (config[(x+1)%N, y, z, 1] + config[(x-1)%N, y, z, 1] +\n                       config[x, (y+1)%N, z, 1] + config[x, (y-1)%N, z, 1] +\n                       config[x, y, (z+1)%N, 1] + config[x, y, (z-1)%N, 1])\n            new_nb2 = (config[(x+1)%N, y, z, 2] + config[(x-1)%N, y, z, 2] +\n                       config[x, (y+1)%N, z, 2] + config[x, (y-1)%N, z, 2] +\n                       config[x, y, (z+1)%N, 2] + config[x, y, (z-1)%N, 2])\n            newE = - (new0 * new_nb0 + new1 * new_nb1 + new2 * new_nb2)\n            dE = newE - oldE\n            if dE &lt; 0 or r &lt; math.exp(-beta * dE):\n                config[x, y, z, 0] = new0\n                config[x, y, z, 1] = new1\n                config[x, y, z, 2] = new2\n    return config\n\n# Wolf Cluster Algorithms 2D\n\n@njit\ndef wolff_update_2d_ising(config, beta, N):\n    \n    # create array to store sites to be flipped (cluster membership)\n    cluster = np.zeros((N, N), dtype=np.int8)\n    \n    # create stack to store site coordinates to be searched\n    stack = np.empty((N*N, 2), dtype=np.int64)\n    # pointer for number of sites left to search\n    stack_ptr = 0\n    \n    # pick a random site \n    i = np.random.randint(0, N)\n    j = np.random.randint(0, N)\n    s0 = config[i, j]\n    \n\n    cluster[i, j] = 1\n    stack[0, 0] = i; stack[0, 1] = j\n    stack_ptr = 1\n    \n    p_add = 1.0 - math.exp(-2.0 * beta)\n\n    while stack_ptr &gt; 0:\n        stack_ptr -= 1\n        # retrieve next site coordinates\n        i = stack[stack_ptr, 0]\n        j = stack[stack_ptr, 1]\n        # For each neighbor:\n        for di, dj in ((1,0), (-1,0), (0,1), (0,-1)):\n            ni = (i + di) % N\n            nj = (j + dj) % N\n            # if neighbor is not yet in the cluster and has the same spin as the seed:\n            if cluster[ni, nj] == 0 and config[ni, nj] == s0:\n                # add neighbor with probability p_add\n                if np.random.random() &lt; p_add:\n                    config[ni, nj] = -config[ni, nj]\n                \n                    cluster[ni, nj] = 1\n                    stack[stack_ptr, 0] = ni\n                    stack[stack_ptr, 1] = nj\n                    stack_ptr += 1\n                    \n                        \n    return config\n\n\n@njit\ndef wolff_update_2d_xy(config, beta, N):\n    \n    # Choose a random reflection direction (unit vector in 2D)\n    phi_ref = np.random.uniform(0, 2*math.pi)\n    \n    # store components\n    r0 = math.cos(phi_ref)\n    r1 = math.sin(phi_ref)\n    \n    # create array to store what needs to be reflected\n    cluster = np.zeros((N, N), dtype=np.int8)\n    \n    # create stack to store what site coordinates needs to be searches\n    stack = np.empty((N*N, 2), dtype=np.int64)\n    # create pointer for number of sites left to search\n    stack_ptr = 0\n    \n    # pick random site\n    i = np.random.randint(0, N)\n    j = np.random.randint(0, N)\n    \n    # flip seed\n    theta = config[i, j]\n    config[i, j] = (2*phi_ref - theta) % (2*math.pi)\n    \n    cluster[i, j] = 1\n    stack[0, 0] = i; stack[0, 1] = j\n    stack_ptr = 1\n    \n    while stack_ptr &gt; 0:\n        stack_ptr -= 1\n        # retrieve next site coords\n        i = stack[stack_ptr, 0]\n        j = stack[stack_ptr, 1]\n        # For each neighbor:\n        for di, dj in ((1,0), (-1,0), (0,1), (0,-1)):\n            ni = (i+di) % N\n            nj = (j+dj) % N\n            if cluster[ni, nj] == 0:\n                theta_i = config[i, j]\n                theta_n = config[ni, nj]\n                a_i = (math.cos(theta_i)*r0 + math.sin(theta_i)*r1)\n                a_n = (math.cos(theta_n)*r0 + math.sin(theta_n)*r1)\n                \n                p_add = 1.0 - math.exp(min(0,2.0 * beta * a_i * a_n))\n                \n                if np.random.random() &lt; p_add:\n                    config[ni, nj] = (2*phi_ref - theta_n) % (2*math.pi)\n                    cluster[ni, nj] = 1\n                    stack[stack_ptr, 0] = ni\n                    stack[stack_ptr, 1] = nj\n                    stack_ptr += 1\n                    \n    return config\n\n    \n@njit\ndef wolff_update_2d_heisenberg(config, beta, N):\n    \n    # Choose a random reflection vector in R3 using spherical coords\n    theta_r = np.random.uniform(0, 2*math.pi)  \n    phi_r = np.random.uniform(0, math.pi)        \n    \n    # store components\n    r0 = math.sin(phi_r) * math.cos(theta_r)\n    r1 = math.sin(phi_r) * math.sin(theta_r)\n    r2 = math.cos(phi_r)\n    \n    # create array to store sites \n    cluster = np.zeros((N, N), dtype=np.int8)\n    \n    # create stack to store site coordinates to be searched\n    stack = np.empty((N*N, 2), dtype=np.int64)\n    # pointer for number of sites left to search\n    stack_ptr = 0\n    \n    # pick a random site as the seed\n    i = np.random.randint(0, N)\n    j = np.random.randint(0, N)\n    \n    # compute projection a = S · r for the seed spin\n    a = config[i, j, 0]*r0 + config[i, j, 1]*r1 + config[i, j, 2]*r2\n    \n    #flip seed\n    s0 = config[i, j, 0]\n    s1 = config[i, j, 1]\n    s2 = config[i, j, 2]\n    config[i, j, 0] = s0 - 2 * a * r0\n    config[i, j, 1] = s1 - 2 * a * r1\n    config[i, j, 2] = s2 - 2 * a * r2\n        \n    # mark the seed as in the cluster and add it to the stack\n    cluster[i, j] = 1\n    stack[0, 0] = i; stack[0, 1] = j\n    stack_ptr = 1\n    \n    \n    while stack_ptr &gt; 0:\n        stack_ptr -= 1\n        # retrieve next site coordinates\n        i = stack[stack_ptr, 0]\n        j = stack[stack_ptr, 1]\n        # For each neighbor:\n        for di, dj in ((1,0), (-1,0), (0,1), (0,-1)):\n            ni = (i + di) % N\n            nj = (j + dj) % N\n            if cluster[ni, nj] == 0:\n\n                a_i = config[i, j, 0]*r0 + config[i, j, 1]*r1 + config[i, j, 2]*r2\n                a_n = config[ni, nj, 0]*r0 + config[ni, nj, 1]*r1 + config[ni, nj, 2]*r2\n                \n                p_add = 1.0 - math.exp(2.0 * beta * min(0,a_i * a_n))\n\n                if np.random.random() &lt; p_add:\n                    \n                    s0_i = config[ni, nj, 0]\n                    s1_i = config[ni, nj, 1]\n                    s2_i = config[ni, nj, 2]\n                    a_val = s0*r0 + s1*r1 + s2*r2\n                    config[ni, nj, 0] = s0_i - 2 * a_val * r0\n                    config[ni, nj, 1] = s1_i - 2 * a_val * r1\n                    config[ni, nj, 2] = s2_i - 2 * a_val * r2\n                    \n                    cluster[ni, nj] = 1\n                    stack[stack_ptr, 0] = ni\n                    stack[stack_ptr, 1] = nj\n                    stack_ptr += 1\n                        \n    return config\n\n#Wrapper for cluster update\n@njit\ndef wolff_update_2d(config, beta, N, model):\n    if model == 0:\n        return wolff_update_2d_ising(config, beta, N)\n    elif model == 1:\n        return wolff_update_2d_xy(config, beta, N)\n    elif model == 2:\n        return wolff_update_2d_heisenberg(config, beta, N)\n    \n\n# 3D Cluster Updates\n@njit\ndef wolff_update_3d_ising(config, beta, N):\n    # create array to store sites to be flipped (cluster membership)\n    cluster = np.zeros((N, N, N), dtype=np.int8)\n    \n    # create stack to store site coordinates to be searched\n    stack = np.empty((N*N*N, 3), dtype=np.int64)\n    stack_ptr = 0\n    \n    # pick a random site\n    x = np.random.randint(0, N)\n    y = np.random.randint(0, N)\n    z = np.random.randint(0, N)\n    s0 = config[x, y, z]\n    \n    # mark seed as in the cluster and add to stack\n    cluster[x, y, z] = 1\n    stack[0, 0] = x; stack[0, 1] = y; stack[0, 2] = z\n    stack_ptr = 1\n    \n    p_add = 1.0 - math.exp(-2.0 * beta)\n    \n    # Grow the cluster\n    while stack_ptr &gt; 0:\n        stack_ptr -= 1\n        x = stack[stack_ptr, 0]\n        y = stack[stack_ptr, 1]\n        z = stack[stack_ptr, 2]\n        # iterate over the six nearest neighbors in 3D\n        for dx, dy, dz in ((1,0,0), (-1,0,0), (0,1,0), (0,-1,0), (0,0,1), (0,0,-1)):\n            nx = (x + dx) % N\n            ny = (y + dy) % N\n            nz = (z + dz) % N\n            if cluster[nx, ny, nz] == 0 and config[nx, ny, nz] == s0:\n                if np.random.random() &lt; p_add:\n                    # flip neighbor spin on the fly\n                    config[nx, ny, nz] = -config[nx, ny, nz]\n                    cluster[nx, ny, nz] = 1\n                    stack[stack_ptr, 0] = nx\n                    stack[stack_ptr, 1] = ny\n                    stack[stack_ptr, 2] = nz\n                    stack_ptr += 1\n                    \n    return config\n\n@njit\ndef wolff_update_3d_xy(config, beta, N):\n    # Choose a random reflection direction (unit vector in 2D, same for each site)\n    phi_ref = np.random.uniform(0, 2*math.pi)\n    r0 = math.cos(phi_ref)\n    r1 = math.sin(phi_ref)\n    \n    # create array to store what needs to be reflected (cluster membership)\n    cluster = np.zeros((N, N, N), dtype=np.int8)\n    \n    # create stack to store site coordinates to be searched\n    stack = np.empty((N*N*N, 3), dtype=np.int64)\n    stack_ptr = 0\n    \n    # pick a random site (seed)\n    x = np.random.randint(0, N)\n    y = np.random.randint(0, N)\n    z = np.random.randint(0, N)\n    theta = config[x, y, z]\n    \n    # flip seed unconditionally\n    config[x, y, z] = (2*phi_ref - theta) % (2*math.pi)\n    cluster[x, y, z] = 1\n    stack[0, 0] = x; stack[0, 1] = y; stack[0, 2] = z\n    stack_ptr = 1\n    \n    # Grow the cluster\n    while stack_ptr &gt; 0:\n        stack_ptr -= 1\n        x = stack[stack_ptr, 0]\n        y = stack[stack_ptr, 1]\n        z = stack[stack_ptr, 2]\n        # iterate over the six nearest neighbors in 3D\n        for dx, dy, dz in ((1,0,0), (-1,0,0), (0,1,0), (0,-1,0), (0,0,1), (0,0,-1)):\n            nx = (x + dx) % N\n            ny = (y + dy) % N\n            nz = (z + dz) % N\n            \n            if cluster[nx, ny, nz] == 0:\n                theta_i = config[x, y, z]\n                theta_n = config[nx, ny, nz]\n                a_i = (math.cos(theta_i)*r0 + math.sin(theta_i)*r1)\n                a_n = (math.cos(theta_n)*r0 + math.sin(theta_n)*r1)\n                \n                p_add = 1.0 - math.exp(min(0,2.0 * beta * a_i * a_n))\n                \n                if np.random.random() &lt; p_add:\n                    config[nx, ny, nz] = (2*phi_ref - theta_n) % (2*math.pi)\n                    cluster[nx, ny, nz] = 1\n                    stack[stack_ptr, 0] = nx\n                    stack[stack_ptr, 1] = ny\n                    stack[stack_ptr, 2] = nz\n                    stack_ptr += 1    \n                \n                        \n    return config\n\n\n@njit\ndef wolff_update_3d_heisenberg(config, beta, N):\n    # Choose a random reflection vector in R^3 using spherical coordinates\n    theta_r = np.random.uniform(0, 2*math.pi)\n    phi_r = np.random.uniform(0, math.pi)\n    r0 = math.sin(phi_r)*math.cos(theta_r)\n    r1 = math.sin(phi_r)*math.sin(theta_r)\n    r2 = math.cos(phi_r)\n    \n    # create array to store sites (cluster membership)\n    cluster = np.zeros((N, N, N), dtype=np.int8)\n    \n    # create stack to store site coordinates to be searched\n    stack = np.empty((N*N*N, 3), dtype=np.int64)\n    stack_ptr = 0\n    \n    # pick a random site as the seed\n    x = np.random.randint(0, N)\n    y = np.random.randint(0, N)\n    z = np.random.randint(0, N)\n    \n    # compute projection a = S · r for the seed spin\n    a = config[x, y, z, 0]*r0 + config[x, y, z, 1]*r1 + config[x, y, z, 2]*r2\n    # flip seed unconditionally using the reflection operation\n    s0 = config[x, y, z, 0]\n    s1 = config[x, y, z, 1]\n    s2 = config[x, y, z, 2]\n    config[x, y, z, 0] = s0 - 2 * a * r0\n    config[x, y, z, 1] = s1 - 2 * a * r1\n    config[x, y, z, 2] = s2 - 2 * a * r2\n    \n    cluster[x, y, z] = 1\n    stack[0, 0] = x; stack[0, 1] = y; stack[0, 2] = z\n    stack_ptr = 1\n    \n    # Grow the cluster\n    while stack_ptr &gt; 0:\n        stack_ptr -= 1\n        x = stack[stack_ptr, 0]\n        y = stack[stack_ptr, 1]\n        z = stack[stack_ptr, 2]\n        # iterate over the six nearest neighbors in 3D\n        for dx, dy, dz in ((1,0,0), (-1,0,0), (0,1,0), (0,-1,0), (0,0,1), (0,0,-1)):\n            nx = (x + dx) % N\n            ny = (y + dy) % N\n            nz = (z + dz) % N\n            if cluster[nx, ny, nz] == 0:\n\n                a_i = config[x, y, z, 0]*r0 + config[x, y, z, 1]*r1 + config[x, y, z, 2]*r2\n                a_n = config[nx, ny, nz, 0]*r0 + config[nx, ny, nz, 0]*r1 + config[nx, ny, nz, 0]*r2\n                \n                p_add = 1.0 - math.exp(2.0 * beta * min(0,a_i * a_n))\n\n                if np.random.random() &lt; p_add:\n                    \n                    s0_i = config[nx, ny, nz, 0]\n                    s1_i = config[nx, ny, nz, 1]\n                    s2_i = config[nx, ny, nz, 2]\n                    a_val = s0*r0 + s1*r1 + s2*r2\n                    config[nx, ny, nz, 0] = s0_i - 2 * a_val * r0\n                    config[nx, ny, nz, 1] = s1_i - 2 * a_val * r1\n                    config[nx, ny, nz, 2] = s2_i - 2 * a_val * r2\n                    \n                    cluster[nx, ny, nz, 0] = 1\n                    stack[stack_ptr, 0] = nx\n                    stack[stack_ptr, 1] = ny\n                    stack[stack_ptr, 2] = nz\n                    stack_ptr += 1\n                \n    return config\n\n\n@njit\ndef wolff_update_3d(config, beta, N, model):\n    if model == 0:\n        return wolff_update_3d_ising(config, beta, N)\n    elif model == 1:\n        return wolff_update_3d_xy(config, beta, N)\n    elif model == 2:\n        return wolff_update_3d_heisenberg(config, beta, N)\n\n# ==========================================================\n# COMBINED MEASUREMENTS (energy, magnetisation, correlation)\n# ==========================================================\n@njit\ndef measure2d_all(config, N, model):\n    R = N // 2\n    energy = 0.0\n    if model == 0:\n        mag = 0.0\n        for i in range(N):\n            for j in range(N):\n                S = config[i, j]\n                energy += -S * (config[i, (j+1)%N] + config[(i+1)%N, j])\n                mag += S\n        corr = np.zeros(R+1, dtype=np.float64)\n        count = np.zeros(R+1, dtype=np.int64)\n        for i in range(N):\n            for j in range(N):\n                for r in range(R+1):\n                    corr[r] += config[i, j] * config[(i+r)%N, j]\n                    count[r] += 1\n        for r in range(R+1):\n            if count[r] &gt; 0:\n                corr[r] /= count[r]\n        return energy, mag, corr\n    elif model == 1:\n        sum_cos = 0.0\n        sum_sin = 0.0\n        for i in range(N):\n            for j in range(N):\n                theta = config[i, j]\n                energy += - (math.cos(theta - config[i, (j+1)%N]) +\n                            math.cos(theta - config[(i+1)%N, j]))\n                sum_cos += math.cos(theta)\n                sum_sin += math.sin(theta)\n        mag = math.sqrt(sum_cos*sum_cos + sum_sin*sum_sin)\n        corr = np.zeros(R+1, dtype=np.float64)\n        count = np.zeros(R+1, dtype=np.int64)\n        for i in range(N):\n            for j in range(N):\n                for r in range(R+1):\n                    corr[r] += math.cos(config[i, j] - config[(i+r)%N, j])\n                    count[r] += 1\n        for r in range(R+1):\n            if count[r] &gt; 0:\n                corr[r] /= count[r]\n        return energy, mag, corr\n    elif model == 2:\n        sum0 = 0.0; sum1 = 0.0; sum2 = 0.0\n        for i in range(N):\n            for j in range(N):\n                s0 = config[i, j, 0]\n                s1 = config[i, j, 1]\n                s2 = config[i, j, 2]\n                energy += - ((s0 * config[i, (j+1)%N, 0] + s1 * config[i, (j+1)%N, 1] + s2 * config[i, (j+1)%N, 2]) +\n                           (s0 * config[(i+1)%N, j, 0] + s1 * config[(i+1)%N, j, 1] + s2 * config[(i+1)%N, j, 2]))\n                sum0 += s0; sum1 += s1; sum2 += s2\n        mag = math.sqrt(sum0*sum0 + sum1*sum1 + sum2*sum2)\n        corr = np.zeros(R+1, dtype=np.float64)\n        count = np.zeros(R+1, dtype=np.int64)\n        for i in range(N):\n            for j in range(N):\n                for r in range(R+1):\n                    s0 = config[i, j, 0]\n                    s1 = config[i, j, 1]\n                    s2 = config[i, j, 2]\n                    t0 = config[(i+r)%N, j, 0]\n                    t1 = config[(i+r)%N, j, 1]\n                    t2 = config[(i+r)%N, j, 2]\n                    corr[r] += s0*t0 + s1*t1 + s2*t2\n                    count[r] += 1\n        for r in range(R+1):\n            if count[r] &gt; 0:\n                corr[r] /= count[r]\n        return energy, mag, corr\n\n@njit\ndef measure3d_all(config, N, model):\n    R = N // 2\n    energy = 0.0\n    if model == 0:\n        mag = 0.0\n        for x in range(N):\n            for y in range(N):\n                for z in range(N):\n                    S = config[x, y, z]\n                    energy += -S * (config[(x+1)%N, y, z] + config[x, (y+1)%N, z] + config[x, y, (z+1)%N])\n                    mag += S\n        corr = np.zeros(R+1, dtype=np.float64)\n        count = np.zeros(R+1, dtype=np.int64)\n        for x in range(N):\n            for y in range(N):\n                for z in range(N):\n                    for r in range(R+1):\n                        corr[r] += config[x, y, z] * config[(x+r)%N, y, z]\n                        count[r] += 1\n        for r in range(R+1):\n            if count[r] &gt; 0:\n                corr[r] /= count[r]\n        return energy, mag, corr\n    elif model == 1:\n        sum_cos = 0.0; sum_sin = 0.0\n        for x in range(N):\n            for y in range(N):\n                for z in range(N):\n                    theta = config[x, y, z]\n                    energy += - (math.cos(theta - config[(x+1)%N, y, z]) +\n                                math.cos(theta - config[x, (y+1)%N, z]) +\n                                math.cos(theta - config[x, y, (z+1)%N]))\n                    sum_cos += math.cos(theta)\n                    sum_sin += math.sin(theta)\n        mag = math.sqrt(sum_cos*sum_cos + sum_sin*sum_sin)\n        corr = np.zeros(R+1, dtype=np.float64)\n        count = np.zeros(R+1, dtype=np.int64)\n        for x in range(N):\n            for y in range(N):\n                for z in range(N):\n                    for r in range(R+1):\n                        corr[r] += math.cos(config[x, y, z] - config[(x+r)%N, y, z])\n                        count[r] += 1\n        for r in range(R+1):\n            if count[r] &gt; 0:\n                corr[r] /= count[r]\n        return energy, mag, corr\n    elif model == 2:\n        sum0 = 0.0; sum1 = 0.0; sum2 = 0.0\n        for x in range(N):\n            for y in range(N):\n                for z in range(N):\n                    s0 = config[x, y, z, 0]\n                    s1 = config[x, y, z, 1]\n                    s2 = config[x, y, z, 2]\n                    energy += - ((s0 * config[(x+1)%N, y, z, 0] + s1 * config[(x+1)%N, y, z, 1] + s2 * config[(x+1)%N, y, z, 2]) +\n                                (s0 * config[x, (y+1)%N, z, 0] + s1 * config[x, (y+1)%N, z, 1] + s2 * config[x, (y+1)%N, z, 2]) +\n                                (s0 * config[x, y, (z+1)%N, 0] + s1 * config[x, y, (z+1)%N, 1] + s2 * config[x, y, (z+1)%N, 2]))\n                    sum0 += s0; sum1 += s1; sum2 += s2\n        mag = math.sqrt(sum0*sum0 + sum1*sum1 + sum2*sum2)\n        corr = np.zeros(R+1, dtype=np.float64)\n        count = np.zeros(R+1, dtype=np.int64)\n        for x in range(N):\n            for y in range(N):\n                for z in range(N):\n                    for r in range(R+1):\n                        s0 = config[x, y, z, 0]\n                        s1 = config[x, y, z, 1]\n                        s2 = config[x, y, z, 2]\n                        t0 = config[(x+r)%N, y, z, 0]\n                        t1 = config[(x+r)%N, y, z, 1]\n                        t2 = config[(x+r)%N, y, z, 2]\n                        corr[r] += s0*t0 + s1*t1 + s2*t2\n                        count[r] += 1\n        for r in range(R+1):\n            if count[r] &gt; 0:\n                corr[r] /= count[r]\n        return energy, mag, corr\n\n# ==========================================================\n# SIMULATION ROUTINE\n# ==========================================================\ndef run_simulation(config, beta, eqSteps, mcSteps, N, dim, model, delta, update_type):\n    \"\"\"\n    Runs equilibration then measurement sweeps.\n    If update_type == 'local', local Metropolis moves are used.\n    If update_type == 'cluster', Wolff cluster updates are used.\n    Measurements (energy, magnetisation, correlation) are computed in one pass.\n    \"\"\"\n    # Convert model to numeric code: 0=ising, 1=xy, 2=heisenberg.\n    if model == 'ising':\n        mcode = 0\n    elif model == 'xy':\n        mcode = 1\n    elif model == 'heisenberg':\n        mcode = 2\n    else:\n        raise ValueError(\"Unknown model\")\n    \n    # Equilibration:\n    for _ in range(eqSteps):\n        if update_type == 'local':\n            if dim == 2:\n                mcmove2d(config, beta, N, mcode, delta)\n            else:\n                mcmove3d(config, beta, N, mcode, delta)\n        elif update_type == 'cluster':\n            if dim == 2:\n                wolff_update_2d(config, beta, N, mcode)\n            else:\n                wolff_update_3d(config, beta, N, mcode)\n    # Measurement:\n    m_i = np.empty(mcSteps, dtype=np.float64)\n    e_i = np.empty(mcSteps, dtype=np.float64)\n    R = N // 2\n    corr_sum = np.zeros(R+1, dtype=np.float64)\n    for i in range(mcSteps):\n        if update_type == 'local':\n            if dim == 2:\n                mcmove2d(config, beta, N, mcode, delta)\n            else:\n                mcmove3d(config, beta, N, mcode, delta)\n        elif update_type == 'cluster':\n            if dim == 2:\n                wolff_update_2d(config, beta, N, mcode)\n            else:\n                wolff_update_3d(config, beta, N, mcode)\n        if dim == 2:\n            e, m, corr = measure2d_all(config, N, mcode)\n        else:\n            e, m, corr = measure3d_all(config, N, mcode)\n        e_i[i] = e\n        m_i[i] = m\n        corr_sum += corr\n    corr_avg = corr_sum / mcSteps\n    return m_i, e_i, corr_avg\n\n# ==========================================================\n# SIMULATION WRAPPER (for multiprocessing)\n# ==========================================================\ndef simulate_temp(args, output_folder, dim, model, delta, update_type):\n    \"\"\"\n    Runs simulation for given N and T_value and saves data.\n    \"\"\"\n    N, T_value, eqSteps, mcSteps = args\n    beta = 1.0 / T_value\n    config = initialstate(N, dim, model)\n    m_i, e_i, corr_avg = run_simulation(config, beta, eqSteps, mcSteps, N, dim, model, delta, update_type)\n    filename = os.path.join(output_folder, f\"run-T{T_value:.3f}N{N}D{dim}-{model}-{update_type}.npz\")\n    np.savez(filename,\n             energy=e_i,\n             magnetisation=m_i,\n             correlation=corr_avg)\n    print(f\"Finished: T={T_value:.3f}, N={N}, dim={dim}, model={model}, update={update_type}, avg m/site={m_i.mean()/(N**dim):.3f}\")\n    return T_value, N, m_i, e_i, corr_avg\n\n# ==========================================================\n# DATA CREATION LOOP\n# ==========================================================\ndef create_data(output_folder, nt, n_list, eqSteps, mcSteps, T_arr, dim, model, delta, update_type):\n    if os.path.exists(output_folder):\n        print(f\"Folder '{output_folder}' already exists.\")\n    else:\n        os.makedirs(output_folder)\n    params_filepath = os.path.join(output_folder, \"simulation_parameters.npz\")\n    np.savez(params_filepath,\n             nt=nt,\n             n_list=np.array(n_list),\n             eqSteps=eqSteps,\n             mcSteps=mcSteps,\n             T_arr=T_arr,\n             dim=dim,\n             model=model,\n             delta=delta,\n             update_type=update_type)\n    print(f\"Simulation parameters saved to {params_filepath}\")\n    tasks = []\n    for N in n_list:\n        for T_val in T_arr:\n            tasks.append((N, T_val, eqSteps, mcSteps))\n    total_tasks = len(tasks)\n    completed_tasks = 0\n    pool = mp.Pool(processes=5)\n    sim_func = partial(simulate_temp, output_folder=output_folder, dim=dim, model=model, delta=delta, update_type=update_type)\n    for result in pool.imap_unordered(sim_func, tasks):\n        completed_tasks += 1\n        print(f\"Progress: {completed_tasks}/{total_tasks} simulations completed.\")\n    pool.close()\n    pool.join()\n\n# ==========================================================\n# MAIN EXECUTION\n# ==========================================================\nif __name__ == '__main__':\n    output_folder = \"data10\"\n    nt          = 50                      # Number of temperature points\n    n_list      = [16, 32, 64]            # Lattice sizes\n    eqSteps     = 1024 * 10               # Equilibration sweeps\n    mcSteps     = 1024 * 10               # Measurement sweeps\n    T_arr       = np.linspace(3.5, 5.5, nt) # Temperature array\n    dim         = 3                       # 2 or 3\n    model       = 'xy'                    # 'ising', 'xy', or 'heisenberg'\n    delta       = 0.3                     # For local moves (not used in cluster)\n    update_type = 'cluster'               # Choose 'local' or 'cluster'\n    \n    create_data(output_folder, nt, n_list, eqSteps, mcSteps, T_arr, dim, model, delta, update_type)",
    "crumbs": [
      "Main Code",
      "Main Code"
    ]
  },
  {
    "objectID": "notebook.html",
    "href": "notebook.html",
    "title": "Example in jupyter",
    "section": "",
    "text": "from __future__ import division\nimport numpy as np\nfrom numpy.random import rand\nimport matplotlib.pyplot as plt\n\n\n#----------------------------------------------------------------------\n##  BLOCK OF FUNCTIONS USED IN THE MAIN CODE\n#----------------------------------------------------------------------\ndef initialstate(N):   \n    ''' generates a random spin configuration for initial condition'''\n    state = 2*np.random.randint(2, size=(N,N))-1\n    return state\n\n\ndef mcmove(config, beta):\n    '''Monte Carlo move using Metropolis algorithm '''\n    for i in range(N):\n        for j in range(N):\n                a = np.random.randint(0, N)\n                b = np.random.randint(0, N)\n                s =  config[a, b]\n                nb = config[(a+1)%N,b] + config[a,(b+1)%N] + config[(a-1)%N,b] + config[a,(b-1)%N]\n                cost = 2*s*nb\n                if cost &lt; 0:\n                    s *= -1\n                elif rand() &lt; np.exp(-cost*beta):\n                    s *= -1\n                config[a, b] = s\n    return config\n\n\ndef calcEnergy(config):\n    '''Energy of a given configuration'''\n    energy = 0\n    for i in range(len(config)):\n        for j in range(len(config)):\n            S = config[i,j]\n            nb = config[(i+1)%N, j] + config[i,(j+1)%N] + config[(i-1)%N, j] + config[i,(j-1)%N]\n            energy += -nb*S\n    return energy/4.\n\n\ndef calcMag(config):\n    '''Magnetization of a given configuration'''\n    mag = np.sum(config)\n    return mag\n\n\n## change these parameters for a smaller (faster) simulation \nnt      = 4        #  number of temperature points\nN       = 16         #  size of the lattice, N x N\neqSteps = 1024       #  number of MC sweeps for equilibration\nmcSteps = 1024       #  number of MC sweeps for calculation\n\nT       = np.linspace(1.53, 3.28, nt) \nE,M,C,X = np.zeros(nt), np.zeros(nt), np.zeros(nt), np.zeros(nt)\nn1, n2  = 1.0/(mcSteps*N*N), 1.0/(mcSteps*mcSteps*N*N) \n# divide by number of samples, and by system size to get intensive values\n\n7 mins nt = 10 # number of temperature points N = 32 # size of the lattice, N x N eqSteps = 1024 # number of MC sweeps for equilibration mcSteps = 1024 # number of MC sweeps for calculation\n20seconds nt = 4 N = 16\n\n#----------------------------------------------------------------------\n#  MAIN PART OF THE CODE\n#----------------------------------------------------------------------\nfor tt in range(nt):\n    print(tt)\n    E1 = M1 = E2 = M2 = 0\n    config = initialstate(N)\n    iT=1.0/T[tt]; iT2=iT*iT;\n    \n    for i in range(eqSteps):         # equilibrate\n        mcmove(config, iT)           # Monte Carlo moves\n\n    for i in range(mcSteps):\n        mcmove(config, iT)           \n        Ene = calcEnergy(config)     # calculate the energy\n        Mag = calcMag(config)        # calculate the magnetisation\n\n        E1 = E1 + Ene\n        M1 = M1 + Mag\n        M2 = M2 + Mag*Mag \n        E2 = E2 + Ene*Ene\n\n    E[tt] = n1*E1\n    M[tt] = n1*M1\n    C[tt] = (n1*E2 - n2*E1*E1)*iT2\n    X[tt] = (n1*M2 - n2*M1*M1)*iT\n\n0\n1\n2\n3\n\n\n\nf = plt.figure(figsize=(9, 5)); # plot the calculated values    \n\nsp =  f.add_subplot(1, 1, 1 );\nplt.scatter(T, E, s=50, marker='o', color='IndianRed')\nplt.xlabel(\"Temperature (T)\", fontsize=20);\nplt.ylabel(\"Energy \", fontsize=20);         plt.axis('tight');\n\nsp =  f.add_subplot(1, 1, 2 );\nplt.scatter(T, abs(M), s=50, marker='o', color='RoyalBlue')\nplt.xlabel(\"Temperature (T)\", fontsize=20); \nplt.ylabel(\"Magnetization \", fontsize=20);   plt.axis('tight');\n\nsp =  f.add_subplot(1, 1, 3 );\nplt.scatter(T, C, s=50, marker='o', color='IndianRed')\nplt.xlabel(\"Temperature (T)\", fontsize=20);  \nplt.ylabel(\"Specific Heat \", fontsize=20);   plt.axis('tight');   \n\nsp =  f.add_subplot(1, 1, 4 );\nplt.scatter(T, X, s=50, marker='o', color='RoyalBlue')\nplt.xlabel(\"Temperature (T)\", fontsize=20); \nplt.ylabel(\"Susceptibility\", fontsize=20);   plt.axis('tight');\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[24], line 8\n      5 plt.xlabel(\"Temperature (T)\", fontsize=20);\n      6 plt.ylabel(\"Energy \", fontsize=20);         plt.axis('tight');\n----&gt; 8 sp =  f.add_subplot(1, 1, 2 );\n      9 plt.scatter(T, abs(M), s=50, marker='o', color='RoyalBlue')\n     10 plt.xlabel(\"Temperature (T)\", fontsize=20); \n\nFile ~/Documents/Ising_Project/minimal-quarto-lab-book/venv/lib/python3.13/site-packages/matplotlib/figure.py:768, in FigureBase.add_subplot(self, *args, **kwargs)\n    766         args = tuple(map(int, str(args[0])))\n    767     projection_class, pkw = self._process_projection_requirements(**kwargs)\n--&gt; 768     ax = projection_class(self, *args, **pkw)\n    769     key = (projection_class, pkw)\n    770 return self._add_axes_internal(ax, key)\n\nFile ~/Documents/Ising_Project/minimal-quarto-lab-book/venv/lib/python3.13/site-packages/matplotlib/axes/_base.py:656, in _AxesBase.__init__(self, fig, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, forward_navigation_events, *args, **kwargs)\n    654 else:\n    655     self._position = self._originalPosition = mtransforms.Bbox.unit()\n--&gt; 656     subplotspec = SubplotSpec._from_subplot_args(fig, args)\n    657 if self._position.width &lt; 0 or self._position.height &lt; 0:\n    658     raise ValueError('Width and height specified must be non-negative')\n\nFile ~/Documents/Ising_Project/minimal-quarto-lab-book/venv/lib/python3.13/site-packages/matplotlib/gridspec.py:589, in SubplotSpec._from_subplot_args(figure, args)\n    587 else:\n    588     if not isinstance(num, Integral) or num &lt; 1 or num &gt; rows*cols:\n--&gt; 589         raise ValueError(\n    590             f\"num must be an integer with 1 &lt;= num &lt;= {rows*cols}, \"\n    591             f\"not {num!r}\"\n    592         )\n    593     i = j = num\n    594 return gs[i-1:j]\n\nValueError: num must be an integer with 1 &lt;= num &lt;= 1, not 2\n\n\n\n\n\n\n\n\n\n\n\nclass Ising():\n    ''' Simulating the Ising model '''    \n    ## monte carlo moves\n    def mcmove(self, config, N, beta):\n        ''' This is to execute the monte carlo moves using \n        Metropolis algorithm such that detailed\n        balance condition is satisified'''\n        for i in range(N):\n            for j in range(N):            \n                    a = np.random.randint(0, N)\n                    b = np.random.randint(0, N)\n                    s =  config[a, b]\n                    nb = config[(a+1)%N,b] + config[a,(b+1)%N] + config[(a-1)%N,b] + config[a,(b-1)%N]\n                    cost = 2*s*nb\n                    if cost &lt; 0:    \n                        s *= -1\n                    elif rand() &lt; np.exp(-cost*beta):\n                        s *= -1\n                    config[a, b] = s\n        return config\n    \n    def simulate(self):   \n        ''' This module simulates the Ising model'''\n        N, temp     = 64, .4        # Initialse the lattice\n        config = 2*np.random.randint(2, size=(N,N))-1\n        f = plt.figure(figsize=(15, 15), dpi=80);    \n        self.configPlot(f, config, 0, N, 1);\n        \n        msrmnt = 1001\n        for i in range(msrmnt):\n            self.mcmove(config, N, 1.0/temp)\n            if i == 1:       self.configPlot(f, config, i, N, 2);\n            if i == 4:       self.configPlot(f, config, i, N, 3);\n            if i == 32:      self.configPlot(f, config, i, N, 4);\n            if i == 100:     self.configPlot(f, config, i, N, 5);\n            if i == 1000:    self.configPlot(f, config, i, N, 6);\n                 \n                    \n    def configPlot(self, f, config, i, N, n_):\n        ''' This modules plts the configuration once passed to it along with time etc '''\n        X, Y = np.meshgrid(range(N), range(N))\n        sp =  f.add_subplot(3, 3, n_ )  \n        plt.setp(sp.get_yticklabels(), visible=False)\n        plt.setp(sp.get_xticklabels(), visible=False)      \n        plt.pcolormesh(X, Y, config, cmap=plt.cm.RdBu);\n        plt.title('Time=%d'%i); plt.axis('tight')    \n    plt.show()\n\n\nrm = Ising()\n\n\nrm.simulate()"
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "Week 1",
    "section": "",
    "text": "Topics:\n\nRenormalisation\nCritical exponents\nScaling laws\nPhase transitions\nClusters\nFundamental model\nMetropolis algorithm\nBlueCrystal HPC\n\nResearch and understand/experiment with code\nAim idea: ‘create popular account using research as structure’\n\n\n\n\n\nIntro\n\nMonte Carlo sampling method\nUse Ising to model magnetism, understand magnetic phase transition\nMain: 2D-square lattice, investigate parameters close to phase transition\nExtra: exact solution 1D, Potts/XY models 2D\n\nPhase transitions\n\nVan der Waals example, gas doesn’t resist being compressed —&gt; must have phase transition\nMagnetism\n\nAll sites spin up/down\nNeighbouring atoms favour same direction, absolute zero has ground states ,all down(m=-ve)/up(m=+ve)\nAbove T=0, entropy favours random spin, high temperatures —&gt; p=1/2 for up/down —&gt; M=0 (zero external field)\nCritical temp T_c when M=0\n\nOther PT’s: superfluids, superconductors\nPT example of spontaneously-broken symmetry\n\nIsing Model\n\nEach site assigned spin value σ = ±1 (up or down)\nEnergy Hamiltonian, H = − Σ J.σ_i.σ_j − Σ B.σ_i , can be hard to calculate, N sites —&gt; 2^N configurations of system\nFirst Σ over all NN’s (2D - 4 bonds),\n\nJ: exchange energy,\n\nJ &lt; 0 —&gt; system favours NN’s same direction spin (ferromagnet), J&gt;0 —&gt; anti-ferromagnet\n\n\nNote: not using SI units in computation , (σ =±ℏ/2)\nNote: real magnetic system, spin can be in any direction —&gt;crystal lattice leads to preferred directions —&gt; ‘spin-orbit’ coupling\nNote: Ising model can be used to model any system where each lattices site has two possible states\n\nStatistical Physics\n\nProbability of state occurring = p = (1/Z).(exp (−H/kBT))\nPartition function (Z) encodes other observables: Z = Σexp (−H/kBT), sum over all states\n\nU =  = - ∂ln(Z)/∂β = (1/Z).ΣH.exp(−H/k_B.T), β = 1/kBT\nF = −kBT ln (Z) : Helmholtz free energy\n\ndF = −SdT + MdB\nS = ∂F/∂T\n\nS = −k_B.Σp.ln(p) , ’Shannon Entropy\n\nM = ∂F/∂B\n\nM = Σ &lt;σ&gt; = ∂/∂B\n\n\n\n\nSingle site exact solution\n\nH = -Bσ = ±B , (σ = ±1)\nZ = exp (−B/kBT) + exp (B/k_B.T)\n&lt;σ&gt; = (1/Z). Σσ.exp(−H/k_B.T) = tanh (B/k_B.T)\nExercise in notebook?\n\nMean-Field Theory\n\nAssume each site experiences NN’s effects as an average effective energy\nH = − ΣB_eff.σ_i , B_eff = B + J.&lt;σ&gt;.z , z = No. Neighbours\nEach spin equivalent on average, each neighbour has same average spin\n2D-square-lattice —&gt; B_eff = B + 4.J.&lt;σ&gt;\n\nFrom single site equation, &lt;σ&gt; = tanh (B_eff /k_B.T) = tanh (B + 4.J.&lt;σ&gt; /k_B.T)\n\nTransendental equation\nIf parameter are such that zJ/kBT &gt; 1, in addition to trivial sol. &lt;σ&gt; = 0, there are two others &lt;σ&gt; &gt; 0 & &lt;σ&gt; &lt; 0\n\nSystem will spontaneously choose of these solutions &lt;—&gt; ferromagnet with spontaneous magnetic moment\nThis happens in the approx solution at T_c = z.J/k_B\nExample of Symmetry Breaking\n\n\n\n\n\n\n\n\nMetrolopolis Algorithms\n\n1: Initialise random starting configuration\n2: Choose one site randomly, calculate energy change of system if spin flipped\n3: If energy reduced –&gt; flip spin, If not –&gt; generate random number 0&lt;p&lt;1, flip if p&lt;exp(-k_b.t.delta_E), [flip with probability = boltzman factor]\n4: Iterate steps 2 and 3 until maximum number of monte carlo (MC) steps reached, observables calculated from all accepted configurations\n\nThings to calulcate\n\nRunning time as function of size of the box\nRunning time as function of total MC steps\ndeviations of numerically calulcated magnetisation from analytical solution (SEE https://en.wikipedia.org/wiki/Square_lattice_Ising_model#Exact_solution)\ncharacteristic configurations patterns for different temperatures\nexploit finite size scaling\n\n\n\n\n\n\nhttps://www.youtube.com/watch?v=OgO1gpXSUzU\nhttps://www.youtube.com/watch?v=EaR3C4e600k\nBasically random sampling and using law of large numbers (as no.trials increases –&gt; average of samples converges to true expected value)",
    "crumbs": [
      "Week 1"
    ]
  },
  {
    "objectID": "week1.html#initial-meeting",
    "href": "week1.html#initial-meeting",
    "title": "Week 1",
    "section": "",
    "text": "Topics:\n\nRenormalisation\nCritical exponents\nScaling laws\nPhase transitions\nClusters\nFundamental model\nMetropolis algorithm\nBlueCrystal HPC\n\nResearch and understand/experiment with code\nAim idea: ‘create popular account using research as structure’",
    "crumbs": [
      "Week 1"
    ]
  },
  {
    "objectID": "week1.html#pdf-session-1---key-concepts-and-background",
    "href": "week1.html#pdf-session-1---key-concepts-and-background",
    "title": "Week 1",
    "section": "",
    "text": "Intro\n\nMonte Carlo sampling method\nUse Ising to model magnetism, understand magnetic phase transition\nMain: 2D-square lattice, investigate parameters close to phase transition\nExtra: exact solution 1D, Potts/XY models 2D\n\nPhase transitions\n\nVan der Waals example, gas doesn’t resist being compressed —&gt; must have phase transition\nMagnetism\n\nAll sites spin up/down\nNeighbouring atoms favour same direction, absolute zero has ground states ,all down(m=-ve)/up(m=+ve)\nAbove T=0, entropy favours random spin, high temperatures —&gt; p=1/2 for up/down —&gt; M=0 (zero external field)\nCritical temp T_c when M=0\n\nOther PT’s: superfluids, superconductors\nPT example of spontaneously-broken symmetry\n\nIsing Model\n\nEach site assigned spin value σ = ±1 (up or down)\nEnergy Hamiltonian, H = − Σ J.σ_i.σ_j − Σ B.σ_i , can be hard to calculate, N sites —&gt; 2^N configurations of system\nFirst Σ over all NN’s (2D - 4 bonds),\n\nJ: exchange energy,\n\nJ &lt; 0 —&gt; system favours NN’s same direction spin (ferromagnet), J&gt;0 —&gt; anti-ferromagnet\n\n\nNote: not using SI units in computation , (σ =±ℏ/2)\nNote: real magnetic system, spin can be in any direction —&gt;crystal lattice leads to preferred directions —&gt; ‘spin-orbit’ coupling\nNote: Ising model can be used to model any system where each lattices site has two possible states\n\nStatistical Physics\n\nProbability of state occurring = p = (1/Z).(exp (−H/kBT))\nPartition function (Z) encodes other observables: Z = Σexp (−H/kBT), sum over all states\n\nU =  = - ∂ln(Z)/∂β = (1/Z).ΣH.exp(−H/k_B.T), β = 1/kBT\nF = −kBT ln (Z) : Helmholtz free energy\n\ndF = −SdT + MdB\nS = ∂F/∂T\n\nS = −k_B.Σp.ln(p) , ’Shannon Entropy\n\nM = ∂F/∂B\n\nM = Σ &lt;σ&gt; = ∂/∂B\n\n\n\n\nSingle site exact solution\n\nH = -Bσ = ±B , (σ = ±1)\nZ = exp (−B/kBT) + exp (B/k_B.T)\n&lt;σ&gt; = (1/Z). Σσ.exp(−H/k_B.T) = tanh (B/k_B.T)\nExercise in notebook?\n\nMean-Field Theory\n\nAssume each site experiences NN’s effects as an average effective energy\nH = − ΣB_eff.σ_i , B_eff = B + J.&lt;σ&gt;.z , z = No. Neighbours\nEach spin equivalent on average, each neighbour has same average spin\n2D-square-lattice —&gt; B_eff = B + 4.J.&lt;σ&gt;\n\nFrom single site equation, &lt;σ&gt; = tanh (B_eff /k_B.T) = tanh (B + 4.J.&lt;σ&gt; /k_B.T)\n\nTransendental equation\nIf parameter are such that zJ/kBT &gt; 1, in addition to trivial sol. &lt;σ&gt; = 0, there are two others &lt;σ&gt; &gt; 0 & &lt;σ&gt; &lt; 0\n\nSystem will spontaneously choose of these solutions &lt;—&gt; ferromagnet with spontaneous magnetic moment\nThis happens in the approx solution at T_c = z.J/k_B\nExample of Symmetry Breaking",
    "crumbs": [
      "Week 1"
    ]
  },
  {
    "objectID": "week1.html#ising-exercise-powerpoints",
    "href": "week1.html#ising-exercise-powerpoints",
    "title": "Week 1",
    "section": "",
    "text": "Metrolopolis Algorithms\n\n1: Initialise random starting configuration\n2: Choose one site randomly, calculate energy change of system if spin flipped\n3: If energy reduced –&gt; flip spin, If not –&gt; generate random number 0&lt;p&lt;1, flip if p&lt;exp(-k_b.t.delta_E), [flip with probability = boltzman factor]\n4: Iterate steps 2 and 3 until maximum number of monte carlo (MC) steps reached, observables calculated from all accepted configurations\n\nThings to calulcate\n\nRunning time as function of size of the box\nRunning time as function of total MC steps\ndeviations of numerically calulcated magnetisation from analytical solution (SEE https://en.wikipedia.org/wiki/Square_lattice_Ising_model#Exact_solution)\ncharacteristic configurations patterns for different temperatures\nexploit finite size scaling",
    "crumbs": [
      "Week 1"
    ]
  },
  {
    "objectID": "week1.html#monte-carlo-method-videos",
    "href": "week1.html#monte-carlo-method-videos",
    "title": "Week 1",
    "section": "",
    "text": "https://www.youtube.com/watch?v=OgO1gpXSUzU\nhttps://www.youtube.com/watch?v=EaR3C4e600k\nBasically random sampling and using law of large numbers (as no.trials increases –&gt; average of samples converges to true expected value)",
    "crumbs": [
      "Week 1"
    ]
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "Week 6",
    "section": "",
    "text": "- Narrative\n    -what is the ising model?\n        - \n    -why is it interesting\n        -phase transition as temperature varied - spontaneous change\n            - what is phase transition\n                - order parameter\n            - what is second order phase transition\n            - critical temperature\n                - universality near critical temp\n            -critical exponents\n    - quantitative explanation of above\n    - Ising model\n        - Hamiltonian\n        - Partition function\n        - Observables ---&gt; derivations\n    - Methods\n        - Observables...\n        - Metropolis\n        - Cluster Algorithm\n        - Binder Cumulant - Critical Temp\n        - Critical Exponents\n    - Results\n        - Magnetisation vs iteration (wolfs vs metropolis)\n        - Binder cumulant \n        - Critical Exponents\n            - magnetisation\n            - susceplitibility\n            - specific temperature\n            - correlation function\n    - Conclusion\n\n\n\n- refining plan and researching literature\n- General \n    - Monte Carlo [Binder textbook](https://www.eng.uc.edu/~beaucag/Classes/AdvancedMaterialsThermodynamics/Books/David%20P.%20Landau,%20Kurt%20Binder%20-%20A%20Guide%20to%20Monte%20Carlo%20Simulations%20in%20Statistical%20Physics%20(2014,%20Cambridge%20University%20Press)%20-%20libgen.lc.pdf)\n    - ising model concerned with the physics of phase transitions\n    - phase transitions occur when a small change in a physical parameter causes a large scale change in the system\n        - water freezing at certain temperature\n        - spontaneous magnetisation - Ising model original purpose \n    - ising model seeks to describe how short range behaviour gives rise to large scale behaviour\n        - general mathematical model for this concept\n            - universality near critical temperature \n- Ising Model\n    - to investigate behaviour will approach it in the context of ferromagnetism and the mathematics of statistical Mechanics\n    - site has spin up or down\n    - Hamiltonian\n        - measures energy of whole system, assumes only nearest-neighbour interaction contribute to energy\n    -Partition function\n        - 1d mean field theory\n        - Observables --&gt; critical exponents\n    - 2^N calculation motivate statisctical maethods below\n- Methods\n    - Monte Carlo\n    - Metropolis\n    - Cluster algorithm\n    - Binder parameter --&gt; critical temperature\n    - use critical temperature to get critical exponents\n- Results\n    - Magnetisation graph (with analytical) and algorithm speed up \n    - phase diagram mag suc vs vs temp \n    - Binder cumulant and critical temperature comparison \n    - Critical exponents 2d and 3d\n        - multi-graph?\n    - errors\n- Conclusion\n      ;",
    "crumbs": [
      "Week 6"
    ]
  },
  {
    "objectID": "week6.html#morning-meeting",
    "href": "week6.html#morning-meeting",
    "title": "Week 6",
    "section": "",
    "text": "- Narrative\n    -what is the ising model?\n        - \n    -why is it interesting\n        -phase transition as temperature varied - spontaneous change\n            - what is phase transition\n                - order parameter\n            - what is second order phase transition\n            - critical temperature\n                - universality near critical temp\n            -critical exponents\n    - quantitative explanation of above\n    - Ising model\n        - Hamiltonian\n        - Partition function\n        - Observables ---&gt; derivations\n    - Methods\n        - Observables...\n        - Metropolis\n        - Cluster Algorithm\n        - Binder Cumulant - Critical Temp\n        - Critical Exponents\n    - Results\n        - Magnetisation vs iteration (wolfs vs metropolis)\n        - Binder cumulant \n        - Critical Exponents\n            - magnetisation\n            - susceplitibility\n            - specific temperature\n            - correlation function\n    - Conclusion",
    "crumbs": [
      "Week 6"
    ]
  },
  {
    "objectID": "week6.html#research-and-writing",
    "href": "week6.html#research-and-writing",
    "title": "Week 6",
    "section": "",
    "text": "- refining plan and researching literature\n- General \n    - Monte Carlo [Binder textbook](https://www.eng.uc.edu/~beaucag/Classes/AdvancedMaterialsThermodynamics/Books/David%20P.%20Landau,%20Kurt%20Binder%20-%20A%20Guide%20to%20Monte%20Carlo%20Simulations%20in%20Statistical%20Physics%20(2014,%20Cambridge%20University%20Press)%20-%20libgen.lc.pdf)\n    - ising model concerned with the physics of phase transitions\n    - phase transitions occur when a small change in a physical parameter causes a large scale change in the system\n        - water freezing at certain temperature\n        - spontaneous magnetisation - Ising model original purpose \n    - ising model seeks to describe how short range behaviour gives rise to large scale behaviour\n        - general mathematical model for this concept\n            - universality near critical temperature \n- Ising Model\n    - to investigate behaviour will approach it in the context of ferromagnetism and the mathematics of statistical Mechanics\n    - site has spin up or down\n    - Hamiltonian\n        - measures energy of whole system, assumes only nearest-neighbour interaction contribute to energy\n    -Partition function\n        - 1d mean field theory\n        - Observables --&gt; critical exponents\n    - 2^N calculation motivate statisctical maethods below\n- Methods\n    - Monte Carlo\n    - Metropolis\n    - Cluster algorithm\n    - Binder parameter --&gt; critical temperature\n    - use critical temperature to get critical exponents\n- Results\n    - Magnetisation graph (with analytical) and algorithm speed up \n    - phase diagram mag suc vs vs temp \n    - Binder cumulant and critical temperature comparison \n    - Critical exponents 2d and 3d\n        - multi-graph?\n    - errors\n- Conclusion\n      ;",
    "crumbs": [
      "Week 6"
    ]
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "Week 5",
    "section": "",
    "text": "- Report\n    - talking report structure\n    - blackboard latex template\n    - how to find references\n    - zotero\n    - zotero overleaf\n- Code \n    - make sure graphs look good in report\n    - explore Renormalisation\n\n\n\n- make sure error bars are valid\n- read through book and try to code 3x3 renormalisation graph\n- show errors decrease with run time, large N has higher error right now\n- create plan for writeup (probably do first to orient other avenues)\n- other Ideas  \n    - extend to xy model, 3d model\n    - implement other resampling methods (e.g. jackknife)\n    - cluster algorithms to explore closer to critical temp\n    - explore different lattice geometries\n\nError handling\n- made sure all errors was plotted\n    - took mean and standard error from time series of magnetisation and energy for each temperature\n    - used those errors and propogated for the binder cumulant\n    - \n\n\n\n- Introduction (1/2 page)\n    - Background and Motivation\n        - Phase transition/critcality ---&gt; Ising Model\n- Theory (1 1/2 page)\n    - Ising Model\n    - Behavior at critical temperature\n    - critical exponents\n    - need for numerical simulation\n- Methods (1/2 page)\n    - Algorithmic details (Metropolis Algorithm)\n    - Error analysis \n    - Binder cumulant to find Critical temperature\n    - Using critical temperature to extract critical exponents\n- Results (1 page)\n    - Observables analysis\n    - Binder Cumulant analysis\n    - Critical Exponents analysis  \n    - Error vs temperature analysis\n- Conclusion\n    -?\n- Bibliogrphy",
    "crumbs": [
      "Week 5"
    ]
  },
  {
    "objectID": "week5.html#morning-meeting",
    "href": "week5.html#morning-meeting",
    "title": "Week 5",
    "section": "",
    "text": "- Report\n    - talking report structure\n    - blackboard latex template\n    - how to find references\n    - zotero\n    - zotero overleaf\n- Code \n    - make sure graphs look good in report\n    - explore Renormalisation",
    "crumbs": [
      "Week 5"
    ]
  },
  {
    "objectID": "week5.html#potential-to-dos",
    "href": "week5.html#potential-to-dos",
    "title": "Week 5",
    "section": "",
    "text": "- make sure error bars are valid\n- read through book and try to code 3x3 renormalisation graph\n- show errors decrease with run time, large N has higher error right now\n- create plan for writeup (probably do first to orient other avenues)\n- other Ideas  \n    - extend to xy model, 3d model\n    - implement other resampling methods (e.g. jackknife)\n    - cluster algorithms to explore closer to critical temp\n    - explore different lattice geometries\n\nError handling\n- made sure all errors was plotted\n    - took mean and standard error from time series of magnetisation and energy for each temperature\n    - used those errors and propogated for the binder cumulant\n    -",
    "crumbs": [
      "Week 5"
    ]
  },
  {
    "objectID": "week5.html#write-up-plan",
    "href": "week5.html#write-up-plan",
    "title": "Week 5",
    "section": "",
    "text": "- Introduction (1/2 page)\n    - Background and Motivation\n        - Phase transition/critcality ---&gt; Ising Model\n- Theory (1 1/2 page)\n    - Ising Model\n    - Behavior at critical temperature\n    - critical exponents\n    - need for numerical simulation\n- Methods (1/2 page)\n    - Algorithmic details (Metropolis Algorithm)\n    - Error analysis \n    - Binder cumulant to find Critical temperature\n    - Using critical temperature to extract critical exponents\n- Results (1 page)\n    - Observables analysis\n    - Binder Cumulant analysis\n    - Critical Exponents analysis  \n    - Error vs temperature analysis\n- Conclusion\n    -?\n- Bibliogrphy",
    "crumbs": [
      "Week 5"
    ]
  }
]